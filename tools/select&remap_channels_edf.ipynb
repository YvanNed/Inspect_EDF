{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140f58b3-cda9-42a6-a6f8-445ec19f463e",
   "metadata": {},
   "source": [
    "# Select, rename and define a re-reference method for .edf files of an EEG database \n",
    "This notebook allows you to select channels of interest within your .edf EEG database, rename them, and define a re-reference method. \\\n",
    "It returns a JSON file (corresponding to a python dictionary) that you can use later in your analysis to apply the choice you made here. \\\n",
    "It is especially useful for datasets with different eeg montage (e.g. multicentric dataset). \n",
    "\n",
    "---\n",
    "**To use this notebook, read each text box (called markdown cells in Jupyter notebook), run its associated code box (code cell), interact with the widgets (buttons and text box), and read the output below.**\\\n",
    "To run a cell, select the cell and either click on \"Run\" and \"Run Selected Cell\" in the menu bar, or press \"Shift+Enter\". \\\n",
    "\\\n",
    "This notebook is organized into 4 sections (with a section 0 to prepare your notebook):\n",
    "1. Select your study folder, extract the data's information, and dispaly channels configurations\n",
    "2. Select channels of interest\n",
    "3. Rename channels\n",
    "4. Define re-reference method\n",
    "5. Preview and save JSON file\n",
    "6. Test the JSON file\n",
    "\n",
    "Once you are done with one section, you can reduce it by pressing the down arrow on the left of the section title, to improve the readability.\\\n",
    "\\\n",
    "_The notebook will save a .json file in a folder config_param within your study folder._ \\\n",
    "_To load this file as a python dictionary:\\\n",
    "define a path variable_ ``json_path = \"your_path\"``\\\n",
    "_and use_ ``with open(json_path, \"r\", encoding=\"utf-8\") as f: config_dict = json.load(f)``\n",
    "\n",
    "---\n",
    "This notebook was developed on the APOMORPHEE database and tested on ICEBERG.  \\\n",
    "last update 20/09/2025, YN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a248543-56c9-4167-a989-8ef7198cffff",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316eaf2b-5591-4698-968d-5117df3f8b13",
   "metadata": {},
   "source": [
    "## 0. Import packages and define custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524814bf-22e4-401b-8b44-24fb84529dcd",
   "metadata": {},
   "source": [
    "The code cell below loads the packages required for this notebook and defines custom functions that we will use.\\\n",
    "If you have already installed all the packages, you will get the message ``‚úÖPackages and functions successfully imported!``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411d73d-c71c-433d-81d2-169e69bd00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cell\n",
    "try:\n",
    "    import os\n",
    "    import re\n",
    "    import mne\n",
    "    import math\n",
    "    import json\n",
    "    import chardet\n",
    "    import warnings\n",
    "    import traceback\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import ipywidgets as widgets\n",
    "    from textwrap import shorten\n",
    "    from collections import OrderedDict\n",
    "    from ipyfilechooser import FileChooser\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "except ImportError as e:\n",
    "    print(\"‚ö†Ô∏è Error: \", e)\n",
    "else:\n",
    "    print(\"‚úÖ Packages and functions successfully imported!\")\n",
    "\n",
    "# custom function to detect automatically and return the encoding of edf file\n",
    "def detect_encoding(byte_string, min_confidence=0.6):\n",
    "    result = chardet.detect(byte_string)\n",
    "    encoding = result['encoding']\n",
    "    confidence = result['confidence']\n",
    "    if encoding is None or confidence < min_confidence:\n",
    "        raise UnicodeDecodeError(\"chardet\", byte_string, 0, len(byte_string),\n",
    "                                 f\"\\tUnable to reliably detect encoding. Detected: {encoding} with confidence {confidence}\")\n",
    "    return encoding\n",
    "\n",
    "# custom function to read information from EDF headers, without using the pyedflib package (that was too strict for ICEBERG)\n",
    "# EDF file should follow a strict format, dedicating a specific number of octets for each type of information.\n",
    "# it means that we can read the info octet by octet by specifying the number of octets we expect for the next variable (that is known from the EDF norm)\n",
    "def read_edf_header_custom(file_path):\n",
    "    with open(file_path, 'rb') as f: # open the file in binary mode, to read octet by octet. \n",
    "        header = {}\n",
    "        # detect encoding\n",
    "        raw_header = f.read(256)\n",
    "        encoding = detect_encoding(raw_header)\n",
    "        # print(f\"\\tDetected encoding for {file_path} : {encoding}\")\n",
    "        # Rewind to the beginning of the file\n",
    "        f.seek(0)\n",
    "        \n",
    "        # the first 256 octets are global subject info\n",
    "        header['version'] = f.read(8).decode(encoding).strip()\n",
    "        header['patient_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['recording_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['start_date'] = f.read(8).decode(encoding).strip()\n",
    "        header['start_time'] = f.read(8).decode(encoding).strip()\n",
    "        header['header_bytes'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['reserved'] = f.read(44).decode(encoding).strip()\n",
    "        header['n_data_records'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['duration_data_record'] = float(f.read(8).decode(encoding).strip())\n",
    "        header['n_channels'] = int(f.read(4).decode(encoding).strip())\n",
    "        \n",
    "        # get info per channel\n",
    "        n = header['n_channels']\n",
    "        channel_fields = {\n",
    "            'channel': [],\n",
    "            'transducer_type': [],\n",
    "            'dimension': [],\n",
    "            'physical_min': [],\n",
    "            'physical_max': [],\n",
    "            'digital_min': [],\n",
    "            'digital_max': [],\n",
    "            'prefiltering': [],\n",
    "            'sampling_frequency': [],\n",
    "            'reserved': [],\n",
    "        }\n",
    "\n",
    "        for key in channel_fields:\n",
    "            length = {\n",
    "                'channel': 16,\n",
    "                'transducer_type': 80,\n",
    "                'dimension': 8,\n",
    "                'physical_min': 8,\n",
    "                'physical_max': 8,\n",
    "                'digital_min': 8,\n",
    "                'digital_max': 8,\n",
    "                'prefiltering': 80,\n",
    "                'sampling_frequency': 8,\n",
    "                'reserved': 32,\n",
    "            }[key]\n",
    "            channel_fields[key] = [f.read(length).decode(encoding).strip() for _ in range(n)]\n",
    "\n",
    "        header.update(channel_fields)\n",
    "    \n",
    "    return header\n",
    "\n",
    "# function to extract filter information from the string in headers\n",
    "def extract_filter_value(s, tag):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(rf'{tag}[:\\s]*([\\d\\.]+)\\s*', s, re.IGNORECASE)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# custom function to get the sampling frequency out of a dataframe (the df needs to have 'subject' and 'channel' as columns)\n",
    "def get_sf(df, subject, channel):\n",
    "    df_sf = df[(df['subject'] == subject) & (df['channel'] == channel)]\n",
    "    if not df_sf.empty:\n",
    "        return df_sf.iloc[0]['sampling_frequency']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# function to create a widget slider to select the configuration to inspect\n",
    "def mk_config_slider(value = 1, min = 1, max = 5):\n",
    "    config_slider = widgets.IntSlider(\n",
    "    value=value,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    step=1,\n",
    "    description='Selected configuration:',\n",
    "    style={'description_width': '150px'},   # increase description width (to adjust based on the description)\n",
    "    layout=widgets.Layout(width='400px'),   # to adjust widget size\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    "    )\n",
    "    return config_slider\n",
    "\n",
    "# function to print the configuration of a dataset parameter\n",
    "def print_config(i, config_dict, param):\n",
    "    # get the key and value from the dictionary\n",
    "    idx = i - 1\n",
    "    # get participant ID\n",
    "    value = list(config_dict.values())  \n",
    "    v = value[idx]  \n",
    "    # get configuration\n",
    "    key = list(config_dict.keys())\n",
    "    k = key[idx]\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {i}')\n",
    "    print(f'\\t{len(k)} {param}: {k}')\n",
    "    print(f'\\t{len(v)} participants: {v}')\n",
    "\n",
    "# function to create a scrollable box for long output (e.g., cell loading the data) \n",
    "def print_in_scrollable_box(text, height=300, font_size=\"12px\"):\n",
    "    display(HTML(f'<pre style=\"overflow-y:scroll; height:{height}px; border:1px solid black; padding:10px; font-size:{font_size};\">{text}</pre>'))\n",
    "\n",
    "# STATE is note really used in this notebook, but added to debug the voila version\n",
    "STATE = SimpleNamespace(\n",
    "    folder_path=None,\n",
    "    config_param_path=None,\n",
    "    edf_files=[],\n",
    "    configs=None,\n",
    "    config_labels=None,\n",
    "    selected_by_config_raw=None,\n",
    "    selected_by_config_canonical_prelim=None,\n",
    "    selected_by_config_canonical=None,\n",
    "    ch_config_dict=None,\n",
    "    remap_by_config=None,\n",
    "    reref_plan_by_config=None,\n",
    "    per_subject_dict=None,\n",
    "    COMMON_10_10=None,\n",
    "    json_path=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64d0e8-5d9e-4661-b4c6-5454f39680fc",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9a604-7fe3-4a81-9e60-1587f7cb14e1",
   "metadata": {},
   "source": [
    "## 1. Select study folder and extract EEGs/EOGs information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a71a42-dc8b-44c1-828d-de3a75b493cf",
   "metadata": {},
   "source": [
    "### 1.1 Select the study folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a34884-abce-42a7-b8db-10e500e75d23",
   "metadata": {},
   "source": [
    "The code cell below will open a widget to select the folder containing your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124017c-7f30-4794-aab6-55a462a5b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call widget to select your data folder \n",
    "chooser = FileChooser(os.getcwd())\n",
    "chooser.title = \"<b>Choose your study folder</b>\"\n",
    "chooser.show_only_dirs = True\n",
    "\n",
    "# Define output widget to redirect the print within the function\n",
    "out = widgets.Output()\n",
    "\n",
    "# custom function to extract the folder path once the folder has been chosen: \n",
    "def on_folder_selected(chooser):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        chooser.folder_path = chooser.selected_path\n",
    "        print(\"üìÅ Selected Path:\", chooser.folder_path)\n",
    "        \n",
    "        # get the edf file list \n",
    "        chooser.edf_files = [\n",
    "            f for f in Path(chooser.folder_path).rglob('*.edf')\n",
    "            if not f.name.startswith('._') # don't select files starting with ._ (that can be found in mac for example)\n",
    "            ]\n",
    "        if not chooser.edf_files:\n",
    "            print(f\"‚ö†Ô∏è There is no .edf file in your folder\")\n",
    "        else:\n",
    "            print(f\"\\nThere is {len(chooser.edf_files)} .edf files in your folder!\")\n",
    "        \n",
    "        # check the existence and/or create the config_param folder that will receive the outputs from this notebook to relabel and re-ref your data\n",
    "        chooser.config_param_path = f'{chooser.folder_path}/config_param'\n",
    "        if not os.path.exists(chooser.config_param_path):\n",
    "            os.makedirs(chooser.config_param_path)\n",
    "            print(\"\\nCreated config. parameter folder at: \" + chooser.config_param_path)\n",
    "        else:\n",
    "            print(\"\\nConfig. parameter folder already exists. \\nPrevious parameters (if any) will be overwritten at: \\n\" + chooser.config_param_path)\n",
    "\n",
    "# callback to run the function only when a folder is selected\n",
    "chooser.register_callback(on_folder_selected)\n",
    "display(chooser, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7e801-ae24-4fdd-a177-a2cbd95e4595",
   "metadata": {},
   "source": [
    "### 1.2 Extract infromation from each file parameters for each participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e5941-d03b-4bba-9e55-5360c6777d51",
   "metadata": {},
   "source": [
    "The code cell below will loop across the .edf files to extract the information of EEGs and EOGs from each subject.\\\n",
    "It returns a table that can easily be manipulated to access specific information in the rest of the notebook.\\\n",
    "If some files failed to load, their names will be saved in a .tsv file in the summary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6870b-badd-4225-aaef-fc974516dee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get variables from the chooser widget\n",
    "folder_path = chooser.folder_path\n",
    "config_param_path = chooser.config_param_path\n",
    "edf_files = chooser.edf_files\n",
    "STATE.edf_files = edf_files\n",
    "\n",
    "# \n",
    "table_found = False\n",
    "found_group = False\n",
    "\n",
    "# Initialize a list of dataframes to store file info, which will be concatenated at the end (this is better for performance)\n",
    "df_list = []\n",
    "# Initialize an empty list for files that could not be read\n",
    "failed_list = []\n",
    "\n",
    "# intialize a dynamic output\n",
    "output = \"\"\n",
    "dynamic_out = widgets.Output()\n",
    "display(dynamic_out)\n",
    "\n",
    "for e, edf_path in enumerate(edf_files):\n",
    "    with dynamic_out:\n",
    "        output += (f'file {e+1}/{len(edf_files)}, currently opening file: {edf_path}\\n')\n",
    "        dynamic_out.clear_output(wait=True)\n",
    "        print_in_scrollable_box(output, font_size = \"12px\")\n",
    "        \n",
    "        # read file with the custom function\n",
    "        try:\n",
    "            edf_header = read_edf_header_custom(edf_path) \n",
    "            \n",
    "            # get subject name (corresponding to file_name)\n",
    "            sub_name = edf_path.stem\n",
    "            \n",
    "            # get subject group (from the parent folder because in the ICEBERG database subfolders were created per patient group)\n",
    "            sub_folder = edf_path.parent.name # get the parent folder of the subject file (path)\n",
    "            \n",
    "            # create df from signal info\n",
    "            df = pd.DataFrame(edf_header)\n",
    "                \n",
    "            # theoretical resolution (edf are 16bit files so the eeg signal can take 2^16 values within the dynamic range)\n",
    "            df['res_theoretical'] = (abs(pd.to_numeric(df['physical_min']))+abs(pd.to_numeric(df['physical_max'])))/pow(2,16)\n",
    "            # turn theoretical resolution to uV if dimension is mV (if no dimension, it is a mess)\n",
    "            df.loc[df['dimension'].str.contains('mv', case=False, na=False), 'res_theoretical'] *= 1000\n",
    "            \n",
    "            # get filtering info in different columns\n",
    "            df['lowpass']   = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'LP'))\n",
    "            df['highpass']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'HP'))\n",
    "            df['notch']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'NOTCH'))\n",
    "            \n",
    "            # add subject info in the dataframe\n",
    "            df['subject'] = sub_name\n",
    "            df['sub_folder'] = sub_folder\n",
    "            df['group'] = np.nan # initialyze column 'group' with NaN\n",
    "            # get group from participants table if any (else group will be inferred from subfolder or filename extension later)\n",
    "            if found_group:\n",
    "                df['group'] = subj_table.loc[subj_table['participant_id'] == sub_name, 'group'].iloc[0]\n",
    "\n",
    "            # extract filename component before and after subject number (so we assume subject name contains at least incrementing numbers that are at the beginning of the file name)  \n",
    "            #   ^       ‚Üí start of string  \n",
    "            # (.*?)     ‚Üí group‚ÄØ1: as few chars as possible, up to the first digit  \n",
    "            # (\\d+)     ‚Üí group‚ÄØ2: the number itself  \n",
    "            # (.*)      ‚Üí group‚ÄØ3: the rest of the string  \n",
    "            # $         ‚Üí end of string\n",
    "            pre_comp = sub_num = post_comp = np.nan\n",
    "            pattern = re.compile(r'^(.*?)(\\d+)(.*)$')\n",
    "            m = pattern.match(sub_name)\n",
    "            if m:\n",
    "                pre_comp = m.group(1) or np.nan\n",
    "                sub_num = m.group(2) or np.nan\n",
    "                post_comp = m.group(3) or np.nan\n",
    "            df['pre_fn_comp'] = pre_comp\n",
    "            df['post_fn_comp'] = post_comp\n",
    "            df['sub_num'] = sub_num\n",
    "            \n",
    "            df['path'] = str(edf_path)\n",
    "            df['session'] = np.nan # session will be inferred later from file name component\n",
    "            \n",
    "            # select only the columns of interest\n",
    "            df = df[['subject', 'group', 'session', 'path', 'sub_folder', 'sub_num', 'pre_fn_comp', 'post_fn_comp', 'channel', 'transducer_type', 'dimension', 'sampling_frequency', \n",
    "                 'highpass', 'lowpass', 'notch', 'physical_min', 'physical_max', 'res_theoretical']]\n",
    "            \n",
    "            # store subject data\n",
    "            df_list.append(df)\n",
    "    \n",
    "        except UnicodeDecodeError as e:\n",
    "            err = f\"‚ö†Ô∏è Encoding problem for {edf_path}\\n\"\n",
    "            output += err\n",
    "            clear_output(wait=True)\n",
    "            print_in_scrollable_box(output, font_size=\"12px\")\n",
    "            failed_list.append((edf_path, 'encoding'))\n",
    "        except Exception as e:\n",
    "            # tb = traceback.format_exc()\n",
    "            err = f\"‚ùå Unexpected problem for {edf_path} : {e}\\n\"\n",
    "            output += err\n",
    "            clear_output(wait=True)\n",
    "            print_in_scrollable_box(output, font_size=\"12px\")\n",
    "            failed_list.append((edf_path, 'other'))\n",
    "   \n",
    "# concatenate dataframe into one and only\n",
    "with warnings.catch_warnings(): # this is to skip a warning not affecting our operation\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    df_full = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# save the failed list if not empty:\n",
    "failed_df = pd.DataFrame(failed_list)\n",
    "if not failed_df.empty:\n",
    "    failed_df.to_csv(f'{config_param_path}/failed_edf_read.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving the list of files that could not be read to: \\n{config_param_path}/failed_edf_read.tsv')\n",
    "\n",
    "# select only EEG and EOGs channels and return a warning if the number of participant is smaller/higher\n",
    "# define common EEG label from the 10-10 convention\n",
    "COMMON_EEG_label = r'\\bFp1\\b|\\bFpz\\b|\\bFp2\\b|\\bAF7\\b|\\bAF3\\b|\\bAFz\\b|\\bAF4\\b|\\bAF8\\b|\\bF7\\b|\\bF5\\b|\\bF3\\b|\\bF1\\b|\\bFz\\b|\\bF2\\b|\\bF4\\b|\\bF6\\b|\\bF8\\b|\\bFT7\\b|\\bFC5\\b|\\bFC3\\b|\\bFC1\\b|\\bFCz\\b|\\bFC2\\b|\\bFC4\\b|\\bFC6\\b|\\bFT8\\b|\\bT7\\b|\\bC5\\b|\\bC3\\b|\\bC1\\b|\\bCz\\b|\\bC2\\b|\\bC4\\b|\\bC6\\b|\\bT8\\b|\\bTP7\\b|\\bCP5\\b|\\bCP3\\b|\\bCP1\\b|\\bCPz\\b|\\bCP2\\b|\\bCP4\\b|\\bCP6\\b|\\bTP8\\b|\\bP7\\b|\\bP5\\b|\\bP3\\b|\\bP1\\b|\\bPz\\b|\\bP2\\b|\\bP4\\b|\\bP6\\b|\\bP8\\b|\\bPO7\\b|\\bPO5\\b|\\bPO3\\b|\\bPOz\\b|\\bPO4\\b|\\bPO6\\b|\\bPO8\\b|\\bO1\\b|\\bOz\\b|\\bO2\\b|\\bM1\\b|\\bM2\\b|EEG'\n",
    "mask = df_full['transducer_type'].str.contains(r'\\bEEG\\b|\\bAGAGCL ELECTRODE\\b|\\bEOG\\b', case=False, na=False) | df_full['channel'].str.contains(r'EOG', case=False, na=False) | df_full['channel'].str.contains(COMMON_EEG_label, case = False, na=False)\n",
    "df_ch = df_full[mask]\n",
    "# remove the emg/ecg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "df_ch = df_ch[~df_ch['channel'].str.contains(r'emg|ecg', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "\n",
    "# get the EEG configuration per participant \n",
    "ch_per_sub = df_ch.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the channel configuration of each participant and store them in a dict to print per channel config\n",
    "ch_config_dict = {}\n",
    "for config in ch_per_sub.unique():\n",
    "    sub = ch_per_sub[ch_per_sub == config].index.tolist()\n",
    "    ch_config_dict[config] = sub\n",
    "\n",
    "if len(ch_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple EEG configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different configuration: {len(ch_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one EEG configuration in your dataset! <<<\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a752f46-632f-4120-b905-f32a26a4d6cc",
   "metadata": {},
   "source": [
    "### 1.3 Display channels configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82370416-f37a-460f-a3b2-612e2c62230d",
   "metadata": {},
   "source": [
    "The code cell below will display the different existing channels configuration within your dataset.\\\n",
    "You should inspect it to identify the channels shared across your configurations to guide your selection of channels.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3eedc-eaf3-4e87-9649-d9f61bdfa579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- A. Construire un tableau \"align√©\" colonnes=config -------\n",
    "# ch_config_dict: { tuple(sorted(set(channels))) : [list_of_subjects] }\n",
    "configs = list(ch_config_dict.keys())\n",
    "n_configs = len(configs)\n",
    "\n",
    "# pr√©pares des √©tiquettes lisibles \"Cfg 1 (n=12)  [ex: sub1, sub2, ...]\"\n",
    "col_labels = []\n",
    "for i, cfg in enumerate(configs, start=1):\n",
    "    subs = ch_config_dict[cfg]\n",
    "    n = len(subs)\n",
    "    # petit aper√ßu des participants dans l'en-t√™te (tronqu√©)\n",
    "    preview = shorten(\", \".join(subs[:5]), width=40, placeholder=\"‚Ä¶\")\n",
    "    col_labels.append(f\"config. {i}<br>(n={n})\")\n",
    "\n",
    "# liste tri√©e des canaux par config\n",
    "cfg_channel_lists = [sorted(list(cfg)) for cfg in configs]\n",
    "max_len = max(len(lst) for lst in cfg_channel_lists) if cfg_channel_lists else 0\n",
    "\n",
    "# on padde les colonnes √† la m√™me hauteur\n",
    "data = {}\n",
    "for label, ch_list in zip(col_labels, cfg_channel_lists):\n",
    "    padded = ch_list + [\"\"] * (max_len - len(ch_list))\n",
    "    data[label] = padded\n",
    "\n",
    "df_configs_aligned = pd.DataFrame(data)\n",
    "df_configs_aligned.index = pd.Index(range(1, max_len+1), name=\"rank\")\n",
    "\n",
    "display(HTML(df_configs_aligned.to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3bfd1-2a06-47a9-a01a-22323d0b2a15",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67a9af-c44b-4064-8b39-e40a96407ff0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Select channels of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b255e-9f6f-4b84-8739-9e702025d1af",
   "metadata": {},
   "source": [
    "The code cell below will open a widget where you can select your channels of interest per configuration.\n",
    "- Click a configuration to unfold its channels list.\n",
    "- Click on the checkboxes to un/select a channel.\n",
    "- You can use the textbox to search for specific channels, and the buttons to un/select all channels.\n",
    "- Repeat this operation for each configuration.\n",
    "- Click the \"Save selection\" button to save your selection, a short summary will be displayed.\\\n",
    "Make sure to click on the \"Save selection\" button before moving on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1ca84-cf7a-419d-a864-12725088c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(x):\n",
    "    return \"\" if x is None else str(x).strip()\n",
    "\n",
    "# --- Pr√©pare les donn√©es depuis ch_config_dict/configs ---\n",
    "# configs : liste de tuples/channels (d√©j√† construite dans ton code pr√©c√©dent)\n",
    "# ch_config_dict : { tuple(sorted(set(channels))) : [list_of_subjects] }\n",
    "\n",
    "if 'configs' not in globals():\n",
    "    configs = list(ch_config_dict.keys())\n",
    "\n",
    "config_labels = []\n",
    "channels_by_cfg = []   # liste parall√®le aux labels : list[str] de canaux raw par config\n",
    "\n",
    "for i, cfg in enumerate(configs, start=1):\n",
    "    subs = ch_config_dict[cfg]\n",
    "    n = len(subs)\n",
    "    label = f\"config. {i} (n={n})\"\n",
    "    config_labels.append(label)\n",
    "    channels_by_cfg.append(sorted(list(cfg)))\n",
    "\n",
    "# --- Calcul canaux communs (optionnel : bouton \"communs\" utile) ---\n",
    "canonical_by_cfg = [sorted({normalize_label(ch) for ch in cfg if normalize_label(ch)}) for cfg in channels_by_cfg]\n",
    "common_canonical = set(canonical_by_cfg[0]) if canonical_by_cfg else set()\n",
    "for cset in canonical_by_cfg[1:]:\n",
    "    common_canonical &= set(cset)\n",
    "\n",
    "# --------- Fabrique un panneau par configuration (avec recherche) ---------\n",
    "def build_config_panel(ch_list):\n",
    "    \"\"\"\n",
    "    Retourne (container_widget, state_dict) pour une configuration donn√©e.\n",
    "    state_dict contient: 'checkboxes', 'filter', 'count_label'\n",
    "    \"\"\"\n",
    "    # Widgets de contr√¥le\n",
    "    filter_box   = widgets.Text(placeholder=\"Filter channels (regex or text)‚Ä¶\", layout=widgets.Layout(width=\"320px\"))\n",
    "    btn_all      = widgets.Button(description=\"select all\", tooltip=\"S√©lectionner tous les canaux\")\n",
    "    btn_none     = widgets.Button(description=\"deselect all\", tooltip=\"D√©selectionner tous les canaux\")\n",
    "    btn_invert   = widgets.Button(description=\"inverse selection\", tooltip=\"Inverser la s√©lection\")\n",
    "    # btn_common   = widgets.Button(description=\"Commun(s)\", tooltip=\"Garder uniquement les canaux communs (canonis√©s)\")\n",
    "\n",
    "    # Cases √† cocher (une par canal)\n",
    "    checkboxes = [widgets.Checkbox(value=True, description=ch) for ch in ch_list]  # par d√©faut: tout coch√©\n",
    "    count_label = widgets.HTML()  # affichera \"X / N s√©lectionn√©s\"\n",
    "\n",
    "    # Mise √† jour du compteur\n",
    "    def update_count():\n",
    "        sel = sum(cb.value for cb in checkboxes)\n",
    "        total = len(checkboxes)\n",
    "        count_label.value = f\"<b>{sel}</b> / {total} s√©lectionn√©s\"\n",
    "\n",
    "    update_count()\n",
    "\n",
    "    # Handlers boutons\n",
    "    def on_all(_):\n",
    "        for cb in checkboxes:\n",
    "            cb.value = True\n",
    "        update_count()\n",
    "\n",
    "    def on_none(_):\n",
    "        for cb in checkboxes:\n",
    "            cb.value = False\n",
    "        update_count()\n",
    "\n",
    "    def on_invert(_):\n",
    "        for cb in checkboxes:\n",
    "            cb.value = not cb.value\n",
    "        update_count()\n",
    "\n",
    "    # def on_common(_):\n",
    "    #     # On garde coch√©s seulement les canaux dont la forme canonis√©e est dans l'intersection\n",
    "    #     keep = {cb: (normalize_label(cb.description) in common_canonical) for cb in checkboxes}\n",
    "    #     for cb, k in keep.items():\n",
    "    #         cb.value = bool(k)\n",
    "    #     update_count()\n",
    "\n",
    "    btn_all.on_click(on_all)\n",
    "    btn_none.on_click(on_none)\n",
    "    btn_invert.on_click(on_invert)\n",
    "    # btn_common.on_click(on_common)\n",
    "\n",
    "    # Filtrage (afficher/masquer visuellement selon filtre)\n",
    "    # Accepte une regex ; si regex invalide, on tombe en \"contains\" insensible √† la casse\n",
    "    out_box = widgets.VBox(checkboxes, layout=widgets.Layout(max_height=\"300px\", overflow=\"auto\", border=\"1px solid #ddd\", padding=\"4px\"))\n",
    "\n",
    "    def apply_filter(*args):\n",
    "        patt = filter_box.value.strip()\n",
    "        for cb in checkboxes:\n",
    "            show = True\n",
    "            label = cb.description\n",
    "            if patt:\n",
    "                try:\n",
    "                    show = bool(re.search(patt, label, flags=re.IGNORECASE))\n",
    "                except re.error:\n",
    "                    show = patt.lower() in label.lower()\n",
    "            cb.layout.display = \"\" if show else \"none\"\n",
    "\n",
    "    filter_box.observe(apply_filter, names=\"value\")\n",
    "\n",
    "    # Chaque checkbox met √† jour le compteur\n",
    "    for cb in checkboxes:\n",
    "        cb.observe(lambda ch: update_count(), names=\"value\")\n",
    "\n",
    "    controls = widgets.HBox([filter_box, btn_all, btn_none, btn_invert], layout=widgets.Layout(gap=\"8px\", flex_flow=\"row wrap\"))\n",
    "    footer   = widgets.HBox([count_label])\n",
    "\n",
    "    panel = widgets.VBox([controls, out_box, footer])\n",
    "    state = {\"checkboxes\": checkboxes, \"filter\": filter_box, \"count_label\": count_label}\n",
    "    return panel, state\n",
    "\n",
    "# --------- Construire l‚ÄôAccordion global ---------\n",
    "panels = []\n",
    "states = []  # un state par config\n",
    "for ch_list in channels_by_cfg:\n",
    "    panel, st = build_config_panel(ch_list)\n",
    "    panels.append(panel)\n",
    "    states.append(st)\n",
    "\n",
    "acc = widgets.Accordion(children=panels)\n",
    "for i, lbl in enumerate(config_labels):\n",
    "    acc.set_title(i, lbl)\n",
    "\n",
    "display(acc)\n",
    "\n",
    "# --------- Bouton pour r√©cup√©rer la s√©lection dans deux variables ---------\n",
    "btn_save = widgets.Button(description=\"Save selection\", button_style=\"success\", icon=\"save\")\n",
    "save_out = widgets.Output()\n",
    "\n",
    "def collect_selection(_=None):\n",
    "    \"\"\"\n",
    "    Construit deux dicts:\n",
    "      - selected_by_config_raw:  {config_label: [canaux 'raw' coch√©s]}\n",
    "      - selected_by_config_canon: {config_label: [canaux canonis√©s (uniques)]}\n",
    "    Les deux variables sont cr√©√©es/√©cras√©es dans l'espace global du notebook.\n",
    "    \"\"\"\n",
    "    selected_raw = {}\n",
    "    selected_canon = {}\n",
    "\n",
    "    for lbl, st, ch_list in zip(config_labels, states, channels_by_cfg):\n",
    "        # r√©associer proprement description -> checkbox\n",
    "        # (l‚Äôordre de ch_list correspond √† l‚Äôordre de cr√©ation)\n",
    "        checked = []\n",
    "        for cb in st[\"checkboxes\"]:\n",
    "            if cb.value:\n",
    "                checked.append(cb.description)\n",
    "\n",
    "        selected_raw[lbl] = checked\n",
    "        # version canonis√©e (unique, tri√©e)\n",
    "        selected_canon[lbl] = sorted({normalize_label(x) for x in checked if normalize_label(x)})\n",
    "\n",
    "    globals()['selected_by_config_raw'] = selected_raw\n",
    "    globals()['selected_by_config_canonical'] = selected_canon\n",
    "\n",
    "    with save_out:\n",
    "        clear_output()\n",
    "        print(\"‚úÖ S√©lections enregistr√©es dans :\")\n",
    "        print(\"   - selected_by_config_raw\")\n",
    "        # petit r√©sum√©\n",
    "        for k in selected_raw:\n",
    "            print(f\"\\t‚Ä¢ {k}: {len(selected_raw[k])} canaux choisis => {selected_raw[k]}\")\n",
    "\n",
    "btn_save.on_click(collect_selection)\n",
    "display(widgets.HBox([btn_save]), save_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59154c02-01d3-4cca-a068-c8771194f485",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9fae4-74a4-432f-b591-2fe83ecc23ce",
   "metadata": {},
   "source": [
    "## 3. Rename channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106352c0-ddb9-44be-98c0-992946d80cbf",
   "metadata": {},
   "source": [
    "The code cell below will open a widget where you can define a new label for the previously selected channels per configuration.\n",
    "- Click a configuration to unfold its channels list.\n",
    "- Use the textboxes to define new labels.\n",
    "- Suggestions following the 10-10 international system can already be proposed.\n",
    "- Click the \"(Re)apply rules to all\" to retrieve the suggestions.\n",
    "- The new labels can be different from the 10-10 system but it can be a problem to plot topomaps in your future analyses.\n",
    "- Repeat this operation for each configuration.\n",
    "- Click the \"Save remapping\" button to save your inputs, a short summary will be displayed.\\\n",
    "Make sure to click on the \"Save remapping\" button before moving on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88177c2a-e592-47d7-968b-92d994c805ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Normalization and synonyms\n",
    "# -----------------------------\n",
    "\n",
    "# 10‚Äì20 core (with official mixed case)\n",
    "COMMON_10_20 = [\n",
    "    \"Fp1\",\"Fp2\",\"F7\",\"F3\",\"Fz\",\"F4\",\"F8\",\n",
    "    \"T3\",\"C3\",\"Cz\",\"C4\",\"T4\",\n",
    "    \"T5\",\"P3\",\"Pz\",\"P4\",\"T6\",\n",
    "    \"O1\",\"O2\",\"T7\",\"T8\",\"P7\",\"P8\",\n",
    "    \"M1\",\"M2\",\"EOG_L\",\"EOG_R\"\n",
    "]\n",
    "\n",
    "# 10‚Äì10 extended (official mixed case; includes z in lowercase, Fp with p lowercase, etc.)\n",
    "COMMON_10_10 = [\n",
    "    # Frontal pole\n",
    "    \"Fp1\", \"Fpz\", \"Fp2\",\n",
    "    # Frontal\n",
    "    \"AF7\", \"AF3\", \"AFz\", \"AF4\", \"AF8\",\n",
    "    \"F7\", \"F5\", \"F3\", \"F1\", \"Fz\", \"F2\", \"F4\", \"F6\", \"F8\",\n",
    "    # Frontocentral\n",
    "    \"FT7\", \"FC5\", \"FC3\", \"FC1\", \"FCz\", \"FC2\", \"FC4\", \"FC6\", \"FT8\",\n",
    "    # Central\n",
    "    \"T7\", \"C5\", \"C3\", \"C1\", \"Cz\", \"C2\", \"C4\", \"C6\", \"T8\",\n",
    "    # Centroparietal\n",
    "    \"TP7\", \"CP5\", \"CP3\", \"CP1\", \"CPz\", \"CP2\", \"CP4\", \"CP6\", \"TP8\",\n",
    "    # Parietal\n",
    "    \"P7\", \"P5\", \"P3\", \"P1\", \"Pz\", \"P2\", \"P4\", \"P6\", \"P8\",\n",
    "    # Parieto-occipital\n",
    "    \"PO7\", \"PO5\", \"PO3\", \"POz\", \"PO4\", \"PO6\", \"PO8\",\n",
    "    # Occipital\n",
    "    \"O1\", \"Oz\", \"O2\",\n",
    "    # Mastoid\n",
    "    \"M1\", \"M2\",\n",
    "    # EOG (not strictly 10‚Äì10 but commonly used)\n",
    "    \"EOG_L\", \"EOG_R\",\n",
    "]\n",
    "\n",
    "# Build a case map: normalized key -> official mixed-case label\n",
    "def _keyize(s: str) -> str:\n",
    "    \"\"\"Uppercase and strip non-alphanumerics for matching.\"\"\"\n",
    "    return re.sub(r\"[^A-Z0-9]\", \"\", str(s).strip().upper())\n",
    "\n",
    "CASE_MAP = { _keyize(lbl): lbl for lbl in COMMON_10_10 }\n",
    "\n",
    "# Synonyms (match by uppercase key; values should be final targets you want)\n",
    "# Example: FZREF -> Fz, CZREF -> Cz, A1->M1, LOC->EOG_L, etc.\n",
    "SYNONYMS_RAW = {\n",
    "    # Eyes / EOG\n",
    "    \"LOC\": \"EOG_L\", \"ROC\": \"EOG_R\",\n",
    "    \"E1\": \"EOG_L\", \"E2\": \"EOG_R\",\n",
    "    \"EOGLEFT\": \"EOG_L\", \"EOGRIGHT\": \"EOG_R\",\n",
    "    # Mastoids / alternates\n",
    "    \"A1\": \"M1\", \"A2\": \"M2\",\n",
    "    # Explicit REF variants (anywhere they appear intact)\n",
    "    \"FZREF\": \"Fz\", \"CZREF\": \"Cz\", \"PZREF\": \"Pz\",\n",
    "}\n",
    "SYNONYMS = { _keyize(k): v for k, v in SYNONYMS_RAW.items() }\n",
    "\n",
    "def normalize_label(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Return canonical EEG label using 10‚Äì10 official casing.\n",
    "    Steps:\n",
    "      0) strip common modality prefixes (EEG, EOG, EMG, ECG, EKG) preserving the remainder\n",
    "      1) clean & uppercase for matching\n",
    "      2) apply synonyms (case-insensitive)\n",
    "      3) strip trailing REF/M1/M2/A1/A2\n",
    "      4) re-case using CASE_MAP (10‚Äì10)\n",
    "      5) apply cautious heuristics ONLY for known 10‚Äì10 families\n",
    "      6) if still unknown -> return original label (stripped), not Title-case\n",
    "    \"\"\"\n",
    "    if raw is None:\n",
    "        return \"\"\n",
    "\n",
    "    # 0) Retirer les pr√©fixes de modalit√© : \"EEG F3\" -> \"F3\"\n",
    "    # (on garde l'original pour le fallback final)\n",
    "    original = str(raw).strip()\n",
    "    pre = re.sub(r'^(EEG|EOG|EMG|ECG|EKG)[\\s_-]+', '', original, flags=re.IGNORECASE)\n",
    "\n",
    "    # 1) Keyize\n",
    "    s_clean = _keyize(pre)  # uppercase + strip separators\n",
    "\n",
    "    # 2) Synonymes\n",
    "    if s_clean in SYNONYMS:\n",
    "        target = SYNONYMS[s_clean]\n",
    "        key_t = _keyize(target)\n",
    "        return CASE_MAP.get(key_t, target)\n",
    "\n",
    "    # 3) Retirer suffixes de r√©f√©rence\n",
    "    s_clean = re.sub(r\"(M1|M2|A1|A2|REF)$\", \"\", s_clean)\n",
    "\n",
    "    # 4) Mapping direct 10‚Äì10\n",
    "    if s_clean in CASE_MAP:\n",
    "        return CASE_MAP[s_clean]\n",
    "\n",
    "    # 5) Heuristiques PRUDENTES, seulement si le pr√©fixe fait partie d'une famille 10‚Äì10\n",
    "    #    (√©vite de bricoler des labels comme \"EEGF3\")\n",
    "    KNOWN_FAMILIES = {\n",
    "        \"FP\",\"AF\",\"F\",\"FT\",\"FC\",\"C\",\"CP\",\"TP\",\"P\",\"PO\",\"O\",\"T\",\"M\",\"EOG\"\n",
    "    }\n",
    "    m = re.match(r\"([A-Z]+)(\\d*Z?)$\", s_clean)  # capture lettres + chiffres (et z √©ventuel)\n",
    "    if m:\n",
    "        letters, digits = m.groups()\n",
    "        # autoriser heuristiques si le pr√©fixe appartient √† une famille connue\n",
    "        # cas particulier: \"FZ\", \"CZ\", etc. -> g√©rer le 'z' minuscule\n",
    "        if any(letters.startswith(fam) for fam in KNOWN_FAMILIES):\n",
    "            # z final en minuscule pour les montages '...Z'\n",
    "            if letters.endswith(\"Z\") and len(letters) >= 2:\n",
    "                return letters[:-1].title() + \"z\"\n",
    "            # FP -> Fp + digits (inclut Fpz si digits==\"Z\")\n",
    "            if letters.startswith(\"FP\"):\n",
    "                if digits.upper() == \"Z\":\n",
    "                    return \"Fpz\"\n",
    "                return \"Fp\" + digits.lower()\n",
    "            # fallback l√©ger: Title-case des lettres pour familles connues\n",
    "            return letters.title() + digits\n",
    "\n",
    "    # 6) Si on n'a rien reconnu ou heuristiques non applicables -> rendre l'ORIGINAL\n",
    "    return original\n",
    "    \n",
    "# ----------------------------------------------------------------\n",
    "# 2) Build the suggestion pool = official 10‚Äì10 + normalized from selections\n",
    "# ----------------------------------------------------------------\n",
    "if 'selected_by_config_raw' not in globals():\n",
    "    raise RuntimeError(\"selected_by_config_raw not found. Run the selection widget first.\")\n",
    "\n",
    "config_labels = list(selected_by_config_raw.keys())\n",
    "\n",
    "suggest_pool = set(COMMON_10_10)  # start with the official 10‚Äì10 mixed-case labels\n",
    "for cfg_label in config_labels:\n",
    "    for raw in selected_by_config_raw[cfg_label]:\n",
    "        if raw:\n",
    "            suggest_pool.add(normalize_label(raw))\n",
    "\n",
    "SUGGESTIONS = sorted(x for x in suggest_pool if x)\n",
    "# -----------------------------------------------------------\n",
    "# 3) Editor: one Accordion tab per config, rows with Combobox\n",
    "# -----------------------------------------------------------\n",
    "row_widgets_by_cfg = {}  # {cfg_label: {raw_label: Combobox}}\n",
    "\n",
    "def make_row(raw_label: str):\n",
    "    \"\"\"Return (HBox, Combobox) for raw -> canonical mapping.\"\"\"\n",
    "    # Combobox = suggestions + free text\n",
    "    combo = widgets.Combobox(\n",
    "        options=SUGGESTIONS,\n",
    "        value=normalize_label(raw_label),        # pre-fill with a suggestion\n",
    "        placeholder=\"Type or pick a canonical label‚Ä¶\",\n",
    "        ensure_option=False,                     # allow values outside the options list\n",
    "        description=\"\",                          # no left description (we show raw label separately)\n",
    "        layout=widgets.Layout(width=\"240px\")\n",
    "    )\n",
    "    raw_lab = widgets.Label(raw_label, layout=widgets.Layout(width=\"220px\"))\n",
    "    row = widgets.HBox([raw_lab, combo])\n",
    "    return row, combo\n",
    "\n",
    "panels = []\n",
    "for cfg_label in config_labels:\n",
    "    row_widgets_by_cfg[cfg_label] = {}\n",
    "\n",
    "    # stable ordering\n",
    "    raw_list = sorted(selected_by_config_raw[cfg_label], key=lambda s: s.upper())\n",
    "\n",
    "    # Local toolbar\n",
    "    btn_apply_rules = widgets.Button(\n",
    "        description=\"(Re)apply rules to all\",\n",
    "        tooltip=\"Re-run normalize_label(raw) for every row in this configuration\",\n",
    "        button_style=\"info\"\n",
    "    )\n",
    "    info = widgets.HTML(value=\"<i>You can type freely or pick a suggestion.</i>\")\n",
    "\n",
    "    # Rows\n",
    "    rows = []\n",
    "    for raw in raw_list:\n",
    "        row, combo = make_row(raw)\n",
    "        rows.append(row)\n",
    "        row_widgets_by_cfg[cfg_label][raw] = combo\n",
    "\n",
    "    # Bind apply-all\n",
    "    def make_apply_all(rows_map=row_widgets_by_cfg[cfg_label], raws=raw_list):\n",
    "        def fn(_):\n",
    "            for r in raws:\n",
    "                rows_map[r].value = normalize_label(r)\n",
    "        return fn\n",
    "    btn_apply_rules.on_click(make_apply_all())\n",
    "\n",
    "    panel = widgets.VBox([\n",
    "        widgets.HBox([btn_apply_rules, info]),\n",
    "        widgets.VBox(\n",
    "            rows,\n",
    "            layout=widgets.Layout(max_height=\"380px\", overflow=\"auto\", border=\"1px solid #ddd\", padding=\"6px\")\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    panels.append(panel)\n",
    "\n",
    "acc = widgets.Accordion(children=panels)\n",
    "for i, cfg_label in enumerate(config_labels):\n",
    "    acc.set_title(i, cfg_label)\n",
    "\n",
    "display(acc)\n",
    "\n",
    "# === 10‚Äì10 helpers ===\n",
    "ALLOWED_NON_TENTEN = {\"EOG_L\", \"EOG_R\"}  # tol√©r√©s au m√™me titre que 10‚Äì10\n",
    "\n",
    "def is_ten_ten(label: str) -> bool:\n",
    "    \"\"\"True si le label est dans la nomenclature 10‚Äì10 (CASE_MAP) ou explicitement autoris√©.\"\"\"\n",
    "    if not label:\n",
    "        return False\n",
    "    key = _keyize(label)  # m√™me keyizer que pour CASE_MAP\n",
    "    return (key in CASE_MAP) or (label in ALLOWED_NON_TENTEN)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4) Save mapping -> remap_by_config + warnings + exports\n",
    "# --------------------------------------------\n",
    "\n",
    "btn_save = widgets.Button(description=\"Save remapping\", button_style=\"success\", icon=\"save\")\n",
    "out = widgets.Output(\n",
    "    layout=widgets.Layout(\n",
    "        width=\"100%\",\n",
    "        height=\"auto\",\n",
    "        max_height=\"none\",\n",
    "        overflow=\"visible\",      # <- enl√®ve la scrollbox\n",
    "        border=\"0\"  # optionnel\n",
    "    )\n",
    ")\n",
    "display(widgets.HBox([btn_save]), out)\n",
    "\n",
    "def on_save(_=None):\n",
    "    export_msg = \"\"\n",
    "    warnings_dup = []      # [(cfg_label, {canon: [raws...]})]\n",
    "    nonstandard = {}       # {cfg_label: [non-10‚Äì10 labels]}\n",
    "    try:\n",
    "        # --- build mappings ---\n",
    "        remap = {}\n",
    "        canonical_lists = {}\n",
    "\n",
    "        for cfg_label in config_labels:\n",
    "            rows_map = row_widgets_by_cfg[cfg_label]   # {raw: Combobox}\n",
    "            mapping = {}\n",
    "            bad = []\n",
    "            for raw, combo in rows_map.items():\n",
    "                can = (combo.value or \"\").strip()\n",
    "                mapping[raw] = can\n",
    "                # v√©rif stricte 10‚Äì10 (PAS de garde)\n",
    "                if can and not is_ten_ten(can):\n",
    "                    bad.append(can)\n",
    "\n",
    "            remap[cfg_label] = mapping\n",
    "            canonical_lists[cfg_label] = sorted({v for v in mapping.values() if v})\n",
    "            if bad:\n",
    "                nonstandard[cfg_label] = sorted(set(bad))\n",
    "\n",
    "        # doublons de cibles canonis√©es (info)\n",
    "        for cfg_label, mapping in remap.items():\n",
    "            inv = {}\n",
    "            for raw, can in mapping.items():\n",
    "                if not can:\n",
    "                    continue\n",
    "                inv.setdefault(can, []).append(raw)\n",
    "            dups = {k: v for k, v in inv.items() if len(v) > 1}\n",
    "            if dups:\n",
    "                warnings_dup.append((cfg_label, dups))\n",
    "\n",
    "        # exposer en globals\n",
    "        globals()[\"remap_by_config\"] = remap\n",
    "        globals()[\"selected_by_config_canonical\"] = canonical_lists\n",
    "\n",
    "        # --- exports ---\n",
    "        try:\n",
    "            # mapping complet\n",
    "            df_rows = []\n",
    "            for cfg_label, mapping in remap.items():\n",
    "                for raw, can in mapping.items():\n",
    "                    df_rows.append({\"config\": cfg_label, \"raw_channel\": raw, \"canonical_channel\": can})\n",
    "            df_map = pd.DataFrame(df_rows)\n",
    "            # commenting the save for now\n",
    "            # df_map.to_csv(f\"{config_param_path}/remap_raw_to_canonical.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "            # listes canoniques par config\n",
    "            df_canon = pd.DataFrame({cfg: pd.Series(chs) for cfg, chs in canonical_lists.items()})\n",
    "            # commenting the save for now\n",
    "            # df_canon.to_csv(f\"{config_param_path}/selected_canonical_by_config.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "            # labels non 10‚Äì10\n",
    "            if nonstandard:\n",
    "                ns_rows = []\n",
    "                for cfg_label, labs in nonstandard.items():\n",
    "                    for lab in labs:\n",
    "                        ns_rows.append({\"config\": cfg_label, \"non_10_10_label\": lab})\n",
    "                # commenting the save for now\n",
    "                # pd.DataFrame(ns_rows).to_csv(f\"{config_param_path}/non_10_10_labels.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "            export_msg = (f\"\\nüìù Exports:\\n\"\n",
    "                          f\" - {config_param_path}/remap_raw_to_canonical.tsv\\n\"\n",
    "                          f\" - {config_param_path}/selected_canonical_by_config.tsv\"\n",
    "                          + (f\"\\n - {config_param_path}/non_10_10_labels.tsv\" if nonstandard else \"\"))\n",
    "        except Exception as e:\n",
    "            export_msg = f\"\\n(Export skipped: {e})\"\n",
    "\n",
    "        # Export JSON\n",
    "        try:\n",
    "            # commenting the save for now (20/11/2025)\n",
    "            json_path = os.path.join(config_param_path, \"mne_remap_plan.json\")\n",
    "            # with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            #     json.dump(remap_by_config, f, indent=2, ensure_ascii=False)\n",
    "            saved_msg = f\"    JSON:\\n - {json_path}\"\n",
    "        except Exception as e:\n",
    "            saved_msg = f\"(JSON export skipped: {e})\"\n",
    "        print(saved_msg)\n",
    "\n",
    "        # --- affichage ---\n",
    "        with out:\n",
    "            clear_output()\n",
    "            print(\"‚úÖ Mapping saved to variables:\")\n",
    "            print(\"   - remap_by_config\")\n",
    "            print(\"   - selected_by_config_canonical\")\n",
    "            # commenting the export because they are saved later per participant\n",
    "            # print(export_msg)\n",
    "            # print(saved_msg)\n",
    "\n",
    "            if warnings_dup:\n",
    "                print(\"\\n‚ö†Ô∏è Multiple raw labels mapped to the same canonical within a configuration:\")\n",
    "                for cfg_label, dups in warnings_dup:\n",
    "                    print(f\"  ‚Ä¢ {cfg_label}: {dups}\")\n",
    "\n",
    "            if nonstandard:\n",
    "                print(\"\\n‚ö†Ô∏è Non-10‚Äì10 canonical labels detected (consider official 10‚Äì10 names):\")\n",
    "                for cfg_label, badlist in nonstandard.items():\n",
    "                    print(f\"  ‚Ä¢ {cfg_label}: {badlist}\")\n",
    "                print(\"‚ö†Ô∏è This might cause issue to plot topomap (this is not a problem for clinical set-up with 3 channels only)\")\n",
    "\n",
    "            if not warnings_dup and not nonstandard:\n",
    "                print(\"\\nNo issues detected.\")\n",
    "\n",
    "            print(\"\\nQuick overview of the remapping:\")\n",
    "            for config, remap_d in remap_by_config.items():\n",
    "                print(f\"\\t{config}: {remap_d}\")\n",
    "\n",
    "    except Exception:\n",
    "        with out:\n",
    "            clear_output()\n",
    "            print(\"‚ùå Error while saving the mapping ‚Äî traceback:\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "btn_save.on_click(on_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1a699-8a5d-4faf-8514-73c27f9bfede",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fdde61-b4ec-4655-b750-e9753eed9f72",
   "metadata": {},
   "source": [
    "## 4. Define re-reference method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0179a5-93b8-4125-b93b-15b4a1a04032",
   "metadata": {},
   "source": [
    "The code cell below will open a widget where you can define a re-reference method (to apply before your analysis).\\\n",
    "There is 3 options: \n",
    "- None (if your data are already re-referenced (e.g. C4-M1 is already referenced to M1)\n",
    "- Average\n",
    "- Custom (to choose one or two specific channels)\n",
    "  \n",
    "Steps of the widget:\n",
    "- Click a configuration to unfold its re-reference selection.\n",
    "- Choose your method of re-referencing.\n",
    "- For custom, select the wanted reference channel and click the \"Add\" button.\n",
    "- To use two channels as reference (e.g. linked mastoids M1-M2), you need to add each channel one by one (with the same instruction as above).\n",
    "- Repeat this operation for each configuration.\n",
    "- Click the \"Save re-reference\" button to save your inputs, a short summary will be displayed.\\\n",
    "Make sure to click on the \"Save re-reference\" button before moving on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed173d-058f-4008-b0b1-f1fe10e9fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs expected\n",
    "if 'selected_by_config_canonical' not in globals():\n",
    "    raise RuntimeError(\"selected_by_config_canonical not found. Run the previous mapping step first.\")\n",
    "if 'COMMON_10_10' not in globals():\n",
    "    COMMON_10_10 = []  # optional\n",
    "\n",
    "config_labels = list(selected_by_config_canonical.keys())\n",
    "\n",
    "# Suggestions: union of 10‚Äì10 and each config channels (per config we‚Äôll filter)\n",
    "base_suggestions = set(COMMON_10_10)\n",
    "\n",
    "# State storage\n",
    "state_by_cfg = {}  # cfg -> dict(mode_radio, combo, add_btn, list_box, info_html)\n",
    "\n",
    "def build_panel_for_config(cfg_label):\n",
    "    \"\"\"\n",
    "    Left: configuration channels (read-only).\n",
    "    Right: mode (None/Average/Custom) and a Combobox-based multi-pick for Custom.\n",
    "    \"\"\"\n",
    "    cfg_channels = sorted(selected_by_config_canonical[cfg_label])\n",
    "    # Suggestions for this config = its channels + 10-10\n",
    "    suggestions = cfg_channels # use sorted(base_suggestions.union(cfg_channels)) if you want to add the 10-10 list\n",
    "\n",
    "    # --- Left: show configuration channels ---\n",
    "    left_title = widgets.HTML(f\"<b>Configuration channels ({len(cfg_channels)}):</b>\")\n",
    "    left_list  = widgets.VBox(\n",
    "        [widgets.HTML(\", \".join(cfg_channels))],\n",
    "        layout=widgets.Layout(max_height=\"150px\", overflow=\"auto\", border=\"1px solid #ddd\", padding=\"6px\")\n",
    "    )\n",
    "    left_box = widgets.VBox([left_title, left_list], layout=widgets.Layout(width=\"50%\"))\n",
    "\n",
    "    # --- Right: controls ---\n",
    "    mode = widgets.RadioButtons(\n",
    "        options=[(\"None (keep as-is)\", \"none\"),\n",
    "                 (\"Average reference\", \"average\"),\n",
    "                 (\"Custom reference (pick)\", \"custom\")],\n",
    "        value=\"none\",\n",
    "        description=\"Method:\",\n",
    "        layout=widgets.Layout(width=\"330px\")\n",
    "    )\n",
    "\n",
    "    # Combobox to add ONE ref channel at a time (free text + suggestions)\n",
    "    combo = widgets.Combobox(\n",
    "        options=suggestions,\n",
    "        value=\"\",\n",
    "        placeholder=\"Type or pick a reference channel‚Ä¶\",\n",
    "        ensure_option=False,   # allow values outside suggestions\n",
    "        layout=widgets.Layout(width=\"260px\")\n",
    "    )\n",
    "    add_btn = widgets.Button(description=\"Add\", button_style=\"primary\", tooltip=\"Add channel to custom reference list\")\n",
    "\n",
    "    # A list of currently chosen reference channels (with removable buttons)\n",
    "    chosen_box = widgets.VBox([], layout=widgets.Layout(\n",
    "        max_height=\"200px\", overflow=\"auto\", border=\"1px solid #ddd\", padding=\"6px\", width=\"260px\"\n",
    "    ))\n",
    "    chosen_label = widgets.HTML(\"<b>Custom reference channels:</b>\")\n",
    "\n",
    "    # Info / validation\n",
    "    info = widgets.HTML(\"<i>Select re-reference method. For 'Custom', add channels using the combobox.</i>\")\n",
    "\n",
    "    # Helper to (re)build the chosen list UI\n",
    "    chosen = []  # Python list of strings (unique)\n",
    "    def refresh_chosen_box():\n",
    "        # Clear and re-create rows with a small remove (√ó) button\n",
    "        rows = []\n",
    "        for ch in chosen:\n",
    "            rm_btn = widgets.Button(description=\"√ó\", tooltip=f\"Remove {ch}\", layout=widgets.Layout(width=\"28px\"))\n",
    "            lbl = widgets.Label(ch)\n",
    "            def make_rm(target=ch):\n",
    "                def _(_b):\n",
    "                    if target in chosen:\n",
    "                        chosen.remove(target)\n",
    "                        refresh_chosen_box()\n",
    "                return _\n",
    "            rm_btn.on_click(make_rm())\n",
    "            rows.append(widgets.HBox([rm_btn, lbl]))\n",
    "        chosen_box.children = rows\n",
    "\n",
    "    # Add channel from combobox\n",
    "    def on_add(_):\n",
    "        ch = (combo.value or \"\").strip()\n",
    "        if not ch:\n",
    "            return\n",
    "        # Deduplicate\n",
    "        if ch not in chosen:\n",
    "            chosen.append(ch)\n",
    "            chosen.sort()\n",
    "            refresh_chosen_box()\n",
    "        combo.value = \"\"  # clear input for next entry\n",
    "\n",
    "    add_btn.on_click(on_add)\n",
    "\n",
    "    # Enable/disable custom area by mode\n",
    "    def set_custom_enabled(enabled: bool):\n",
    "        combo.disabled = not enabled\n",
    "        add_btn.disabled = not enabled\n",
    "        # You can still view/remove chosen even if disabled; leave chosen_box enabled.\n",
    "\n",
    "    def on_mode_change(change):\n",
    "        if change[\"name\"] == \"value\":\n",
    "            m = change[\"new\"]\n",
    "            if m == \"none\":\n",
    "                info.value = \"<i>No re-referencing will be applied for this configuration.</i>\"\n",
    "                set_custom_enabled(False)\n",
    "            elif m == \"average\":\n",
    "                info.value = \"<i>MNE: <code>raw.set_eeg_reference('average')</code>.</i>\"\n",
    "                set_custom_enabled(False)\n",
    "            else:\n",
    "                info.value = \"<i>Pick one or more channels to use as reference (MNE: <code>raw.set_eeg_reference(ref_channels=[...])</code>).</i>\"\n",
    "                set_custom_enabled(True)\n",
    "\n",
    "    mode.observe(on_mode_change, names=\"value\")\n",
    "    set_custom_enabled(False)  # start in \"none\"\n",
    "\n",
    "    right_top = widgets.VBox([mode, info])\n",
    "    right_custom = widgets.VBox([\n",
    "        widgets.HBox([combo, add_btn]),\n",
    "        chosen_label,\n",
    "        chosen_box\n",
    "    ])\n",
    "    right_box = widgets.VBox([right_top, right_custom], layout=widgets.Layout(width=\"50%\"))\n",
    "\n",
    "    # Store state (chosen list lives in closure but also store handle for save)\n",
    "    state_by_cfg[cfg_label] = {\n",
    "        \"mode\": mode,\n",
    "        \"combo\": combo,\n",
    "        \"add_btn\": add_btn,\n",
    "        \"chosen_list_ref\": chosen,   # the Python list to read at save time\n",
    "        \"config_channels\": cfg_channels,\n",
    "        \"info\": info\n",
    "    }\n",
    "\n",
    "    return widgets.HBox([left_box, right_box], layout=widgets.Layout(gap=\"16px\", align_items=\"flex-start\"))\n",
    "\n",
    "# Build accordion\n",
    "panels = [build_panel_for_config(cfg) for cfg in config_labels]\n",
    "acc_reref = widgets.Accordion(children=panels)\n",
    "for i, cfg in enumerate(config_labels):\n",
    "    acc_reref.set_title(i, f\"{cfg} ‚Äî re-reference\")\n",
    "display(acc_reref)\n",
    "\n",
    "# Save button\n",
    "btn_save_plan = widgets.Button(description=\"Save re-reference\", button_style=\"success\", icon=\"save\", layout=widgets.Layout(width='150px'))\n",
    "out_plan = widgets.Output()\n",
    "display(widgets.HBox([btn_save_plan]), out_plan)\n",
    "\n",
    "def validate_choice(cfg_label, mode, ref_chans, cfg_channels):\n",
    "    \"\"\"Return (ok, message). Warn if custom refs not present in this config.\"\"\"\n",
    "    if mode == \"custom\":\n",
    "        if len(ref_chans) == 0:\n",
    "            return False, \"Please add at least one reference channel for 'Custom' mode.\"\n",
    "        missing = [ch for ch in ref_chans if ch not in cfg_channels]\n",
    "        if missing:\n",
    "            return False, f\"Some chosen reference channels are not in this configuration: {missing}\"\n",
    "    return True, mode\n",
    "\n",
    "def on_save_plan(_=None):\n",
    "    \"\"\"\n",
    "    Build a dict ready for MNE re-referencing, per configuration:\n",
    "      - 'none'\n",
    "      - 'average'\n",
    "      - 'custom' + ref_channels: [...]\n",
    "    Export JSON for later reuse.\n",
    "    \"\"\"\n",
    "    plan = {}\n",
    "    messages = []\n",
    "    ok_all = True\n",
    "\n",
    "    for cfg in config_labels:\n",
    "        st = state_by_cfg[cfg]\n",
    "        mode = st[\"mode\"].value\n",
    "        refs = list(st[\"chosen_list_ref\"])  # copy\n",
    "        cfg_chs = st[\"config_channels\"]\n",
    "\n",
    "        ok, msg = validate_choice(cfg, mode, refs, cfg_chs)\n",
    "        if not ok:\n",
    "            ok_all = False\n",
    "        messages.append(f\"{cfg}: {msg}\")\n",
    "\n",
    "        if mode == \"none\":\n",
    "            spec = {\"ref_channels\": []}\n",
    "        elif mode == \"average\":\n",
    "            spec = {\"ref_channels\": \"average\"}\n",
    "        else:\n",
    "            spec = {\"ref_channels\": refs}\n",
    "\n",
    "        plan[cfg] = spec\n",
    "\n",
    "    globals()[\"reref_plan_by_config\"] = plan\n",
    "\n",
    "    # Export JSON\n",
    "    try:\n",
    "        out_json = os.path.join(config_param_path, \"mne_reref_plan.json\")\n",
    "        with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(plan, f, indent=2, ensure_ascii=False)\n",
    "        saved_msg = f\"Saved JSON:\\n  - {out_json}\"\n",
    "    except Exception as e:\n",
    "        saved_msg = f\"(JSON export skipped: {e})\"\n",
    "\n",
    "    with out_plan:\n",
    "        clear_output()\n",
    "        print(\"‚úÖ Re-reference plan saved to variable: reref_plan_by_config\")\n",
    "        print(saved_msg)\n",
    "        print(\"\\nSummary:\")\n",
    "        for m in messages:\n",
    "            print(\" - \" + m)\n",
    "        if not ok_all:\n",
    "            print(\"\\n‚ö†Ô∏è Please fix the warnings above before applying to MNE.\")\n",
    "\n",
    "btn_save_plan.on_click(on_save_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2544aaa-adc1-4b78-a15f-621749d1ca01",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365de2d-a828-436d-b099-2b3217b51432",
   "metadata": {},
   "source": [
    "## 5. Preview and save JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f74feb-abfb-47bc-a831-8e3f88d6f92f",
   "metadata": {},
   "source": [
    "The code cell below will open a widget to preview the resulting file and save it.\n",
    "- Name the file as you please.\n",
    "- Click on \"Preview\" to display the first rows of the file. You can inspect if it corresponds to your expectations. \n",
    "- Click on the \"Save\" button to save the .json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4f1d1-a82c-448d-8973-257e37fbb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Widget minimaliste : aper√ßu JSON exact + sauvegarde forc√©e ===\n",
    "# Pr√©requis dans l'environnement :\n",
    "# - ch_config_dict : { tuple(sorted(set(raw_channels))) : [list_of_subjects] }\n",
    "# - configs        : list(tuple(...))          # m√™me ordre que config_labels\n",
    "# - config_labels  : list[str]                  # ex. \"config. 1 (n=26)\"\n",
    "# - remap_by_config: { \"config. i (n=‚Ä¶)\" : {raw_channel: canonical_channel, ...} }\n",
    "# - (optionnel) reref_plan_by_config : { \"config. i (n=‚Ä¶)\" : {\"ref_channels\": ...} }\n",
    "# - config_param_path : dossier o√π sauvegarder le JSON\n",
    "\n",
    "# ---------- logique de construction ----------\n",
    "def _as_label_per_config(configs, config_labels):\n",
    "    if len(configs) != len(config_labels):\n",
    "        raise RuntimeError(\n",
    "            \"Inconsistency: 'configs' and 'config_labels' have different lengths.\"\n",
    "        )\n",
    "    return {tuple(cfg): lab for cfg, lab in zip(configs, config_labels)}\n",
    "\n",
    "def _subject_to_config_label(ch_config_dict, cfg2label):\n",
    "    out = {}\n",
    "    for cfg_tuple, subs in ch_config_dict.items():\n",
    "        lab = cfg2label.get(tuple(cfg_tuple))\n",
    "        if lab is None:\n",
    "            # tol√©rance √† l‚Äôordre: on tente la correspondance par set-√©galit√©\n",
    "            set_cfg = set(cfg_tuple)\n",
    "            for k_tuple, k_lab in cfg2label.items():\n",
    "                if set(k_tuple) == set_cfg:\n",
    "                    lab = k_lab\n",
    "                    break\n",
    "            if lab is None:\n",
    "                raise KeyError(f\"Config tuple not found in the mapping configs‚Üílabels:\\n{cfg_tuple}\")\n",
    "        for s in subs:\n",
    "            out[s] = lab\n",
    "    return out\n",
    "\n",
    "def _normalize_ref_value(ref_value):\n",
    "    if isinstance(ref_value, list):\n",
    "        if len(ref_value) == 0:\n",
    "            return []\n",
    "        if len(ref_value) == 1:\n",
    "            return [ref_value[0]]\n",
    "        return ref_value\n",
    "    return ref_value  # 'average' ou autre cha√Æne\n",
    "\n",
    "def build_per_subject_dict():\n",
    "    needed = [\"ch_config_dict\", \"configs\", \"config_labels\", \"remap_by_config\", \"config_param_path\"]\n",
    "    missing = [v for v in needed if v not in globals()]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing(s) variable(s): {', '.join(missing)}\")\n",
    "    if not os.path.isdir(config_param_path):\n",
    "        raise RuntimeError(f\"'config_param_path' is not a valid folder: {config_param_path}\")\n",
    "\n",
    "    cfg2label = _as_label_per_config(configs, config_labels)\n",
    "    subject_to_cfg_label = _subject_to_config_label(ch_config_dict, cfg2label)\n",
    "\n",
    "    per_subject = OrderedDict()\n",
    "    for sub, cfg_label in sorted(subject_to_cfg_label.items(), key=lambda kv: kv[0]):\n",
    "        remap_map = remap_by_config.get(cfg_label, {})\n",
    "        if \"reref_plan_by_config\" in globals():\n",
    "            ref_spec = reref_plan_by_config.get(cfg_label, {\"ref_channels\": []})\n",
    "            ref_val = _normalize_ref_value(ref_spec.get(\"ref_channels\", []))\n",
    "        else:\n",
    "            ref_val = None\n",
    "\n",
    "        # Compacte toujours le label de config\n",
    "        cfg_compact = re.sub(r\"\\s*\\(n=\\d+\\)\\s*$\", \"\", cfg_label)\n",
    "\n",
    "        per_subject[sub] = {\n",
    "            \"config\": cfg_compact,\n",
    "            \"remap\": remap_map,\n",
    "            \"ref_channels\": ref_val\n",
    "        }\n",
    "    return per_subject\n",
    "\n",
    "# ---------- UI ----------\n",
    "title = widgets.HTML(\"<h3>Participant ‚Üí {config, remap, ref_channels}</h3>\")\n",
    "fname_text = widgets.Text(value=\"remap_reref_persubject.json\", description=\"Fichier:\", layout=widgets.Layout(width=\"420px\"))\n",
    "\n",
    "btn_preview = widgets.Button(description=\"Preview\", button_style=\"info\", icon=\"eye\")\n",
    "btn_save = widgets.Button(description=\"Save\", button_style=\"success\", icon=\"save\", disabled=True)\n",
    "\n",
    "preview_out = widgets.Output(layout=widgets.Layout(border=\"1px solid #444\", padding=\"6px\", max_height=\"360px\", overflow=\"auto\"))\n",
    "status_out = widgets.Output()\n",
    "\n",
    "_state = {\"dict\": None, \"path\": None, \"json_text\": None}\n",
    "\n",
    "def _render_json_block(json_text, max_lines=41):\n",
    "    \"\"\"\n",
    "    Affiche seulement les `max_lines` premi√®res lignes du JSON\n",
    "    pour √©viter d'alourdir le widget quand il est tr√®s gros.\n",
    "    \"\"\"\n",
    "    lines = json_text.splitlines()\n",
    "    if len(lines) > max_lines:\n",
    "        preview = \"\\n\".join(lines[:max_lines]) + f\"\\n... ({len(lines)-max_lines} lignes suppl√©mentaires masqu√©es)\"\n",
    "    else:\n",
    "        preview = json_text\n",
    "    style = \"margin:0; white-space:pre; font-family:Menlo,Consolas,monospace; font-size:12px;\"\n",
    "    return f\"<pre style='{style}'>{preview}</pre>\"\n",
    "\n",
    "def _make_preview():\n",
    "    d = build_per_subject_dict()\n",
    "    out_json = os.path.join(config_param_path, fname_text.value.strip() or \"remap_reref_persubject.json\")\n",
    "    json_text = json.dumps(d, indent=2, ensure_ascii=False)\n",
    "    _state.update(dict(dict=d, path=out_json, json_text=json_text))\n",
    "\n",
    "@btn_preview.on_click\n",
    "def _on_preview(_):\n",
    "    preview_out.clear_output()\n",
    "    status_out.clear_output()\n",
    "    try:\n",
    "        _make_preview()\n",
    "        with preview_out:\n",
    "            display(HTML(f\"<p style='margin:0 0 6px 0'><b>JSON will be saved here :</b> <code>{_state['path']}</code></p>\"))\n",
    "            display(HTML(_render_json_block(_state[\"json_text\"])))\n",
    "        btn_save.disabled = False\n",
    "    except Exception as e:\n",
    "        btn_save.disabled = True\n",
    "        with preview_out:\n",
    "            display(HTML(f\"<pre style='color:#c33'>{type(e).__name__}: {e}</pre>\"))\n",
    "\n",
    "@btn_save.on_click\n",
    "def _on_save(_):\n",
    "    status_out.clear_output()\n",
    "    if not _state.get(\"dict\") or not _state.get(\"path\"):\n",
    "        with status_out:\n",
    "            display(HTML(\"<span style='color:#c33'>Click first on <b>Preview</b>.</span>\"))\n",
    "        return\n",
    "    out_json = _state[\"path\"]\n",
    "    STATE.json_path = out_json\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(out_json), exist_ok=True)\n",
    "        with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(_state[\"json_text\"])\n",
    "        with status_out:\n",
    "            display(HTML(f\"<span style='color:#2b8a3e'>‚úÖ JSON saved (overwrite) : <code>{out_json}</code></span>\"))\n",
    "            display(HTML(f\"<br>To load your file, use these coding lines:\"))\n",
    "            display(HTML(f\"<p>- <code>json_path = {out_json}</code></p>\"))\n",
    "            display(HTML(f\"<p>- <code>with open(json_path, 'r', encoding='utf-8') as f: config_dict = json.load(f)</code></p>\"))\n",
    "            display(HTML(f\"<br>To select the info of a participant:\"))\n",
    "            display(HTML(f\"<p>- <code>file_ID = os.path.basename(edf_path).split('.')[0]</code></p>\"))\n",
    "            display(HTML(f\"<p>- <code>sub_config = config_dict[file_ID]</code></p>\"))\n",
    "            display(HTML(f\"<br>To load the data with only the selected channels:\"))\n",
    "            display(HTML(f\"<p>- <code>raw = mne.io.read_raw_edf(edf_path, preload=True, include=list(sub_config['remap'].keys()))</code></p>\"))\n",
    "            display(HTML(f\"<br>To rename the selected channels:\"))\n",
    "            display(HTML(f\"<p>- <code>raw.rename_channels(sub_config['remap'])</code></p>\"))\n",
    "            display(HTML(f\"<br>To apply the re-reference method:\"))\n",
    "            display(HTML(f\"<p>- <code>raw.set_eeg_reference(ref_channels = sub_config['ref_channels'])</code></p>\"))\n",
    "            display(HTML(f\"<p>- <code>raw.drop_channels(sub_config['ref_channels'])</code></p>\"))\n",
    "\n",
    "        globals()[\"per_subject_dict\"] = _state[\"dict\"]\n",
    "    except Exception as e:\n",
    "        with status_out:\n",
    "            display(HTML(f\"<pre style='color:#c33'>{type(e).__name__}: {e}</pre>\"))\n",
    "\n",
    "# ---------- agencement ----------\n",
    "controls = widgets.HBox([fname_text, btn_preview, btn_save])\n",
    "box = widgets.VBox([title, controls, preview_out, status_out])\n",
    "display(box)\n",
    "\n",
    "# Pour g√©n√©rer automatiquement l'aper√ßu √† l'ex√©cution :\n",
    "# _on_preview(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46c8f3-0605-4728-8fa7-8a77ea0ca167",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2d34e-90fb-4f98-bab7-71ad94a082df",
   "metadata": {},
   "source": [
    "## 6. Test the JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a432f-dca6-42e4-a613-2c98244cd6c6",
   "metadata": {},
   "source": [
    "The code cell below will loop across your database and apply the remapping and re-reference.\n",
    "It will return errors if it does not succeed on some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2f122-7c67-461e-9389-6402e949887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the remapping for the full dataset\n",
    "\n",
    "# define custom functions to take into account duplicate channels that will be labelled XX-0 and XX-1 by mne\n",
    "# we keep only the XX-0 and then re-define a dict to select the XX-0 instead of XX\n",
    "# this is necessary for APOMORPHE database\n",
    "def drop_suffix_duplicates(raw):\n",
    "    \"\"\"\n",
    "    Rep√®re les channels de type 'XXX-0', 'XXX-1', ...\n",
    "    et ne garde que les '-0' lorsqu'ils coexistent.\n",
    "    \n",
    "    Exemple :\n",
    "    - ['C4-0', 'C4-1', 'F4', 'O2'] -> on drop 'C4-1'\n",
    "    - ['C4-1'] tout seul -> on ne drop rien.\n",
    "    \"\"\"\n",
    "    ch_names = raw.ch_names\n",
    "    # regroupement par 'base', ex: C4-0 -> base = C4\n",
    "    groups = {}\n",
    "    for ch in ch_names:\n",
    "        if ch.endswith('-0') or ch.endswith('-1'):\n",
    "            base = ch.rsplit('-', 1)[0]\n",
    "            groups.setdefault(base, []).append(ch)\n",
    "\n",
    "    to_drop = []\n",
    "    for base, ch_list in groups.items():\n",
    "        zeros = [c for c in ch_list if c.endswith('-0')]\n",
    "        if zeros:\n",
    "            # si un '-0' existe, on drop tous les autres suffix√©s (typiquement les '-1')\n",
    "            for c in ch_list:\n",
    "                if not c.endswith('-0'):\n",
    "                    to_drop.append(c)\n",
    "\n",
    "    if to_drop:\n",
    "        print(\"üîé Channels suffix√©s trouv√©s, on va drop : \", to_drop)\n",
    "        raw.drop_channels(to_drop)\n",
    "    else:\n",
    "        print(\"‚úÖ Aucun doublon '-0'/'-1' √† nettoyer\")\n",
    "\n",
    "    return raw, to_drop\n",
    "\n",
    "def adapt_remap_dict_to_suffixes(raw, remap_dict):\n",
    "    \"\"\"\n",
    "    Adapte un remap_dict de la forme {\"C4\": \"C\", \"F4\": \"F\", ...}\n",
    "    aux noms de channels r√©ellement pr√©sents dans raw.ch_names,\n",
    "    en rempla√ßant par exemple \"C4\" -> \"C4-0\" si \"C4\" n'existe pas\n",
    "    mais \"C4-0\" oui.\n",
    "\n",
    "    Retourne un nouveau dict pr√™t pour raw.rename_channels().\n",
    "    \"\"\"\n",
    "    ch_set = set(raw.ch_names)\n",
    "    new_remap = {}\n",
    "\n",
    "    for base_label, target in remap_dict.items():\n",
    "        if base_label in ch_set:\n",
    "            # Cas simple : le label existe tel quel dans raw.ch_names\n",
    "            new_remap[base_label] = target\n",
    "        else:\n",
    "            # Cas suffix√© : essayer base_label-0\n",
    "            candidate = f\"{base_label}-0\"\n",
    "            if candidate in ch_set:\n",
    "                new_remap[candidate] = target\n",
    "            # sinon : on ignore ce label (aucun ch correspondant)\n",
    "\n",
    "    return new_remap\n",
    "# load the output (dictionary) of the notebook\n",
    "# json_path = _state['path']  # ton chemin complet\n",
    "json_path = STATE.json_path  # ton chemin complet\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Initialize an empty list for files that could not be read\n",
    "failed_file_list = []\n",
    "\n",
    "# Initialize empty list for channels\n",
    "remap_channels_list = []\n",
    "raw_channels_list = []\n",
    "check_ref_before = []\n",
    "check_ref_after = []\n",
    "\n",
    "# initialize a dynamic output\n",
    "output_remap = \"\"\n",
    "dynamic_remap_out = widgets.Output()\n",
    "display(dynamic_remap_out)\n",
    "# define a function to update the dynamic output\n",
    "def update_scrollbox():\n",
    "    \"\"\"Rafra√Æchit la scrollbox avec le contenu de output_remap.\"\"\"\n",
    "    with dynamic_remap_out:\n",
    "        dynamic_remap_out.clear_output(wait=True)\n",
    "        print_in_scrollable_box(output_remap, font_size=\"12px\")\n",
    "\n",
    "# init mne_output\n",
    "loop_out = widgets.Output()        # sorties MNE temporaires\n",
    "display(loop_out)\n",
    "\n",
    "with loop_out:\n",
    "    # for e, edf_path in enumerate(edf_files):\n",
    "    for e, edf_path in enumerate(SATE.edf_files):\n",
    "        loop_out.clear_output(wait=True)\n",
    "        # output_remap += (f'file {e+1}/{len(edf_files)}, currently remapping: {edf_path}\\n')\n",
    "        output_remap += (f'file {e+1}/{len(STATE.edf_files)}, currently remapping: {edf_path}\\n')\n",
    "        update_scrollbox()\n",
    "            \n",
    "        # read file with the custom function\n",
    "        try:\n",
    "            # extract file ID to get info from the dict\n",
    "            # file_name = os.path.basename(raw_fn)  # Ex: \"15_N1.edf\"\n",
    "            file_ID = os.path.basename(edf_path).split('.')[0]  # Extrait \"15_N1\"\n",
    "\n",
    "            try:\n",
    "                sub_config = config_dict[file_ID]\n",
    "            except KeyError:\n",
    "                err = f\"\\t‚ùå File ID {file_ID} was not found in the remapping dictionary\\n\"\n",
    "                output_remap += err\n",
    "                update_scrollbox()\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                err = f\"\\t‚ùå Unexpected problem with the remapping dictionary and file ID {file_ID}: {e}\\n\"\n",
    "                output_remap += err\n",
    "                update_scrollbox()\n",
    "                continue\n",
    "\n",
    "            selected_channels = list(sub_config[\"remap\"].keys())\n",
    "\n",
    "            # load edf as mne raw object\n",
    "            try:\n",
    "                raw = mne.io.read_raw_edf(edf_path, preload=True, include=selected_channels) # we need to preload to use  re-ref; old param from Thomas encoding=\"latin-1\", \n",
    "            except Exception:\n",
    "                err = f\"\\t‚ùå Unexpected problem in loading edf file with mne: {e}\\n\"\n",
    "                output_remap += err\n",
    "                update_scrollbox()\n",
    "                continue\n",
    "\n",
    "            # save original raw channels\n",
    "            raw_channels_list.append(raw.ch_names)\n",
    "            check_ref_before.append(raw.info['custom_ref_applied'])\n",
    "\n",
    "            # remove duplicates channels\n",
    "            raw, dropped = drop_suffix_duplicates(raw)\n",
    "\n",
    "            # remap dict to take into account XX-0 created by mne for duplicates\n",
    "            remap_dict_adapted = adapt_remap_dict_to_suffixes(raw, sub_config[\"remap\"])\n",
    "\n",
    "            # remap channels (based on the generated dict from jupy notebook):\n",
    "            raw.rename_channels(remap_dict_adapted)\n",
    "            \n",
    "            # set eeg reference\n",
    "            if  sub_config[\"ref_channels\"] != 'average':\n",
    "                raw.set_eeg_reference(ref_channels = sub_config[\"ref_channels\"])\n",
    "                # get rid of the ref\n",
    "                raw.drop_channels(sub_config[\"ref_channels\"])\n",
    "            else:\n",
    "                raw.set_eeg_reference(ref_channels = sub_config[\"ref_channels\"])\n",
    "\n",
    "            remap_channels_list.append(raw.ch_names)\n",
    "            check_ref_after.append(raw.info['custom_ref_applied'])\n",
    "\n",
    "\n",
    "            del raw\n",
    "\n",
    "        except Exception as e:\n",
    "            err = f\"\\t‚ùå Unexpected problem for {edf_path} : {e}\\n\"\n",
    "            output_remap += err\n",
    "            update_scrollbox()\n",
    "            failed_file_list.append((edf_path, 'other'))\n",
    "    loop_out.clear_output()\n",
    "\n",
    "# check the remapping\n",
    "unique_ch = list({tuple(sorted(x)) for x in raw_channels_list})\n",
    "unique_remap = list({tuple(sorted(x)) for x in remap_channels_list})\n",
    "print(f\"Possible channels configurations before remapping: {len(unique_ch)}\") # can be different than the number of configurations earlier because it is for the selected channels \n",
    "for c, chs in enumerate(unique_ch):\n",
    "    print(f\"\\t{chs}\")\n",
    "print(f\"\\nPossible channels configurations after remapping: {len(unique_remap)}\")\n",
    "for c, chs in enumerate(unique_remap):\n",
    "    print(f\"\\t{chs}\")\n",
    "\n",
    "if len(unique_remap) == 1:\n",
    "    print(f\"\\n‚úîÔ∏è The remapping worked ! You can safely use the remapping dictionary for your analyses.\")\n",
    "elif len(unique_remap) > 1:\n",
    "    print(f\"\\n‚ùå The remapping failed. There is still multiple channels configurations.\")\n",
    "elif len(unique_remap) < 1:\n",
    "    print(f\"\\n‚ùå The remapping failed. There is no channels configuration left.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå The remapping failed. Unknown error.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
