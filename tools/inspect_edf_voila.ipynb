{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9897bd26-bb07-41a0-a694-1950c87e8b5d",
   "metadata": {},
   "source": [
    "# Inspect export parameters from .edf files of an EEG database \n",
    "This notebook allows you to inspect the parameters of your .edf EEG database. \\\n",
    "It does not load and inspect the quality of your data. \\\n",
    "It helps you identify if you need to re-export some participant's data (due to poor signal resolution or clipping, as explained later). \\\n",
    "It provides information that helps analyze your dataset (such as the different channel labels, sampling frequency, and filters). \n",
    "\n",
    "---\n",
    "EDF (European Data Format) is a standard format for storing multichannel biological and physical signals: https://www.edfplus.info/. \\\n",
    "It was first published in 1992, and an upgraded version was released in 2003 (adding discontinuous recordings handling, annotations, stimuli, and events in a UTF-8 format). \\\n",
    "It is a compressed 16-bit format, meaning that each measured data point can take 2¹⁶ values between the minimum and maximum values that you set at exportation. \\\n",
    "The min/max values correspond to the dynamic range of your data.\n",
    "\n",
    "---\n",
    "At the exportation in the .edf format (with software like Profusion from Compumedics), many parameters need to be set per recorded channels, such as channels' label, sampling frequency, filtering, units, and dynamic range. \\\n",
    "Exporting as .edf format is tedious and time-consuming, so mistakes in parameters can easily be made.  \\\n",
    "To avoid making mistakes, there is the possibility of implementing montage within some software that will apply your  pre-defined parameters directly **(insert a link on how to make a routine in Compumedics).** \\\n",
    "Inspecting those parameters can also be necessary if you work on an already existing dataset, to make sure that every participant's data is exploitable, specifically if the data comes from multiple sleep clinics. \n",
    "\n",
    "---\n",
    "This notebook reads information from the .edf files, instead of loading the data and relying on existing packages. \\\n",
    "Existing packages, such as PYEDFLIB or MNE, are either too rigid (not able to read some data) or do not return all the information (such as boundaries of dynamic range, filtering parameters, etc).\\\n",
    "\\\n",
    "**This notebook is intended to stand alone, you just have to run it with the package voila.\\\n",
    "In your terminal, run `voila inspect_edf_voila` to start the notebook.\\\n",
    "Then, you will just have to select your database folder and read the outputs.**\\\n",
    "_The notebook will save summary tables as .tsv files (file format easy to read with Excel and to import in Python script) so that you can visually inspect (or reload later) if needed._\\\n",
    "_Those summaries will be stored in a summary folder within the study folder._\\\n",
    "\\\n",
    "This notebook is organized into 4 sections:\n",
    "1. Select your study folder, extract the data's information, and return general information\n",
    "2. Inspect EEG channels\n",
    "3. Inspect EOG channels\n",
    "4. Inspect ECG channels\n",
    "\n",
    "_A Jupyter notebook version exists in order to easily interact with the code_\n",
    "\n",
    "---\n",
    "This notebook was developed on the ICEBERG database and tested on APOMORPHEE (from Noémie's internship).  \\\n",
    "last update 16/09/2025, YN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed075be-fb44-486f-b0b0-75f19b7ba68f",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">\n",
    "First, let's check if you have already installed the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb93176-9fd2-4035-ad97-43cd44ee6cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import packages and define custom functions\n",
    "# Import cell\n",
    "try:\n",
    "    import os\n",
    "    import re\n",
    "    import chardet\n",
    "    import warnings\n",
    "    import traceback\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import ipywidgets as widgets\n",
    "    from ipyfilechooser import FileChooser\n",
    "    from IPython.display import display, HTML\n",
    "except ImportError as e:\n",
    "    print(\"⚠️ Error: \", e)\n",
    "else:\n",
    "    print(\"✅ Packages and functions successfully imported!\")\n",
    "\n",
    "# custom function to detect automatically and return the encoding of edf file\n",
    "def detect_encoding(byte_string, min_confidence=0.6):\n",
    "    result = chardet.detect(byte_string)\n",
    "    encoding = result['encoding']\n",
    "    confidence = result['confidence']\n",
    "    if encoding is None or confidence < min_confidence:\n",
    "        raise UnicodeDecodeError(\"chardet\", byte_string, 0, len(byte_string),\n",
    "                                 f\"\\tUnable to reliably detect encoding. Detected: {encoding} with confidence {confidence}\")\n",
    "    return encoding\n",
    "\n",
    "# custom function to read information from EDF headers, without using the pyedflib package (that was too strict for ICEBERG)\n",
    "# EDF file should follow a strict format, dedicating a specific number of octets for each type of information.\n",
    "# it means that we can read the info octet by octet by specifying the number of octets we expect for the next variable (that is known from the EDF norm)\n",
    "def read_edf_header_custom(file_path):\n",
    "    with open(file_path, 'rb') as f: # open the file in binary mode, to read octet by octet. \n",
    "        header = {}\n",
    "        # detect encoding\n",
    "        raw_header = f.read(256)\n",
    "        encoding = detect_encoding(raw_header)\n",
    "        # print(f\"\\tDetected encoding for {file_path} : {encoding}\")\n",
    "        # Rewind to the beginning of the file\n",
    "        f.seek(0)\n",
    "        \n",
    "        # the first 256 octets are global subject info\n",
    "        header['version'] = f.read(8).decode(encoding).strip()\n",
    "        header['patient_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['recording_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['start_date'] = f.read(8).decode(encoding).strip()\n",
    "        header['start_time'] = f.read(8).decode(encoding).strip()\n",
    "        header['header_bytes'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['reserved'] = f.read(44).decode(encoding).strip()\n",
    "        header['n_data_records'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['duration_data_record'] = float(f.read(8).decode(encoding).strip())\n",
    "        header['n_channels'] = int(f.read(4).decode(encoding).strip())\n",
    "        \n",
    "        # get info per channel\n",
    "        n = header['n_channels']\n",
    "        channel_fields = {\n",
    "            'channel': [],\n",
    "            'transducer_type': [],\n",
    "            'dimension': [],\n",
    "            'physical_min': [],\n",
    "            'physical_max': [],\n",
    "            'digital_min': [],\n",
    "            'digital_max': [],\n",
    "            'prefiltering': [],\n",
    "            'sampling_frequency': [],\n",
    "            'reserved': [],\n",
    "        }\n",
    "\n",
    "        for key in channel_fields:\n",
    "            length = {\n",
    "                'channel': 16,\n",
    "                'transducer_type': 80,\n",
    "                'dimension': 8,\n",
    "                'physical_min': 8,\n",
    "                'physical_max': 8,\n",
    "                'digital_min': 8,\n",
    "                'digital_max': 8,\n",
    "                'prefiltering': 80,\n",
    "                'sampling_frequency': 8,\n",
    "                'reserved': 32,\n",
    "            }[key]\n",
    "            channel_fields[key] = [f.read(length).decode(encoding).strip() for _ in range(n)]\n",
    "\n",
    "        header.update(channel_fields)\n",
    "    \n",
    "    return header\n",
    "\n",
    "# function to extract filter information from the string in headers\n",
    "def extract_filter_value(s, tag):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(rf'{tag}[:\\s]*([\\d\\.]+)\\s*', s, re.IGNORECASE)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# custom function to get the sampling frequency out of a dataframe (the df needs to have 'subject' and 'channel' as columns)\n",
    "def get_sf(df, subject, channel):\n",
    "    df_sf = df[(df['subject'] == subject) & (df['channel'] == channel)]\n",
    "    if not df_sf.empty:\n",
    "        return df_sf.iloc[0]['sampling_frequency']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# function to create a widget slider to select the configuration to inspect\n",
    "def mk_config_slider(value = 1, min = 1, max = 5):\n",
    "    config_slider = widgets.IntSlider(\n",
    "    value=value,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    step=1,\n",
    "    description='Selected configuration:',\n",
    "    style={'description_width': '150px'},   # increase description width (to adjust based on the description)\n",
    "    layout=widgets.Layout(width='400px'),   # to adjust widget size\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    "    )\n",
    "    return config_slider\n",
    "\n",
    "# function to print the configuration of a dataset parameter\n",
    "def print_config(i, config_dict, param):\n",
    "    # get the key and value from the dictionary\n",
    "    idx = i - 1\n",
    "    # get participant ID\n",
    "    value = list(config_dict.values())  \n",
    "    v = value[idx]  \n",
    "    # get configuration\n",
    "    key = list(config_dict.keys())\n",
    "    k = key[idx]\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {i}')\n",
    "    print(f'\\t{len(k)} {param}: {k}')\n",
    "    print(f'\\t{len(v)} participants: {v}')\n",
    "\n",
    "# function to create a scrollable box for long output (e.g., cell loading the data) \n",
    "def print_in_scrollable_box(text, height=300, font_size=\"12px\"):\n",
    "    display(HTML(f'<pre style=\"overflow-y:scroll; height:{height}px; border:1px solid black; padding:10px; font-size:{font_size};\">{text}</pre>'))\n",
    "\n",
    "\n",
    "#%% select data folder (the rest of the code will be encapsulated in the folder selection so that voila waits for the selection to run the rest of cells)\n",
    "# folder selector\n",
    "chooser = FileChooser(os.getcwd())\n",
    "chooser.title = \"<b>Choose your study folder</b>\"\n",
    "chooser.show_only_dirs = True\n",
    "\n",
    "# validation button\n",
    "run_button = widgets.Button(description=\"Start the inspection\", button_style='success')\n",
    "\n",
    "# result display area\n",
    "out = widgets.Output()\n",
    "\n",
    "section1 = widgets.HTML(\"\"\"\n",
    "<hr style=\"height:4px; background-color:black; border:none;\">\n",
    "<h2>1. Select your data folder</h2>\n",
    "\"\"\")\n",
    "display(section1)\n",
    "\n",
    "# main function to run the inspection when a folder have been selected\n",
    "def run_inspection(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        chooser.folder_path = chooser.selected_path\n",
    "        print(\"📁 Selected Path:\", chooser.folder_path)\n",
    "        \n",
    "        # get the edf file list \n",
    "        chooser.edf_files = [\n",
    "            f for f in Path(chooser.folder_path).rglob('*.edf')\n",
    "            if not f.name.startswith('._') # don't select files starting with ._ (that can be found in mac for example)\n",
    "            ]\n",
    "        if not chooser.edf_files:\n",
    "            print(f\"⚠️ There is no .edf file in your folder\")\n",
    "        else:\n",
    "            print(f\"\\nThere is {len(chooser.edf_files)} .edf files in your folder!\")\n",
    "        \n",
    "        # check the existence and/or create the summary folder that will receive the summary tables and the report\n",
    "        chooser.summary_path = f'{chooser.folder_path}/summary'\n",
    "        if not os.path.exists(chooser.summary_path):\n",
    "            os.makedirs(chooser.summary_path)\n",
    "            print(\"\\nCreated summary folder at: \" + chooser.summary_path)\n",
    "        else:\n",
    "            print(\"\\nSummary folder already exists. \\nPrevious summary tables (if any) will be overwritten at: \\n\" + chooser.summary_path)\n",
    "\n",
    "        # get variables from the chooser widget\n",
    "        folder_path = chooser.folder_path\n",
    "        summary_path = chooser.summary_path\n",
    "        edf_files = chooser.edf_files\n",
    "\n",
    "        # check if there is a participants.tsv file to get different groups or sessions\n",
    "        # if there is not a participants.tsv we will try to infer groups from subfolder organization or filename components (additional part from subject number)\n",
    "        # in ICEBERG, subfolders define groups within the data folder\n",
    "        # in APOMORPHEE, suffixes define nights (\"session\") \n",
    "        table_found = False\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            if 'participants.tsv' in files:\n",
    "                table_found = True        \n",
    "                print(f\"Table containing participants information found at: {os.path.join(root, 'participants.tsv')} \")\n",
    "                subj_table_path = os.path.join(root, 'participants.tsv')\n",
    "        \n",
    "        found_group = False\n",
    "        if table_found:\n",
    "            subj_table = pd.read_csv(subj_table_path, sep = '\\t', dtype={'participant_id': str, 'group': str})\n",
    "            if \"group\" in subj_table.columns:\n",
    "                found_group = True\n",
    "                print(f\"We will extract participant's group from it\")\n",
    "            else:\n",
    "                print(f\"No column 'group' was found in the table\")\n",
    "                print(f\"Group will be inferred from subfolder organization or subfolder component\") \n",
    "            \n",
    "        else:\n",
    "            print(f\"No table containing participants information (labelled 'participants.tsv') was found\")\n",
    "            print(f\"If you have a table, please rename it 'participants.tsv' (and make sure you have columns labelled 'participant_id' and 'group' if any)\")\n",
    "            print(f\"In the meantime, we will infer participant's group from subfolder organization or filename component\")\n",
    "            subj_table = pd.DataFrame()\n",
    "\n",
    "        # initialyse list of dataframe to store file info, that will be concatenated at the end (this is better for performance)\n",
    "        df_list = []\n",
    "        # Initialize an empty list for files that could not be read\n",
    "        failed_list = []\n",
    "        # initialize output for a dynamic display (with a scroll box)\n",
    "        output = \"\"\n",
    "        dynamic_out = widgets.Output()\n",
    "        display(dynamic_out)\n",
    "\n",
    "        # Loop over the edf file list to extract parameters from each participant\n",
    "        for e, edf_path in enumerate(edf_files):\n",
    "            with dynamic_out:\n",
    "                output += (f'file {e+1}/{len(edf_files)}, currently opening file: {edf_path}\\n')\n",
    "                dynamic_out.clear_output(wait=True)\n",
    "                print_in_scrollable_box(output, font_size = \"12px\")\n",
    "                \n",
    "                # read file with the custom function\n",
    "                try:\n",
    "                    edf_header = read_edf_header_custom(edf_path) \n",
    "                    \n",
    "                    # get subject name (corresponding to file_name)\n",
    "                    sub_name = edf_path.stem\n",
    "                    \n",
    "                    # get subject group (from the parent folder because in the ICEBERG database subfolders were created per patient group)\n",
    "                    sub_folder = edf_path.parent.name # get the parent folder of the subject file (path)\n",
    "                    \n",
    "                    # create df from signal info\n",
    "                    df = pd.DataFrame(edf_header)\n",
    "                        \n",
    "                    # theoretical resolution (edf are 16bit files so the eeg signal can take 2^16 values within the dynamic range)\n",
    "                    df['res_theoretical'] = (abs(pd.to_numeric(df['physical_min']))+abs(pd.to_numeric(df['physical_max'])))/pow(2,16)\n",
    "                    # turn theoretical resolution to uV if dimension is mV (if no dimension, it is a mess)\n",
    "                    df.loc[df['dimension'].str.contains('mv', case=False, na=False), 'res_theoretical'] *= 1000\n",
    "                    \n",
    "                    # get filtering info in different columns\n",
    "                    df['lowpass']   = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'LP'))\n",
    "                    df['highpass']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'HP'))\n",
    "                    df['notch']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'NOTCH'))\n",
    "                    \n",
    "                    # add subject info in the dataframe\n",
    "                    df['subject'] = sub_name\n",
    "                    df['sub_folder'] = sub_folder\n",
    "                    df['group'] = np.nan # initialyze column 'group' with NaN\n",
    "                    # get group from participants table if any (else group will be inferred from subfolder or filename extension later)\n",
    "                    if found_group:\n",
    "                        df['group'] = subj_table.loc[subj_table['participant_id'] == sub_name, 'group'].iloc[0]\n",
    "        \n",
    "                    # extract filename component before and after subject number (so we assume subject name contains at least incrementing numbers that are at the beginning of the file name)  \n",
    "                    #   ^       → start of string  \n",
    "                    # (.*?)     → group 1: as few chars as possible, up to the first digit  \n",
    "                    # (\\d+)     → group 2: the number itself  \n",
    "                    # (.*)      → group 3: the rest of the string  \n",
    "                    # $         → end of string\n",
    "                    pre_comp = sub_num = post_comp = np.nan\n",
    "                    pattern = re.compile(r'^(.*?)(\\d+)(.*)$')\n",
    "                    m = pattern.match(sub_name)\n",
    "                    if m:\n",
    "                        pre_comp = m.group(1) or np.nan\n",
    "                        sub_num = m.group(2) or np.nan\n",
    "                        post_comp = m.group(3) or np.nan\n",
    "                    df['pre_fn_comp'] = pre_comp\n",
    "                    df['post_fn_comp'] = post_comp\n",
    "                    df['sub_num'] = sub_num\n",
    "                    \n",
    "                    df['path'] = str(edf_path)\n",
    "                    df['session'] = np.nan # session will be inferred later from file name component\n",
    "                    \n",
    "                    # select only the columns of interest\n",
    "                    df = df[['subject', 'group', 'session', 'path', 'sub_folder', 'sub_num', 'pre_fn_comp', 'post_fn_comp', 'channel', 'transducer_type', 'dimension', 'sampling_frequency', \n",
    "                         'highpass', 'lowpass', 'notch', 'physical_min', 'physical_max', 'res_theoretical']]\n",
    "                    \n",
    "                    # store subject data\n",
    "                    df_list.append(df)\n",
    "            \n",
    "                except UnicodeDecodeError as e:\n",
    "                    err = f\"⚠️ Encoding problem for {edf_path}\\n\"\n",
    "                    output += err\n",
    "                    clear_output(wait=True)\n",
    "                    print_in_scrollable_box(output, font_size=\"12px\")\n",
    "                    failed_list.append((edf_path, 'encoding'))\n",
    "                except Exception as e:\n",
    "                    # tb = traceback.format_exc()\n",
    "                    err = f\"❌ Unexpected problem for {edf_path} : {e}\\n\"\n",
    "                    output += err\n",
    "                    clear_output(wait=True)\n",
    "                    print_in_scrollable_box(output, font_size=\"12px\")\n",
    "                    failed_list.append((edf_path, 'other'))\n",
    "           \n",
    "        # concatenate dataframe into one and only\n",
    "        with warnings.catch_warnings(): # this is to skip a warning not affecting our operation\n",
    "            warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "            df_full = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        # save the failed list if not empty:\n",
    "        failed_df = pd.DataFrame(failed_list)\n",
    "        if not failed_df.empty:\n",
    "            failed_df.to_csv(f'{summary_path}/failed_edf_read.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving the list of files that could not be read to: \\n{summary_path}/failed_edf_read.tsv')    \n",
    "        #____________________________________________________________________________________________\n",
    "        \n",
    "        #%% 1.2 General info of the dataset___________________________________________________________\n",
    "        section12 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3> Dataset general information (# participants, groups, recorded sensors)</h3>\n",
    "        \"\"\")\n",
    "        display(section12)\n",
    "        \n",
    "        # get group information, from participants.tsv file, sub_folder, or filename component\n",
    "        print(\"Get group information:\")\n",
    "        if df_full['group'].isna().all():\n",
    "            print(\"The column 'group' is empty, we will infer group from subfolder, if any...\")\n",
    "            if len(df_full['sub_folder'].unique()) > 1:\n",
    "                df_full['group'] = df_full['sub_folder']\n",
    "                print(\">>> Group inferred from folders within the database <<<\")\n",
    "            else:\n",
    "                print(\"There is no distinct folders for groups.\")\n",
    "                print(\"Trying to infer group from filename component...\")\n",
    "                # looping across subject number (and not subject filename) to test if there are multiple filename components per subject (to disentangle groups from session)  \n",
    "                count_precomp = np.zeros(len(df_full['sub_num'].unique()))\n",
    "                count_postcomp = np.zeros(len(df_full['sub_num'].unique()))\n",
    "                for sn, sub_num in enumerate(df_full['sub_num'].unique()):\n",
    "                    df_sub = df_full[df_full['sub_num'] == sub_num]\n",
    "                    count_precomp[sn] = len(df_sub['pre_fn_comp'].unique())\n",
    "                    count_postcomp[sn] = len(df_sub['post_fn_comp'].unique())\n",
    "                # fn component is a group if within subject there is only one component, but there are multiple components between subject\n",
    "                # 1st, try for component before the subject number, 2nd try for component after the subject number \n",
    "                if len(df_full['pre_fn_comp'].unique()) > 1 and count_precomp.mean() == 1:\n",
    "                    df_full['group'] = df_full['pre_fn_comp']\n",
    "                    print(\">>> Group inferred from filename component (before subject number) <<<\")\n",
    "                elif len(df_full['post_fn_comp'].unique()) > 1 and count_postcomp.mean() == 1:\n",
    "                    df_full['group'] = df_full['post_fn_comp']\n",
    "                    print(\">>> Group inferred from filename component (after subject number) <<<\")\n",
    "                else:\n",
    "                    print(\"Did not succeed to identify group from filename component.\")\n",
    "                    print(\"It seems that there is only one group in the study!\")\n",
    "        else:\n",
    "            print(\">>> Group information coming from participants.tsv <<<\")\n",
    "        \n",
    "        print(\"\\nGet session information\")\n",
    "        if len(df_full['pre_fn_comp'].unique()) > 1 and count_precomp.mean() > 1:\n",
    "            print(\">>> Session inferred from filename component (before subject number) <<<\")\n",
    "            df_full['session'] = df_full['pre_fn_comp']\n",
    "        elif len(df_full['post_fn_comp'].unique()) > 1 and count_postcomp.mean() > 1:\n",
    "            print(\">>> Session inferred from filename component (after subject number) <<<\")\n",
    "            df_full['session'] = df_full['post_fn_comp']\n",
    "        else:\n",
    "            print(\"It seems that there is only one session in the study\")\n",
    "        \n",
    "        # save summary table containing full info\n",
    "        df_full.to_csv(f'{summary_path}/FULL_summary_table_edf.tsv', sep = '\\t')\n",
    "        print(f'\\nSaving full informations from the dataset to:\\n{summary_path}/FULL_summary_table_edf.tsv')\n",
    "        \n",
    "        print(\"\\n\\nDataset information:\")\n",
    "        print(f\"- Number of files: {len(df_full['subject'].unique())}\")\n",
    "        print(f\"- Number of participants: {len(df_full['sub_num'].unique())}\")\n",
    "        print(f\"- Number of groups: {len(df_full['group'].unique())}\")\n",
    "        print(f\"- Number of sessions: {len(df_full['session'].unique())}\")\n",
    "        \n",
    "        if len(df_full['group'].unique()) > 1:\n",
    "            print(\"\\nParticipants per groups:\")\n",
    "            print(df_full.drop_duplicates().groupby('group').agg(n_subjects=('subject', 'nunique')))\n",
    "    \n",
    "        print('\\nFull recorded sensors configuration of your database (across participants): ')\n",
    "        ch_output = '\\n'.join(df_full['channel'].unique())\n",
    "        print_in_scrollable_box(ch_output, height = 150)\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 2. Select only the EEGs__________________________________________________________________\n",
    "        section2 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:4px; background-color:black; border:none;\">\n",
    "        <h2>2. Inspect EEG</h2>\n",
    "        \"\"\")\n",
    "        display(section2)\n",
    "        \n",
    "        # select only EEG channels and return a warning if the number of participant is smaller/higher\n",
    "        mask_ch = df_full['transducer_type'].str.contains(r'EEG|AGAGCL ELECTRODE', case = False, na=False) # create a mask that returns true for lines containing either EEG/AGAGCL ELECTRODE in the transducer_type column\n",
    "        df_ch = df_full[mask_ch]\n",
    "        # remove the emg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "        df_ch = df_ch[~df_ch['channel'].str.contains(r'emg|ecg|eog', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "        \n",
    "        # Check if the number of participants with only EEG is the same as df_full. \n",
    "        # If not, it might be because the transducer type was no correctly detected. \n",
    "        # One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "        if len(df_full['subject'].unique()) > len(df_ch['subject'].unique()):\n",
    "            # identify missing subjects\n",
    "            missing_sub = set(df_full['subject'].unique()) - set(df_ch['subject'].unique())\n",
    "            print('\\n!!! There is less participants in the dataset with only EEGs !!!')\n",
    "            print(f'Missing participants: {missing_sub}')\n",
    "            print(\"\\nEither these participants don't have EEGs.\")\n",
    "            print(\"Or the transducer type was not correctly detected.\")\n",
    "            # get df of missing sub to save and inspect\n",
    "            df_miss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "            df_miss.to_csv(f'{summary_path}/EEG_missing_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from missing participants to:\\n{summary_path}/EEG_missing_edf.tsv')\n",
    "            print('Please inspect the file, and specifically the column transducer_type')\n",
    "        elif len(df_full['subject'].unique()) < len(df_ch['subject'].unique()):\n",
    "            print('\\n!!! There is more participants in the dataset with only EEGs !!!')\n",
    "            print('This should not be the case.')\n",
    "            print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "            more_sub = set(df_ch['subject'].unique()) - set(df_full['subject'].unique())\n",
    "            df_more = df_ch[df_ch['subject'].isin(more_sub)]\n",
    "            df_more.to_csv(f'{summary_path}/EEG_suspect_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/EEG_suspect_edf.tsv')\n",
    "        \n",
    "        # saving info from eeg\n",
    "        df_ch.to_csv(f'{summary_path}/EEG_summary_table.tsv', sep = '\\t')\n",
    "        print(f'\\nSaving informations from EEGs to:\\n{summary_path}/EEG_summary_table.tsv')\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 2.1 Inspect EEG configurations___________________________________________________________\n",
    "        section21 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>2.1 Inspect EEG configurations</h3>\n",
    "        <p>By EEG configurations, here, we mean the number of EEG channels and their labeling.\n",
    "        <br>In practice, most EEG studies rely on a single configuration, since all data are typically recorded at the same location, with the same system, and by the same experimenter.\n",
    "        <br>In multicentric datasets, there will likely be many EEG configurations (specific to each recording center).</p>\n",
    "        <p>Knowing your channels' configurations will allow you to select the subset of channels for your analyses (and later re-harmonize the channel labeling if needed).</p>\n",
    "        <p>In classic polysomnographic EEG, there should be at least 4 EEG (F3, C3, O1 and A2 used as the reference) (or less frequently F4, C4, O2 and A1).</p>\n",
    "        <p>Depending on your planned analyses, if a given configuration lacks those channels, you will either need to re-export the data (provided those channels were originally recorded) or exclude the participant.</p>\n",
    "        <p>Below, we check how many EEG configurations your dataset contains.</p>\n",
    "        \"\"\")\n",
    "        display(section21)\n",
    "        \n",
    "        # get the EEG configuration per participant \n",
    "        ch_per_sub = df_ch.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        \n",
    "        # identify the channel configuration of each participant and store them in a dict to print per channel config\n",
    "        ch_config_dict = {}\n",
    "        for config in ch_per_sub.unique():\n",
    "            sub = ch_per_sub[ch_per_sub == config].index.tolist()\n",
    "            ch_config_dict[config] = sub\n",
    "        \n",
    "        if len(ch_config_dict) > 1:\n",
    "            print('\\n>>> There is multiple EEG configurations in your dataset! <<<')    \n",
    "            print(f'\\n\\tNumber of different configuration: {len(ch_config_dict)}\\n')\n",
    "        else:\n",
    "            print('\\n>>> There is only one EEG configuration in your dataset! <<<\\n')\n",
    "\n",
    "        if len(ch_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_ch_slider = mk_config_slider(value = 1, min = 1, max = len(ch_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=ch_config_dict, param=\"channels\"), i=config_ch_slider);\n",
    "        else: \n",
    "            print(\"No EEG configuration found\")\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 2.2 Inspect sampling frequency___________________________________________________________\n",
    "        section22 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>2.2 Inspect EEG sampling frequency</h3>\n",
    "        <p>The sampling frequency is the number of recorded samples per time unit (expressed in Hz). It is set at the acquisition.\n",
    "        <br>Ideally, you expect to have only one sampling frequency for all the EEGs and participants.\n",
    "        <br>In multicentric dataset, you might end up with different sampling frequencies across participants (specific to each recording center).</p> \n",
    "        <p>If you have multiple sampling frequencies across participants in your dataset, we recommend that you harmonize your dataset by downsampling your data to the lowest sampling frequency before your analyses.</p>\n",
    "        <p>Below, we check how many different sampling frequencies your dataset contains.</p>\n",
    "        <p><em>Side note: With multiple sampling frequencies within participants (that can happen for EEG and EOG), each EEG analysis software behaves differently. For example:\n",
    "        <br>&#x2022; MNE python will automatically upsample channels to the highest sampling frequency (with .edf/.bdf/.gdf format)\n",
    "        <br>&#x2022; Fieldtrip will load only a subset of channels (with the sampling frequency the most represented)\n",
    "        </em></p>\n",
    "        \"\"\")\n",
    "        display(section22)\n",
    "        \n",
    "        # the sampling frequency configuration\n",
    "        sf_per_sub = df_ch.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        # identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "        sf_config_dict = {}\n",
    "        for config in sf_per_sub.unique():\n",
    "            sub = sf_per_sub[sf_per_sub == config].index.tolist()\n",
    "            sf_config_dict[config] = sub\n",
    "        \n",
    "        # print info per sf configuration (maybe print it only for multiple config)\n",
    "        if len(sf_config_dict) > 1:\n",
    "            print('\\n>>> There is multiple sampling frequency for EEGs in your dataset! <<<')    \n",
    "            print(f'\\n\\tNumber of different sampling frequency configuration: {len(sf_config_dict)}\\n')\n",
    "            print('Quick overlook of the EEGs associated to sampling frequencies:')\n",
    "            for s, sf in enumerate(df_ch['sampling_frequency'].unique()):\n",
    "                # select only rows with the current sf\n",
    "                df_sf = df_ch[df_ch['sampling_frequency'] == sf].copy()\n",
    "                print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}\\n')\n",
    "        else:\n",
    "            print(f'\\n>>> There is only one sampling frequency for EEGs in your dataset: {df_ch['sampling_frequency'].unique()} <<<\\n')\n",
    "\n",
    "        if len(sf_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_sf_slider = mk_config_slider(value = 1, min = 1, max = len(sf_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=sf_config_dict, param=\"sampling frequencies\"), i=config_sf_slider);\n",
    "        else:\n",
    "            print(\"No EEG sampling frequency found\")\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 2.3 Inspect EEG filters__________________________________________________________________\n",
    "        section23 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>2.3 Inspect EEG filters</h3>\n",
    "        <p>When we visualize EEG data, signals are classically filtered by the software (like compumedics).\n",
    "        <br>For analyses, we classically apply high-pass (to remove very low frequency), low-pass (to remove high frequency), and notch (to remove electric noise) filters.\n",
    "        <br>When we export the data, we can specify whether we want the data to be filtered or not.\n",
    "        <br>A good practice is to export the data without any filter, so that you can apply filters later according to your analyses.\n",
    "        <br>However, for whole-night recordings, we recommend to export the data with a high-pass filter of 0.01 Hz in order to remove slow drift on such long recordings.</p>\n",
    "        <p>If you have multiple filter configurations, we recommend re-exporting the data without filters if possible.</p>\n",
    "        <p>Below, we check which filters were applied and counts how many different ones were used when exporting your dataset.</p>\n",
    "        \"\"\")\n",
    "        display(section23)\n",
    "        \n",
    "        if len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) == 3:\n",
    "            print('\\n>>> All EEGs have the same filters! <<<')\n",
    "        elif len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) > 3:\n",
    "            print('\\n>>> Filters are not fully consistent in EEGs across the dataset! <<<')\n",
    "        else:\n",
    "            print('\\n>>> There may have been a problem in reading the filters. Here is the output: <<<')\n",
    "        \n",
    "        # Get the list of participants with different filtering parameters\n",
    "        # 1st replace NaN because groupby does not like NaN\n",
    "        df_filt = df_ch.copy()\n",
    "        df_filt[['lowpass', 'highpass', 'notch']] = df_filt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "        \n",
    "        config_filters = (\n",
    "            df_filt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "            .apply(lambda x: sorted(set(x)))\n",
    "            .reset_index(name = 'subjects')\n",
    "        )\n",
    "        \n",
    "        # print filter configuration\n",
    "        print(f'\\n\\tNumber of different EEG filters configurations: {len(config_filters)}\\n')\n",
    "\n",
    "        if len(config_filters)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_filter_slider = mk_config_slider(value = 1, min = 1, max = len(config_filters))\n",
    "            \n",
    "            # function to rpint filters configurations\n",
    "            def print_filters(config_slider):\n",
    "                # get the info from the dataframe\n",
    "                idx = config_slider - 1\n",
    "                sID = config_filters.iloc[idx]['subjects']\n",
    "                hpass = config_filters.iloc[idx]['highpass']\n",
    "                lpass = config_filters.iloc[idx]['lowpass']\n",
    "                notch = config_filters.iloc[idx]['notch']\n",
    "                \n",
    "                # print info\n",
    "                print(f'Selected configuration: # {config_slider}')\n",
    "                print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "                print(f'\\t{len(sID)} participants: {sID}')\n",
    "            \n",
    "            widgets.interact(print_filters, config_slider = config_filter_slider);\n",
    "        else:\n",
    "            print(\"No EEG filters found\")\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 2.4 Inspect units in the dataset_________________________________________________________\n",
    "        section24 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>2.4 Inspect EEG units</h3>\n",
    "        <p>At the exportation, channels can be imported in different units.\n",
    "        <br>Each analysis software will handle units differently, so it can be helpful to know which units your dataset contains.\n",
    "        </p> \n",
    "        <p>&#x2022; MNE python will automatically detect the units and convert the data to Volt. However, if the unit is not read correctly, the data will <b>not</b> be converted (e.g. \"UV\" is not interpredted as µV, therefore data are not converted to Volt)\n",
    "        <br>&#x2022; Fieldtrip is loading the data with their unit of origin, so you might want to convert all channels to the same unit before your analysis\n",
    "        </p>\n",
    "        <p>Below, we check how many different units your dataset contains.</p>\n",
    "        \"\"\")\n",
    "        display(section24)\n",
    "\n",
    "        if len(df_ch['dimension'].unique()) == 1:\n",
    "            print(f'\\n>>> All EEGs have the same unit: {df_ch[\"dimension\"].unique()} <<<\\n')\n",
    "        elif len(df_ch['dimension'].unique()) > 1:\n",
    "            print('\\n>>> Multiple units were found! <<<')\n",
    "            print(f'\\n\\tNumber of different units configurations: {len(df_ch['dimension'].unique())}\\n')\n",
    "            print('Quick overlook of EEGs associated to units:')\n",
    "            for u, unit in enumerate(df_ch['dimension'].unique()):\n",
    "                # select only rows with the current sf\n",
    "                df_unit = df_ch[df_ch['dimension'] == unit].copy()\n",
    "                print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "            print(f'\\n')\n",
    "            \n",
    "        # print the different configuration of units \n",
    "        # if info about sf configuration is needed\n",
    "        unit_per_sub = df_ch.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        ch_per_unit = df_ch.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        # identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "        unit_config_dict = {}\n",
    "        for config in unit_per_sub.unique():\n",
    "            sub = unit_per_sub[unit_per_sub == config].index.tolist()\n",
    "            unit_config_dict[config] = sub\n",
    "\n",
    "        if len(unit_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_unit_slider = mk_config_slider(value = 1, min = 1, max = len(unit_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=unit_config_dict, param=\"Units\"), i=config_unit_slider);\n",
    "        else:\n",
    "            print(\"No EEG unit found\")\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 2.5 Inspect EEG signal inversion_________________________________________________________\n",
    "        section25 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>2.5 Inspect EEG signal inversion</h3>\n",
    "        <p>Some softwares (e.g. profusion from compumedics) allows to invert the polarity of the exported data. It can be extremely confusing and can lead to wrong results.\n",
    "        <br>Here, we inspect if the signal is inverted by checking if the minimum physical boundary is higher than the maximum physical boundary.\n",
    "        <br>For .edf file, the physical boundaries are values that are set when exporting the data by specifying the scale of the data.\n",
    "        <br>In profusion (from compumedics) a scale of 1mV will lead to a min physical boundary of -500 µV and a max physical boundary of +500 µV.\n",
    "        </p>\n",
    "        <p>For other EEG format and software, the dynamical range might be set before recording (e.g. to be specified in the montage) and can't be changed at the exportation.\n",
    "        </p>\n",
    "        <p> Below, we check, for each EEG channel, if the minimum physical boundary is greater than the maximum physical boundary, and saves a table containing the channels with inverted polarity.</p>\n",
    "        \"\"\")\n",
    "        display(section25)\n",
    "        \n",
    "        # select rows where the physical min is greater than the physical max\n",
    "        df_inv = df_ch[df_ch['physical_min'] > df_ch['physical_max']]\n",
    "        \n",
    "        if not df_inv.empty:\n",
    "            print('\\n>>> Inverted polarity detected in EEGs! <<<')\n",
    "            print(f'{df_inv.shape[0]} EEGs have an inverted polarity (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "            print(df_inv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "        else:\n",
    "            print('\\n>>> No inverted polarity was detected in EEGs <<<')\n",
    "        df_inv.to_csv(f'{summary_path}/EEG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "        print(f'\\nSaving informations from inverted polarity EEGs to:\\n{summary_path}/EEG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 2.6 Inspect EEG dynamic range and resolution_____________________________________________\n",
    "        section26 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>2.6 Inspect EEG dynamic range and resolution</h3>\n",
    "        <p>The EDF format stores signals in 16 bits, meaning that each sample can take 65&nbsp;536 discrete values (2<sup>16</sup>).\n",
    "        <br>In order to convert these values into real EEG amplitudes, a dynamic range (a minimum and maximum value) must be defined when exporting the data.\n",
    "        <br>Each sample is then given a value between this minimum and maximum (among the 2<sup>16</sup> levels).\n",
    "        </p>\n",
    "        <p>This choice of dynamic range can lead to two opposing problems:</p>\n",
    "            <ul>\n",
    "                <li>\n",
    "                    <strong>Clipping:</strong><br>\n",
    "                    If the dynamic range is too small, certain signal amplitudes exceed the limits.<br>\n",
    "                    The exceeding values are then cut off (therefore “locked” at the min/max), and information is lost.<br>\n",
    "                    Example of data with a dynamic range of ± 100 µV:<br>\n",
    "                    <img src=\"images/clipped.png\" width=\"250\"/>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <strong>Loss of resolution:</strong><br>\n",
    "                    If the dynamic range is too large, the 65&nbsp;536 levels are spread over a too-wide amplitude.<br>\n",
    "                    Each quantization step then becomes too large, and small variations in signal amplitude are no longer visible with precision.<br>\n",
    "                    Example of data with a resolution of 30 µV:<br>\n",
    "                    <img src=\"images/low_resolution.png\" width=\"250\">\n",
    "                </li>\n",
    "                Example of clean data (dynamic range = ± 500 µV; resolution = 0.01 µV:<br>\n",
    "                <img src=\"images/clean.png\" width=\"250\"/>\n",
    "            </ul>\n",
    "        \"\"\")\n",
    "        display(section26)\n",
    "        #---------------------------\n",
    "        section261 = widgets.HTML(\"\"\"\n",
    "        <h4>Dynamic range</h4>\n",
    "        <p>Typical physiological EEG data (good quality) varies from ± 500 µV.\n",
    "        <br>Below, we check if the dynamic range physical boundaries are lower than 500 µV (± 250 µV).\n",
    "        <br>You can change the dynamic range threshold with the widget.\n",
    "        <br>Detected bad channels are saved to a summary table.</p>\n",
    "        \"\"\")\n",
    "        display(section261)\n",
    "        \n",
    "        dr_thres = widgets.BoundedFloatText(\n",
    "            value=500,\n",
    "            min=0,\n",
    "            max=5000,\n",
    "            step=0.1,\n",
    "            style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "            layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "            description='Dynamic range threshold (µV):',\n",
    "            disabled=False\n",
    "        );\n",
    "        \n",
    "        \n",
    "        def check_bad_dr(threshold):\n",
    "            dr_mask = df_ch['res_theoretical']*pow(2,16) <= threshold\n",
    "            bad_dr = df_ch[dr_mask]\n",
    "            \n",
    "            if not bad_dr.empty:\n",
    "                print(f'\\n>>> Dynamic range <= {threshold} µV detected in EEGs! <<<\\n')\n",
    "                print(f'{bad_dr.shape[0]} EEGs detected (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "                print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "            else:\n",
    "                print(f'\\n>>> No EEG with a dynamic range <= {threshold} µV was detected! <<<')\n",
    "            bad_dr.to_csv(f'{summary_path}/EEG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from bad dynamic range EEGs to:\\n{summary_path}/EEG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "        \n",
    "        widgets.interact(check_bad_dr, threshold = dr_thres);\n",
    "        #---------------------------\n",
    "        #---------------------------\n",
    "        section262 = widgets.HTML(\"\"\"\n",
    "        <h4>Resolution</h4>\n",
    "        <p>The theoretical resolution of .edf file is the minimum amplitude variation that can be recorded between two samples (influenced by the dynamic range, as stated above).\n",
    "        <br>Below, we detect EEG channels that have a resolution higher than 0.1 µV.\n",
    "        <br>You can change the resolution threshold with the widget.\n",
    "        <br>Channels with a lower resolution than the threshold are saved to a summary table.</p>\n",
    "        \"\"\")\n",
    "        display(section262)\n",
    "\n",
    "        # res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "        r_thres = widgets.BoundedFloatText(\n",
    "            value=0.1,\n",
    "            min=0,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "            layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "            description='Resolution threshold (µV):',\n",
    "            disabled=False\n",
    "        );\n",
    "        \n",
    "        # define a function to interact with the widget\n",
    "        def check_bad_res(threshold):\n",
    "            r_mask = df_ch['res_theoretical'] >= threshold\n",
    "            bad_res = df_ch[r_mask]\n",
    "            \n",
    "            if not bad_res.empty:\n",
    "                print(f'\\n>>> EEGs with a resolution >= {threshold} µV detected! <<<')\n",
    "                print(f'{bad_res.shape[0]} EEGs detected (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "                print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "            else:\n",
    "                print(f'\\n>>> No EEG with a resolution >= {threshold} µV was detected! <<<')\n",
    "            bad_res.to_csv(f'{summary_path}/EEG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from bad resolution EEGs to:\\n{summary_path}/EEG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "        \n",
    "        widgets.interact(check_bad_res, threshold=r_thres);\n",
    "        #---------------------------\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 3. Select only the EOGs__________________________________________________________________\n",
    "        section3 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:4px; background-color:black; border:none;\">\n",
    "        <h2>3. Inspect EOG</h2>\n",
    "        <p>This section follows the same structure, logic, and outputs as section 2. Inspect EEG.\n",
    "        <br>Hence, the code cells are not commented (please refer to section 2. if you need a refresher).\n",
    "        </p>\n",
    "        \"\"\")\n",
    "        display(section3)\n",
    "\n",
    "        # select only EOGs and return a warning if the number of participant is smaller/higher\n",
    "        mask_eog = df_full['channel'].str.contains(r'EOG', case = False, na=False) # create a mask that returns true for lines containing either EOG in the channel column\n",
    "        df_eog = df_full[mask_eog]\n",
    "        # remove the emg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "        # df_eog = df_eog[~df_eog['channel'].str.contains(r'emg|ecg|eeg|a1|a2', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "        \n",
    "        # Check if the number of participants with only EOG is the same as df_full. \n",
    "        # If not, it might be because the transducer type was no correctly detected. \n",
    "        # One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "        if len(df_full['subject'].unique()) > len(df_eog['subject'].unique()):\n",
    "            # identify missing subjects\n",
    "            missing_sub = set(df_full['subject'].unique()) - set(df_eog['subject'].unique())\n",
    "            print('\\n!!! There is less participants in the dataset with only EOGs !!!')\n",
    "            print(f'Missing participants: {missing_sub}')\n",
    "            print(\"\\nEither these participants don't have EOGs.\")\n",
    "            print(\"Or the transducer type was not correctly detected.\")\n",
    "            # get df of missing sub to save and inspect\n",
    "            df_eogmiss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "            df_eogmiss.to_csv(f'{summary_path}/EOG_missing_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from missing participants to:\\n{summary_path}/EOG_missing_edf.tsv')\n",
    "            print('Please inspect the file, and specifically the column transducer_type')\n",
    "        elif len(df_full['subject'].unique()) < len(df_eog['subject'].unique()):\n",
    "            print('\\n!!! There is more participants in the dataset with only EOGs !!!')\n",
    "            print('This should not be the case.')\n",
    "            print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "            more_sub = set(df_eog['subject'].unique()) - set(df_full['subject'].unique())\n",
    "            df_more = df_eog[df_eog['subject'].isin(more_sub)]\n",
    "            df_more.to_csv(f'{summary_path}/EOG_suspect_edf.csv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/EOG_suspect_edf.tsv')\n",
    "        \n",
    "        # saving info from EOG\n",
    "        df_eog.to_csv(f'{summary_path}/EOG_summary_table.tsv', sep = '\\t')\n",
    "        print(f'\\nSaving informations from EOGs to:\\n{summary_path}/EOG_summary_table.tsv')\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 3.1 Inspect EOG configurations___________________________________________________________\n",
    "        section31 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>3.1 Inspect EOG configurations</h3>\n",
    "        \"\"\")\n",
    "        display(section31)\n",
    "\n",
    "        # get the EOG configuration per participant \n",
    "        eog_per_sub = df_eog.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        \n",
    "        # identify the EOG configuration of each participant and store them in a dict to print per EOG config\n",
    "        eog_config_dict = {}\n",
    "        for config in eog_per_sub.unique():\n",
    "            sub = eog_per_sub[eog_per_sub == config].index.tolist()\n",
    "            eog_config_dict[config] = sub\n",
    "        \n",
    "        if len(eog_config_dict) > 1:\n",
    "            print('\\n>>> There is multiple EOG configurations in your dataset! <<<')    \n",
    "            print(f'\\n\\tNumber of different configuration: {len(eog_config_dict)}\\n')\n",
    "        else:\n",
    "            print('\\n>>> There is only one EOG configuration in your dataset! <<<')\n",
    "\n",
    "        if len(eog_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_eog_slider = mk_config_slider(value = 1, min = 1, max = len(eog_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=eog_config_dict, param=\"Channels\"), i=config_eog_slider);\n",
    "        else:\n",
    "            print(\"No EOG configuration found\")\n",
    "        #____________________________________________________________________________________________\n",
    "        \n",
    "        #%% 3.2 Inspect EOG sampling frequencies_____________________________________________________\n",
    "        section32 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>3.2 Inspect EOG sampling frequencies</h3>\n",
    "        \"\"\")\n",
    "        display(section32)\n",
    "\n",
    "        # the sampling frequency configuration\n",
    "        sfeog_per_sub = df_eog.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        # identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "        sfeog_config_dict = {}\n",
    "        for config in sfeog_per_sub.unique():\n",
    "            sub = sfeog_per_sub[sfeog_per_sub == config].index.tolist()\n",
    "            sfeog_config_dict[config] = sub\n",
    "        \n",
    "        # print info per sf configuration (maybe print it only for multiple config)\n",
    "        if len(sfeog_config_dict) > 1:\n",
    "            print('\\n>>> There is multiple sampling frequency for EOGs in your dataset! <<<')    \n",
    "            print(f'\\n\\tNumber of different sampling frequency configuration: {len(sfeog_config_dict)}\\n')\n",
    "            print('Quick overlook of the EOGs associated to sampling frequencies:')\n",
    "            for s, sf in enumerate(df_eog['sampling_frequency'].unique()):\n",
    "                # select only rows with the current sf\n",
    "                df_sf = df_eog[df_eog['sampling_frequency'] == sf].copy()\n",
    "                print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "        else:\n",
    "            print(f'\\n>>> There is only one sampling frequency for EOGs in your dataset: {df_eog['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "        if len(sfeog_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_sfeog_slider = mk_config_slider(value = 1, min = 1, max = len(sfeog_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=sfeog_config_dict, param=\"Sampling frequencies\"), i=config_sfeog_slider);\n",
    "        else:\n",
    "            print(\"No EOG sampling frequency found\")\n",
    "        #____________________________________________________________________________________________\n",
    "        \n",
    "        #%% 3.3 Inspect EOG filters__________________________________________________________________\n",
    "        section33 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>3.3 Inspect EOG filters</h3>\n",
    "        \"\"\")\n",
    "        display(section33)\n",
    "\n",
    "        if len(df_eog['highpass'].unique())+len(df_eog['lowpass'].unique())+len(df_eog['notch'].unique()) == 3:\n",
    "            print('\\n>>> All EOGs have the same filters! <<<')\n",
    "        elif len(df_eog['highpass'].unique())+len(df_eog['lowpass'].unique())+len(df_eog['notch'].unique()) > 3:\n",
    "            print('\\n>>> Filters are not fully consistent across the dataset! <<<')\n",
    "        else:\n",
    "            print('\\n>>> There may have been a problem in reading the filters. Here is the output: <<<')\n",
    "        \n",
    "        # Get the list of participants with different filtering parameters\n",
    "        # 1st replace NaN because groupby does not like NaN\n",
    "        df_eogfilt = df_eog.copy()\n",
    "        df_eogfilt[['lowpass', 'highpass', 'notch']] = df_eogfilt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "        \n",
    "        config_eogfilters = (\n",
    "            df_eogfilt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "            .apply(lambda x: sorted(set(x)))\n",
    "            .reset_index(name = 'subjects')\n",
    "        )\n",
    "\n",
    "        # print filter configuration\n",
    "        print(f'\\n\\tNumber of different EOG filters configurations: {len(config_eogfilters)}\\n')\n",
    "\n",
    "        if len(config_eogfilters)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_eogfilter_slider = mk_config_slider(value = 1, min = 1, max = len(config_eogfilters))\n",
    "            \n",
    "            # function to rpint filters configurations\n",
    "            def print_eogfilters(config_slider):\n",
    "                # get the info from the dataframe\n",
    "                idx = config_slider - 1\n",
    "                sID = config_eogfilters.iloc[idx]['subjects']\n",
    "                hpass = config_eogfilters.iloc[idx]['highpass']\n",
    "                lpass = config_eogfilters.iloc[idx]['lowpass']\n",
    "                notch = config_eogfilters.iloc[idx]['notch']\n",
    "                \n",
    "                # print info\n",
    "                print(f'Selected configuration: # {config_slider}')\n",
    "                print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "                print(f'\\t{len(sID)} participants: {sID}')\n",
    "            \n",
    "            widgets.interact(print_eogfilters, config_slider = config_eogfilter_slider);\n",
    "        else:\n",
    "            print(\"No EOG filters found\")\n",
    "        #____________________________________________________________________________________________\n",
    "        \n",
    "        #%% 3.4 Inspect EOG units____________________________________________________________________\n",
    "        section34 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>3.4 Inspect EOG units</h3>\n",
    "        \"\"\")\n",
    "        display(section34)\n",
    "\n",
    "        if len(df_eog['dimension'].unique()) == 1:\n",
    "            print(f'\\n>>> All EOGs have the same unit: {df_eog[\"dimension\"].unique()} <<<\\n')\n",
    "        elif len(df_eog['dimension'].unique()) > 1:\n",
    "            print('\\n>>> Multiple units were found! <<<')\n",
    "            print(f'\\n\\tNumber of different EOG units configurations: {len(df_eog['dimension'].unique())}\\n')\n",
    "            print('Quick overlook of EOGs associated to units:')\n",
    "            for u, unit in enumerate(df_eog['dimension'].unique()):\n",
    "                # select only rows with the current sf\n",
    "                df_unit = df_eog[df_eog['dimension'] == unit].copy()\n",
    "                print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "            \n",
    "        \n",
    "        # print the different configuration of units \n",
    "        # if info about sf configuration is needed\n",
    "        eogunit_per_sub = df_eog.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        eog_per_unit = df_eog.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        # identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "        eogunit_config_dict = {}\n",
    "        for config in eogunit_per_sub.unique():\n",
    "            sub = eogunit_per_sub[eogunit_per_sub == config].index.tolist()\n",
    "            eogunit_config_dict[config] = sub\n",
    "\n",
    "        if len(eogunit_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_eogunit_slider = mk_config_slider(value = 1, min = 1, max = len(eogunit_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=eogunit_config_dict, param=\"Units\"), i=config_eogunit_slider);\n",
    "        else:\n",
    "            print(\"No EOG unit found\")\n",
    "        #____________________________________________________________________________________________\n",
    "        \n",
    "        #%% 3.5 Inspect EOG signal inversion_________________________________________________________\n",
    "        section35 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>3.5 Inspect EOG signal inversion</h3>\n",
    "        \"\"\")\n",
    "        display(section35)\n",
    "\n",
    "        # select rows where the physical min is greater than the physical max\n",
    "        df_eoginv = df_eog[df_eog['physical_min'] > df_eog['physical_max']]\n",
    "        \n",
    "        if not df_eoginv.empty:\n",
    "            print('\\n>>> Inverted polarity detected in EOGs! <<<')\n",
    "            print(f'{df_eoginv.shape[0]} EOGs have an inverted polarity (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "            print(df_eoginv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "        else:\n",
    "            print('\\n>>> No inverted polarity was detected in EOGs <<<')\n",
    "        df_eoginv.to_csv(f'{summary_path}/EOG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "        print(f'\\nSaving informations from inverted polarity EOGs to:\\n{summary_path}/EOG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 3.6 Inspect EOG dynamic range and resolution_____________________________________________\n",
    "        section36 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>3.6 Inspect EOG dynamic range and resolution</h3>\n",
    "        \"\"\")\n",
    "        display(section36)\n",
    "        #---------------------------\n",
    "        section361 = widgets.HTML(\"\"\"\n",
    "        <h4>Dynamic range</h4>\n",
    "        \"\"\")\n",
    "        display(section361)\n",
    "\n",
    "        dr_eogthres = widgets.BoundedFloatText(\n",
    "            value=400,\n",
    "            min=0,\n",
    "            max=5000,\n",
    "            step=0.1,\n",
    "            style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "            layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "            description='Dynamic range threshold (µV):',\n",
    "            disabled=False\n",
    "        );\n",
    "\n",
    "        def check_bad_eogdr(threshold):\n",
    "            dr_mask = df_eog['res_theoretical']*pow(2,16) <= threshold\n",
    "            bad_dr = df_eog[dr_mask]\n",
    "            \n",
    "            if not bad_dr.empty:\n",
    "                print(f'\\n>>> Dynamic range <= {threshold} µV detected in EOGs! <<<\\n')\n",
    "                print(f'{bad_dr.shape[0]} EOGs detected (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "                print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "            else:\n",
    "                print(f'\\n>>> No EOG with a dynamic range <= {threshold} µV was detected! <<<')\n",
    "            bad_dr.to_csv(f'{summary_path}/EOG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from bad dynamic range EOGs to:\\n{summary_path}/EOG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "        \n",
    "        widgets.interact(check_bad_eogdr, threshold = dr_eogthres);\n",
    "        #---------------------------\n",
    "        #---------------------------\n",
    "        section362 = widgets.HTML(\"\"\"\n",
    "        <h4>Resolution</h4>\n",
    "        \"\"\")\n",
    "        display(section362)\n",
    "\n",
    "        # res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "        eogr_thres = widgets.BoundedFloatText(\n",
    "            value=0.1,\n",
    "            min=0,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "            layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "            description='Resolution threshold (µV):',\n",
    "            disabled=False\n",
    "        );\n",
    "        \n",
    "        # define a function to interact with the widget\n",
    "        def check_bad_eogres(threshold):\n",
    "            r_mask = df_eog['res_theoretical'] >= threshold\n",
    "            bad_res = df_eog[r_mask]\n",
    "            \n",
    "            if not bad_res.empty:\n",
    "                print(f'\\n>>> EOGs with a resolution >= {threshold} µV detected! <<<')\n",
    "                print(f'{bad_res.shape[0]} EOGs detected (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "                print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "            else:\n",
    "                print(f'\\n>>> No EOG with a resolution >= {threshold} µV was detected! <<<')\n",
    "            bad_res.to_csv(f'{summary_path}/EOG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from bad resolution EOGs to:\\n{summary_path}/EOG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "        \n",
    "        widgets.interact(check_bad_eogres, threshold=eogr_thres);\n",
    "        #---------------------------\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 4. Select only the ECGs__________________________________________________________________\n",
    "        #____________________________________________________________________________________________\n",
    "        section4 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:4px; background-color:black; border:none;\">\n",
    "        <h2>4. Inspect ECG</h2>\n",
    "        <p>This section follows the same structure, logic, and outputs as section 2. Inspect EEG.\n",
    "        <br>Hence, the code cells are not commented (please refer to section 2. if you need a refresher).\n",
    "        </p>\n",
    "        \"\"\")\n",
    "        display(section4)\n",
    "\n",
    "        # select only ECGs and return a warning if the number of participant is smaller/higher\n",
    "        mask_ecg = df_full['channel'].str.contains(r'ecg', case = False, na=False) # create a mask that returns true for lines containing either ecg in the channel column\n",
    "        df_ecg = df_full[mask_ecg]\n",
    "        \n",
    "        # Check if the number of participants with only ECG is the same as df_full. \n",
    "        # If not, it might be because the transducer type was no correctly detected. \n",
    "        # One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "        if len(df_full['subject'].unique()) > len(df_ecg['subject'].unique()):\n",
    "            # identify missing subjects\n",
    "            missing_sub = set(df_full['subject'].unique()) - set(df_ecg['subject'].unique())\n",
    "            print('\\n!!! There is less participants in the dataset with only ECGs !!!')\n",
    "            print(f'Missing participants: {missing_sub}')\n",
    "            print(\"\\nEither these participants don't have ECGs.\")\n",
    "            print(\"Or the transducer type was not correctly detected.\")\n",
    "            # get df of missing sub to save and inspect\n",
    "            df_ecgmiss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "            df_ecgmiss.to_csv(f'{summary_path}/ECG_missing_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from missing participants to:\\n{summary_path}/ECG_missing_edf.tsv')\n",
    "            print('Please inspect the file, and specifically the column transducer_type')\n",
    "        elif len(df_full['subject'].unique()) < len(df_ecg['subject'].unique()):\n",
    "            print('\\n!!! There is more participants in the dataset with only ECGs !!!')\n",
    "            print('This should not be the case.')\n",
    "            print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "            more_sub = set(df_ecg['subject'].unique()) - set(df_full['subject'].unique())\n",
    "            df_more = df_ecg[df_ecg['subject'].isin(more_sub)]\n",
    "            df_more.to_csv(f'{summary_path}/ECG_suspect_edf.csv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/ECG_suspect_edf.tsv')\n",
    "        \n",
    "        # saving info from ECG\n",
    "        df_ecg.to_csv(f'{summary_path}/ECG_summary_table.tsv', sep = '\\t')\n",
    "        print(f'\\nSaving informations from ECGs to:\\n{summary_path}/ECG_summary_table.tsv')\n",
    "        #___________________________________________________________________________________________\n",
    "        \n",
    "        #%% 4.1 Inspect ECG configurations___________________________________________________________\n",
    "        section41 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>4.1 Inspect ECG configurations</h3>\n",
    "        \"\"\")\n",
    "        display(section41)\n",
    "\n",
    "        # get the ECGs configuration per participant \n",
    "        ecg_per_sub = df_ecg.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        \n",
    "        # identify the ECG configuration of each participant and store them in a dict to print per ECG config\n",
    "        ecg_config_dict = {}\n",
    "        for config in ecg_per_sub.unique():\n",
    "            sub = ecg_per_sub[ecg_per_sub == config].index.tolist()\n",
    "            ecg_config_dict[config] = sub\n",
    "        \n",
    "        if len(ecg_config_dict) > 1:\n",
    "            print('\\n>>> There is multiple ECG configurations in your dataset! <<<')    \n",
    "            print(f'\\n\\tNumber of different ECG configuration: {len(ecg_config_dict)}\\n')\n",
    "        else:\n",
    "            print('\\n>>> There is only one ECG configuration in your dataset! <<<')\n",
    "\n",
    "        if len(ecg_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_ecg_slider = mk_config_slider(value = 1, min = 1, max = len(ecg_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=ecg_config_dict, param=\"Channels\"), i=config_ecg_slider);\n",
    "        else:\n",
    "            print(\"No ECG configuration found\")\n",
    "        #___________________________________________________________________________________________\n",
    "        \n",
    "        #%% 4.2 Inspect ECG sampling frequencies____________________________________________________\n",
    "        section42 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>4.2 Inspect ECG sampling frequencies</h3>\n",
    "        \"\"\")\n",
    "        display(section42)\n",
    "        \n",
    "        # the sampling frequency configuration\n",
    "        ecgsf_per_sub = df_ecg.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        # identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "        ecgsf_config_dict = {}\n",
    "        for config in ecgsf_per_sub.unique():\n",
    "            sub = ecgsf_per_sub[ecgsf_per_sub == config].index.tolist()\n",
    "            ecgsf_config_dict[config] = sub\n",
    "        \n",
    "        # print info per sf configuration (maybe print it only for multiple config)\n",
    "        if len(ecgsf_config_dict) > 1:\n",
    "            print('\\n>>> There is multiple sampling frequency for ECGs in your dataset! <<<')    \n",
    "            print(f'\\n\\tNumber of different sampling frequency configuration: {len(ecgsf_config_dict)}\\n')\n",
    "            print('Quick overlook of the ECGs associated to sampling frequencies:')\n",
    "            for s, sf in enumerate(df_ecg['sampling_frequency'].unique()):\n",
    "                # select only rows with the current sf\n",
    "                df_sf = df_ecg[df_ecg['sampling_frequency'] == sf].copy()\n",
    "                print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "        else:\n",
    "            print(f'\\n>>> There is only one sampling frequency for ECGs in your dataset: {df_ecg['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "        if len(ecgsf_config_dict):\n",
    "            # widget to select the configuration of interest\n",
    "            config_ecgsf_slider = mk_config_slider(value = 1, min = 1, max = len(ecgsf_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=ecgsf_config_dict, param=\"Sampling frequencies\"), i=config_ecgsf_slider);\n",
    "        else:\n",
    "            print(\"No ECG sampling frequency\")\n",
    "        #___________________________________________________________________________________________\n",
    "        \n",
    "        #%% 4.3 Inspect ECG filters_________________________________________________________________\n",
    "        section43 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>4.3 Inspect ECG filters</h3>\n",
    "        \"\"\")\n",
    "        display(section43)\n",
    "\n",
    "        if len(df_ecg['highpass'].unique())+len(df_ecg['lowpass'].unique())+len(df_ecg['notch'].unique()) == 3:\n",
    "            print('\\n>>> All ECGs have the same filters! <<<')\n",
    "        elif len(df_ecg['highpass'].unique())+len(df_ecg['lowpass'].unique())+len(df_ecg['notch'].unique()) > 3:\n",
    "            print('\\n>>> Filters are not fully consistent across the dataset! <<<')\n",
    "        else:\n",
    "            print('\\n>>> There may have been a problem in reading the filters. Here is the output: <<<')\n",
    "        \n",
    "        # Get the list of participants with different filtering parameters\n",
    "        # 1st replace NaN because groupby does not like NaN\n",
    "        df_ecgfilt = df_ecg.copy()\n",
    "        df_ecgfilt[['lowpass', 'highpass', 'notch']] = df_ecgfilt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "        \n",
    "        config_ecgfilters = (\n",
    "            df_ecgfilt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "            .apply(lambda x: sorted(set(x)))\n",
    "            .reset_index(name = 'subjects')\n",
    "        )\n",
    "\n",
    "        # print filter configuration\n",
    "        print(f'\\n\\tNumber of different ECG filters configurations: {len(config_ecgfilters)}\\n')\n",
    "\n",
    "        if len(config_ecgfilters)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_ecgfilter_slider = mk_config_slider(value = 1, min = 1, max = len(config_ecgfilters))\n",
    "            \n",
    "            # function to rpint filters configurations\n",
    "            def print_ecgfilters(config_slider):\n",
    "                # get the info from the dataframe\n",
    "                idx = config_slider - 1\n",
    "                sID = config_ecgfilters.iloc[idx]['subjects']\n",
    "                hpass = config_ecgfilters.iloc[idx]['highpass']\n",
    "                lpass = config_ecgfilters.iloc[idx]['lowpass']\n",
    "                notch = config_ecgfilters.iloc[idx]['notch']\n",
    "                \n",
    "                # print info\n",
    "                print(f'Selected configuration: # {config_slider}')\n",
    "                print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "                print(f'\\t{len(sID)} participants: {sID}')\n",
    "            \n",
    "            widgets.interact(print_ecgfilters, config_slider = config_ecgfilter_slider);\n",
    "        else:\n",
    "            print(\"No ECG filters\")\n",
    "        #___________________________________________________________________________________________\n",
    "        \n",
    "        #%% 4.4 Inspect ECG units___________________________________________________________________\n",
    "        section44 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>4.4 Inspect ECG units</h3>\n",
    "        \"\"\")\n",
    "        display(section44)\n",
    "\n",
    "        if len(df_ecg['dimension'].unique()) == 1:\n",
    "            print(f'\\n>>> All ECGs have the same unit: {df_ecg[\"dimension\"].unique()} <<<\\n')\n",
    "        elif len(df_ecg['dimension'].unique()) > 1:\n",
    "            print('\\n>>> Multiple units were found for ECGs! <<<')\n",
    "            print(f'\\n\\tNumber of different units configurations: {len(df_ecg['dimension'].unique())}\\n')\n",
    "            print('Quick overlook of ECGs associated to units:')\n",
    "            for u, unit in enumerate(df_ecg['dimension'].unique()):\n",
    "                # select only rows with the current sf\n",
    "                df_unit = df_ecg[df_ecg['dimension'] == unit].copy()\n",
    "                print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "            \n",
    "        \n",
    "        # print the different configuration of units \n",
    "        # if info about sf configuration is needed\n",
    "        ecgunit_per_sub = df_ecg.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        ecg_per_unit = df_ecg.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "        # identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "        ecgunit_config_dict = {}\n",
    "        for config in ecgunit_per_sub.unique():\n",
    "            sub = ecgunit_per_sub[ecgunit_per_sub == config].index.tolist()\n",
    "            ecgunit_config_dict[config] = sub\n",
    "\n",
    "        if len(ecgunit_config_dict)>=1:\n",
    "            # widget to select the configuration of interest\n",
    "            config_ecgunit_slider = mk_config_slider(value = 1, min = 1, max = len(ecgunit_config_dict))\n",
    "            \n",
    "            # print the configuration selected\n",
    "            # interact with the slider output through the printing function \n",
    "            widgets.interact(lambda i: print_config(i, config_dict=ecgunit_config_dict, param=\"Units\"), i=config_ecgunit_slider);\n",
    "        else:\n",
    "            print(\"No ECG unit found\")\n",
    "        #___________________________________________________________________________________________\n",
    "        \n",
    "        #%% 4.5 Inspect ECG signal inversion________________________________________________________\n",
    "        section45 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>4.5 Inspect ECG signal inversion</h3>\n",
    "        \"\"\")\n",
    "        display(section45)\n",
    "\n",
    "        # select rows where the physical min is greater than the physical max\n",
    "        df_ecginv = df_ecg[df_ecg['physical_min'] > df_ecg['physical_max']]\n",
    "        \n",
    "        if not df_ecginv.empty:\n",
    "            print('\\n>>> Inverted polarity detected in ECGs! <<<')\n",
    "            print(f'{df_ecginv.shape[0]} ECGs have an inverted polarity (from {df_ecg.shape[0]} ECGs in {len(edf_files)} edf files)')\n",
    "            print(df_ecginv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "        else:\n",
    "            print('\\n>>> No inverted polarity was detected in ECGs <<<')\n",
    "        df_ecginv.to_csv(f'{summary_path}/ECG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "        print(f'\\nSaving informations from inverted polarity ECGs to:\\n{summary_path}/ECG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% 4.6 Inspect ECG dynamic range and resolution_____________________________________________\n",
    "        section46 = widgets.HTML(\"\"\"\n",
    "        <hr style=\"height:1px; background-color:black; border:none;\">\n",
    "        <h3>4.6 Inspect ECG dynamic range and resolution</h3>\n",
    "        \"\"\")\n",
    "        display(section46)\n",
    "        #---------------------------\n",
    "        section461 = widgets.HTML(\"\"\"\n",
    "        <h4>Dynamic range</h4>\n",
    "        \"\"\")\n",
    "        display(section461)\n",
    "\n",
    "        ecgdr_thres = widgets.BoundedFloatText(\n",
    "            value=400,\n",
    "            min=0,\n",
    "            max=5000,\n",
    "            step=0.1,\n",
    "            style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "            layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "            description='Dynamic range threshold (µV):',\n",
    "            disabled=False\n",
    "        );\n",
    "        \n",
    "        \n",
    "        def check_bad_ecgdr(threshold):\n",
    "            dr_mask = df_ecg['res_theoretical']*pow(2,16) <= threshold\n",
    "            bad_dr = df_ecg[dr_mask]\n",
    "            \n",
    "            if not bad_dr.empty:\n",
    "                print(f'\\n>>> Dynamic range <= {threshold} µV detected in ECGs! <<<\\n')\n",
    "                print(f'{bad_dr.shape[0]} ECGs detected (from {df_ecg.shape[0]} ECGs in {len(edf_files)} edf files)')\n",
    "                print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "            else:\n",
    "                print(f'\\n>>> No ECG with a dynamic range <= {threshold} µV was detected! <<<')\n",
    "            bad_dr.to_csv(f'{summary_path}/ECG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from bad dynamic range ECGs to:\\n{summary_path}/ECG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "        \n",
    "        widgets.interact(check_bad_ecgdr, threshold = ecgdr_thres);\n",
    "        #---------------------------\n",
    "        #---------------------------\n",
    "        section462 = widgets.HTML(\"\"\"\n",
    "        <h4>Resolution</h4>\n",
    "        \"\"\")\n",
    "        display(section462)\n",
    "\n",
    "        # res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "        ecgr_thres = widgets.BoundedFloatText(\n",
    "            value=0.1,\n",
    "            min=0,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "            layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "            description='Resolution threshold (µV):',\n",
    "            disabled=False\n",
    "        );\n",
    "        \n",
    "        # define a function to interact with the widget\n",
    "        def check_bad_ecgres(threshold):\n",
    "            r_mask = df_ecg['res_theoretical'] >= threshold\n",
    "            bad_res = df_ecg[r_mask]\n",
    "            \n",
    "            if not bad_res.empty:\n",
    "                print(f'\\n>>> ECGs with a resolution >= {threshold} µV detected! <<<')\n",
    "                print(f'{bad_res.shape[0]} ECGs detected (from {df_ecg.shape[0]} ecgs in {len(edf_files)} edf files)')\n",
    "                print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "            else:\n",
    "                print(f'\\n>>> No ECG with a resolution >= {threshold} µV was detected! <<<')\n",
    "            bad_res.to_csv(f'{summary_path}/ECG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "            print(f'\\nSaving informations from bad resolution ECGs to:\\n{summary_path}/ECG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "        \n",
    "        widgets.interact(check_bad_ecgres, threshold=ecgr_thres);\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "        #%% end of the code section__________________________________________________________________\n",
    "        #____________________________________________________________________________________________\n",
    "\n",
    "# Link run button to the main function\n",
    "run_button.on_click(run_inspection)\n",
    "# callback to run the function only when a folder is selected\n",
    "chooser.register_callback(run_inspection)\n",
    "\n",
    "# Display in voila\n",
    "display(chooser, run_button, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
