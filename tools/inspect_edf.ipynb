{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bcc77e-a10a-441b-b8e9-33006dd75aee",
   "metadata": {},
   "source": [
    "# Inspect export parameters from .edf files of an EEG database \n",
    "This notebook allows you to inspect the parameters of your .edf EEG database. \\\n",
    "It does not load and inspect the quality of your data. \\\n",
    "It helps you identify if you need to re-export some participant's data (due to poor signal resolution or clipping, as explained later). \\\n",
    "It provides information that helps analyze your dataset (such as the different channel labels, sampling frequency, and filters). \n",
    "\n",
    "---\n",
    "EDF (European Data Format) is a standard format for storing multichannel biological and physical signals: https://www.edfplus.info/. \\\n",
    "It was first published in 1992, and an upgraded version was released in 2003 (adding discontinuous recordings handling, annotations, stimuli, and events in a UTF-8 format). \\\n",
    "It is a compressed 16-bit format, meaning that each measured data point can take 2¬π‚Å∂ values between the minimum and maximum values that you set at exportation. \\\n",
    "The min/max values correspond to the dynamic range of your data.\n",
    "\n",
    "---\n",
    "At the exportation in the .edf format (with software like Profusion from Compumedics), many parameters need to be set per recorded channels, such as channels' label, sampling frequency, filtering, units, and dynamic range. \\\n",
    "Exporting as .edf format is tedious and time-consuming, so mistakes in parameters can easily be made.  \\\n",
    "To avoid making mistakes, there is the possibility of implementing montage within some software that will apply your  pre-defined parameters directly **(insert a link on how to make a routine in Compumedics).** \\\n",
    "Inspecting those parameters can also be necessary if you work on an already existing dataset, to make sure that every participant's data is exploitable, specifically if the data comes from multiple sleep clinics. \n",
    "\n",
    "---\n",
    "This notebook reads information from the .edf files, instead of loading the data and relying on existing packages. \\\n",
    "Existing packages, such as PYEDFLIB or MNE, are either too rigid (not able to read some data) or do not return all the information (such as boundaries of dynamic range, filtering parameters, etc).\\\n",
    "\\\n",
    "**To use this notebook, read each text box (called markdown cells in Jupyter notebook), run its associated code box (code cell), and read the output below.**\\\n",
    "To run a cell, select the cell and either click on \"Run\" and \"Run Selected Cell\" in the menu bar, or press \"Shift+Enter\". \\\n",
    "_The notebook will save summary tables as .tsv files (file format easy to read with Excel and to import in Python script) so that you can visually inspect (or reload later) if needed._ \\\n",
    "_Those summaries will be stored in a summary folder within the study folder._ \\\n",
    "\\\n",
    "This notebook is organized into 4 sections (with a section 0 to prepare your notebook):\n",
    "1. Select your study folder, extract the data's information, and return general information\n",
    "2. Inspect EEG channels\n",
    "3. Inspect EOG channels\n",
    "4. Inspect ECG channels\n",
    "\n",
    "Once you are done with one section, you can reduce it by pressing the down arrow on the left of the section title, to improve the readability.\n",
    "\n",
    "---\n",
    "This notebook was developed on the ICEBERG database and tested on APOMORPHEE (from No√©mie's internship).  \\\n",
    "last update 16/09/2025, YN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d45c0-237c-4460-9a7c-1f7e88f5c88d",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316eaf2b-5591-4698-968d-5117df3f8b13",
   "metadata": {},
   "source": [
    "## 0. Import packages and define custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d7e8e-b926-4914-97ee-92f4b39567fc",
   "metadata": {},
   "source": [
    "In this notebook (and the majority of Python scripts), we use packages that contain pre-defined functions to perform our operations. \\\n",
    "The code cell below loads the packages required for this notebook and defines custom functions that we will use. \\\n",
    "If you have already installed all the packages, you will get the message ``Packages and functions successfully imported``. \\\n",
    "\\\n",
    "If you are missing one package, you will get an error ``ModuleNotFoundError: No module named 'my_package'``.\\\n",
    "To install the missing package, there are two solutions:\n",
    "1. Install within Jupyter notebook:\n",
    "    - open a new cell (click on \"+\" in the top-left toolbar of the notebook)\n",
    "    - write ``%conda install nom_du_package --yes`` in the new cell\n",
    "    - run the new cell (\"Shift+Enter\" or click \"Run\" and \"Run Selected Cell\" in the menu bar)\n",
    "    - restart the kernel of the Jupyter notebook: click on \"Kernel\" and \"Restart Kernel...\"\n",
    "    - re-run the import cell\n",
    "<div style=\"margin-bottom:10px;\"></div>\n",
    "\n",
    "2. Install within a terminal: \n",
    "    - open a new terminal\n",
    "    - enter the virtual environment you are working in (from where you installed Jupyter notebook) with ``conda activate my_virtual_environment``\n",
    "    - run: ``conda install -k my_package``\n",
    "    - restart the kernel of the Jupyter notebook: click on \"Kernel\" and \"Restart Kernel...\"\n",
    "    - re-run the import cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c657ea5-74e0-43d6-9ab2-8b6ed4a23340",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411d73d-c71c-433d-81d2-169e69bd00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cell\n",
    "try:\n",
    "    import os\n",
    "    import re\n",
    "    import chardet\n",
    "    import warnings\n",
    "    import traceback\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import ipywidgets as widgets\n",
    "    from ipyfilechooser import FileChooser\n",
    "    from IPython.display import display, HTML\n",
    "except ImportError as e:\n",
    "    print(\"‚ö†Ô∏è Error: \", e)\n",
    "else:\n",
    "    print(\"‚úÖ Packages and functions successfully imported!\")\n",
    "\n",
    "# custom function to detect automatically and return the encoding of edf file\n",
    "def detect_encoding(byte_string, min_confidence=0.6):\n",
    "    result = chardet.detect(byte_string)\n",
    "    encoding = result['encoding']\n",
    "    confidence = result['confidence']\n",
    "    if encoding is None or confidence < min_confidence:\n",
    "        raise UnicodeDecodeError(\"chardet\", byte_string, 0, len(byte_string),\n",
    "                                 f\"\\tUnable to reliably detect encoding. Detected: {encoding} with confidence {confidence}\")\n",
    "    return encoding\n",
    "\n",
    "# custom function to read information from EDF headers, without using the pyedflib package (that was too strict for ICEBERG)\n",
    "# EDF file should follow a strict format, dedicating a specific number of octets for each type of information.\n",
    "# it means that we can read the info octet by octet by specifying the number of octets we expect for the next variable (that is known from the EDF norm)\n",
    "def read_edf_header_custom(file_path):\n",
    "    with open(file_path, 'rb') as f: # open the file in binary mode, to read octet by octet. \n",
    "        header = {}\n",
    "        # detect encoding\n",
    "        raw_header = f.read(256)\n",
    "        encoding = detect_encoding(raw_header)\n",
    "        # print(f\"\\tDetected encoding for {file_path} : {encoding}\")\n",
    "        # Rewind to the beginning of the file\n",
    "        f.seek(0)\n",
    "        \n",
    "        # the first 256 octets are global subject info\n",
    "        header['version'] = f.read(8).decode(encoding).strip()\n",
    "        header['patient_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['recording_id'] = f.read(80).decode(encoding).strip()\n",
    "        header['start_date'] = f.read(8).decode(encoding).strip()\n",
    "        header['start_time'] = f.read(8).decode(encoding).strip()\n",
    "        header['header_bytes'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['reserved'] = f.read(44).decode(encoding).strip()\n",
    "        header['n_data_records'] = int(f.read(8).decode(encoding).strip())\n",
    "        header['duration_data_record'] = float(f.read(8).decode(encoding).strip())\n",
    "        header['n_channels'] = int(f.read(4).decode(encoding).strip())\n",
    "        \n",
    "        # get info per channel\n",
    "        n = header['n_channels']\n",
    "        channel_fields = {\n",
    "            'channel': [],\n",
    "            'transducer_type': [],\n",
    "            'dimension': [],\n",
    "            'physical_min': [],\n",
    "            'physical_max': [],\n",
    "            'digital_min': [],\n",
    "            'digital_max': [],\n",
    "            'prefiltering': [],\n",
    "            'sampling_frequency': [],\n",
    "            'reserved': [],\n",
    "        }\n",
    "\n",
    "        for key in channel_fields:\n",
    "            length = {\n",
    "                'channel': 16,\n",
    "                'transducer_type': 80,\n",
    "                'dimension': 8,\n",
    "                'physical_min': 8,\n",
    "                'physical_max': 8,\n",
    "                'digital_min': 8,\n",
    "                'digital_max': 8,\n",
    "                'prefiltering': 80,\n",
    "                'sampling_frequency': 8,\n",
    "                'reserved': 32,\n",
    "            }[key]\n",
    "            channel_fields[key] = [f.read(length).decode(encoding).strip() for _ in range(n)]\n",
    "\n",
    "        header.update(channel_fields)\n",
    "    \n",
    "    return header\n",
    "\n",
    "# function to extract filter information from the string in headers\n",
    "def extract_filter_value(s, tag):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(rf'{tag}[:\\s]*([\\d\\.]+)\\s*', s, re.IGNORECASE)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "# custom function to get the sampling frequency out of a dataframe (the df needs to have 'subject' and 'channel' as columns)\n",
    "def get_sf(df, subject, channel):\n",
    "    df_sf = df[(df['subject'] == subject) & (df['channel'] == channel)]\n",
    "    if not df_sf.empty:\n",
    "        return df_sf.iloc[0]['sampling_frequency']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# function to create a widget slider to select the configuration to inspect\n",
    "def mk_config_slider(value = 1, min = 1, max = 5):\n",
    "    config_slider = widgets.IntSlider(\n",
    "    value=value,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    step=1,\n",
    "    description='Selected configuration:',\n",
    "    style={'description_width': '150px'},   # increase description width (to adjust based on the description)\n",
    "    layout=widgets.Layout(width='400px'),   # to adjust widget size\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    "    )\n",
    "    return config_slider\n",
    "\n",
    "# function to print the configuration of a dataset parameter\n",
    "def print_config(i, config_dict, param):\n",
    "    # get the key and value from the dictionary\n",
    "    idx = i - 1\n",
    "    # get participant ID\n",
    "    value = list(config_dict.values())  \n",
    "    v = value[idx]  \n",
    "    # get configuration\n",
    "    key = list(config_dict.keys())\n",
    "    k = key[idx]\n",
    "    \n",
    "    # print info\n",
    "    print(f'Selected configuration: # {i}')\n",
    "    print(f'\\t{len(k)} {param}: {k}')\n",
    "    print(f'\\t{len(v)} participants: {v}')\n",
    "\n",
    "# function to create a scrollable box for long output (e.g., cell loading the data) \n",
    "def print_in_scrollable_box(text, height=300, font_size=\"12px\"):\n",
    "    display(HTML(f'<pre style=\"overflow-y:scroll; height:{height}px; border:1px solid black; padding:10px; font-size:{font_size};\">{text}</pre>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9a604-7fe3-4a81-9e60-1587f7cb14e1",
   "metadata": {},
   "source": [
    "## 1. Select study folder, extract information, display general information "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a71a42-dc8b-44c1-828d-de3a75b493cf",
   "metadata": {},
   "source": [
    "### 1.1 Select the study folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a34884-abce-42a7-b8db-10e500e75d23",
   "metadata": {},
   "source": [
    "The code cell below will open a widget to select the folder containing your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124017c-7f30-4794-aab6-55a462a5b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call widget to select your data folder \n",
    "chooser = FileChooser(os.getcwd())\n",
    "chooser.title = \"<b>Choose your study folder</b>\"\n",
    "chooser.show_only_dirs = True\n",
    "\n",
    "# Define output widget to redirect the print within the function\n",
    "out = widgets.Output()\n",
    "\n",
    "# custom function to extract the folder path once the folder has been chosen: \n",
    "def on_folder_selected(chooser):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        chooser.folder_path = chooser.selected_path\n",
    "        print(\"üìÅ Selected Path:\", chooser.folder_path)\n",
    "        \n",
    "        # get the edf file list \n",
    "        chooser.edf_files = [\n",
    "            f for f in Path(chooser.folder_path).rglob('*.edf')\n",
    "            if not f.name.startswith('._') # don't select files starting with ._ (that can be found in mac for example)\n",
    "            ]\n",
    "        if not chooser.edf_files:\n",
    "            print(f\"‚ö†Ô∏è There is no .edf file in your folder\")\n",
    "        else:\n",
    "            print(f\"\\nThere is {len(chooser.edf_files)} .edf files in your folder!\")\n",
    "        \n",
    "        # check the existence and/or create the summary folder that will receive the summary tables and the report\n",
    "        chooser.summary_path = f'{chooser.folder_path}/summary'\n",
    "        if not os.path.exists(chooser.summary_path):\n",
    "            os.makedirs(chooser.summary_path)\n",
    "            print(\"\\nCreated summary folder at: \" + chooser.summary_path)\n",
    "        else:\n",
    "            print(\"\\nSummary folder already exists. \\nPrevious summary tables (if any) will be overwritten at: \\n\" + chooser.summary_path)\n",
    "\n",
    "# callback to run the function only when a folder is selected\n",
    "chooser.register_callback(on_folder_selected)\n",
    "display(chooser, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7e801-ae24-4fdd-a177-a2cbd95e4595",
   "metadata": {},
   "source": [
    "### 1.2 Extract infromation from each file parameters from each participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d35c8-052c-4a93-b727-2ec51c6c0857",
   "metadata": {},
   "source": [
    "The code cell below will loop across the .edf files to extract the information of each subject.\\\n",
    "It returns a table that can easily be manipulated to access specific information in the rest of the notebook.\\\n",
    "If some files failed to load, their names will be saved in a .tsv file in the summary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6870b-badd-4225-aaef-fc974516dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variables from the chooser widget\n",
    "folder_path = chooser.folder_path\n",
    "summary_path = chooser.summary_path\n",
    "edf_files = chooser.edf_files\n",
    "\n",
    "# check if there is a participants.tsv file to get different groups or sessions\n",
    "# if there is not a participants.tsv we will try to infer groups from subfolder organization or filename components (additional part from subject number)\n",
    "# in ICEBERG, subfolders define groups within the data folder\n",
    "# in APOMORPHEE, suffixes define nights (\"session\") \n",
    "table_found = False\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    if 'participants.tsv' in files:\n",
    "        table_found = True        \n",
    "        print(f\"Table containing participants information found at: {os.path.join(root, 'participants.tsv')} \")\n",
    "        subj_table_path = os.path.join(root, 'participants.tsv')\n",
    "\n",
    "found_group = False\n",
    "if table_found:\n",
    "    subj_table = pd.read_csv(subj_table_path, sep = '\\t', dtype={'participant_id': str, 'group': str})\n",
    "    if \"group\" in subj_table.columns:\n",
    "        found_group = True\n",
    "        print(f\"We will extract participant's group from it\")\n",
    "    else:\n",
    "        print(f\"No column 'group' was found in the table\")\n",
    "        print(f\"Group will be inferred from subfolder organization or subfolder component\") \n",
    "    \n",
    "else:\n",
    "    print(f\"No table containing participants information (labelled 'participants.tsv') was found\")\n",
    "    print(f\"If you have a table, please rename it 'participants.tsv' (and make sure you have columns labelled 'participant_id' and 'group' if any)\")\n",
    "    print(f\"In the meantime, we will infer participant's group from subfolder organization or filename component in the next cells\")\n",
    "    subj_table = pd.DataFrame()\n",
    "\n",
    "# Initialize a list of dataframes to store file info, which will be concatenated at the end (this is better for performance)\n",
    "df_list = []\n",
    "# Initialize an empty list for files that could not be read\n",
    "failed_list = []\n",
    "\n",
    "# intialize a dynamic output\n",
    "output = \"\"\n",
    "dynamic_out = widgets.Output()\n",
    "display(dynamic_out)\n",
    "\n",
    "for e, edf_path in enumerate(edf_files):\n",
    "    with dynamic_out:\n",
    "        output += (f'file {e+1}/{len(edf_files)}, currently opening file: {edf_path}\\n')\n",
    "        dynamic_out.clear_output(wait=True)\n",
    "        print_in_scrollable_box(output, font_size = \"12px\")\n",
    "        \n",
    "        # read file with the custom function\n",
    "        try:\n",
    "            edf_header = read_edf_header_custom(edf_path) \n",
    "            \n",
    "            # get subject name (corresponding to file_name)\n",
    "            sub_name = edf_path.stem\n",
    "            \n",
    "            # get subject group (from the parent folder because in the ICEBERG database subfolders were created per patient group)\n",
    "            sub_folder = edf_path.parent.name # get the parent folder of the subject file (path)\n",
    "            \n",
    "            # create df from signal info\n",
    "            df = pd.DataFrame(edf_header)\n",
    "                \n",
    "            # theoretical resolution (edf are 16bit files so the eeg signal can take 2^16 values within the dynamic range)\n",
    "            df['res_theoretical'] = (abs(pd.to_numeric(df['physical_min']))+abs(pd.to_numeric(df['physical_max'])))/pow(2,16)\n",
    "            # turn theoretical resolution to uV if dimension is mV (if no dimension, it is a mess)\n",
    "            df.loc[df['dimension'].str.contains('mv', case=False, na=False), 'res_theoretical'] *= 1000\n",
    "            \n",
    "            # get filtering info in different columns\n",
    "            df['lowpass']   = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'LP'))\n",
    "            df['highpass']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'HP'))\n",
    "            df['notch']  = df['prefiltering'].apply(lambda x: extract_filter_value(x, 'NOTCH'))\n",
    "            \n",
    "            # add subject info in the dataframe\n",
    "            df['subject'] = sub_name\n",
    "            df['sub_folder'] = sub_folder\n",
    "            df['group'] = np.nan # initialyze column 'group' with NaN\n",
    "            # get group from participants table if any (else group will be inferred from subfolder or filename extension later)\n",
    "            if found_group:\n",
    "                df['group'] = subj_table.loc[subj_table['participant_id'] == sub_name, 'group'].iloc[0]\n",
    "\n",
    "            # extract filename component before and after subject number (so we assume subject name contains at least incrementing numbers that are at the beginning of the file name)  \n",
    "            #   ^       ‚Üí start of string  \n",
    "            # (.*?)     ‚Üí group‚ÄØ1: as few chars as possible, up to the first digit  \n",
    "            # (\\d+)     ‚Üí group‚ÄØ2: the number itself  \n",
    "            # (.*)      ‚Üí group‚ÄØ3: the rest of the string  \n",
    "            # $         ‚Üí end of string\n",
    "            pre_comp = sub_num = post_comp = np.nan\n",
    "            pattern = re.compile(r'^(.*?)(\\d+)(.*)$')\n",
    "            m = pattern.match(sub_name)\n",
    "            if m:\n",
    "                pre_comp = m.group(1) or np.nan\n",
    "                sub_num = m.group(2) or np.nan\n",
    "                post_comp = m.group(3) or np.nan\n",
    "            df['pre_fn_comp'] = pre_comp\n",
    "            df['post_fn_comp'] = post_comp\n",
    "            df['sub_num'] = sub_num\n",
    "            \n",
    "            df['path'] = str(edf_path)\n",
    "            df['session'] = np.nan # session will be inferred later from file name component\n",
    "            \n",
    "            # select only the columns of interest\n",
    "            df = df[['subject', 'group', 'session', 'path', 'sub_folder', 'sub_num', 'pre_fn_comp', 'post_fn_comp', 'channel', 'transducer_type', 'dimension', 'sampling_frequency', \n",
    "                 'highpass', 'lowpass', 'notch', 'physical_min', 'physical_max', 'res_theoretical']]\n",
    "            \n",
    "            # store subject data\n",
    "            df_list.append(df)\n",
    "    \n",
    "        except UnicodeDecodeError as e:\n",
    "            err = f\"‚ö†Ô∏è Encoding problem for {edf_path}\\n\"\n",
    "            output += err\n",
    "            clear_output(wait=True)\n",
    "            print_in_scrollable_box(output, font_size=\"12px\")\n",
    "            failed_list.append((edf_path, 'encoding'))\n",
    "        except Exception as e:\n",
    "            # tb = traceback.format_exc()\n",
    "            err = f\"‚ùå Unexpected problem for {edf_path} : {e}\\n\"\n",
    "            output += err\n",
    "            clear_output(wait=True)\n",
    "            print_in_scrollable_box(output, font_size=\"12px\")\n",
    "            failed_list.append((edf_path, 'other'))\n",
    "   \n",
    "# concatenate dataframe into one and only\n",
    "with warnings.catch_warnings(): # this is to skip a warning not affecting our operation\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    df_full = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# save the failed list if not empty:\n",
    "failed_df = pd.DataFrame(failed_list)\n",
    "if not failed_df.empty:\n",
    "    failed_df.to_csv(f'{summary_path}/failed_edf_read.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving the list of files that could not be read to: \\n{summary_path}/failed_edf_read.tsv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe23577-f4c7-4616-944c-322ac7d83552",
   "metadata": {},
   "source": [
    "### 1.3 Dataset general information (# participants, groups, recorded sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ebf47-0b76-402e-8282-5f7cfbb16eb6",
   "metadata": {},
   "source": [
    "In the code cell below, we extract group and session information, and we save the summary table (in the summary folder) so that it can be visually inspected with Excel, or reloaded in other script if needed.\\\n",
    "\\\n",
    "To extract group information:\n",
    "- we check if group was read from a file participants.tsv (used in BIDS formatting)\n",
    "- else we try to infer it from subfolders (e.g. ICEBERG database organization)\n",
    "- else we try to infer it from filename component (characters before or after the participant number in the filename)  \n",
    "- else we consider there is only one group in the study\n",
    "\n",
    "To extract session information: \n",
    "- we infer it from filename components (if there is more than one filename component per participant)\n",
    "- else we consider there is only one session per participant\n",
    "\n",
    "Then, we display the general information of the dataset (# files, # participants, # groups, # sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84fc79b-d7c5-4c63-bd43-aba23e4ab332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get group information, from participants.tsv file, sub_folder, or filename component\n",
    "print(\"Get group information:\")\n",
    "if df_full['group'].isna().all():\n",
    "    print(\"The column 'group' is empty, we will infer group from subfolder, if any...\")\n",
    "    if len(df_full['sub_folder'].unique()) > 1:\n",
    "        df_full['group'] = df_full['sub_folder']\n",
    "        print(\">>> Group inferred from folders within the database <<<\")\n",
    "    else:\n",
    "        print(\"There is no distinct folders for groups.\")\n",
    "        print(\"Trying to infer group from filename component...\")\n",
    "        # looping across subject number (and not subject filename) to test if there are multiple filename components per subject (to disentangle groups from session)  \n",
    "        count_precomp = np.zeros(len(df_full['sub_num'].unique()))\n",
    "        count_postcomp = np.zeros(len(df_full['sub_num'].unique()))\n",
    "        for sn, sub_num in enumerate(df_full['sub_num'].unique()):\n",
    "            df_sub = df_full[df_full['sub_num'] == sub_num]\n",
    "            count_precomp[sn] = len(df_sub['pre_fn_comp'].unique())\n",
    "            count_postcomp[sn] = len(df_sub['post_fn_comp'].unique())\n",
    "        # fn component is a group if within subject there is only one component, but there are multiple components between subject\n",
    "        # 1st, try for component before the subject number, 2nd try for component after the subject number \n",
    "        if len(df_full['pre_fn_comp'].unique()) > 1 and count_precomp.mean() == 1:\n",
    "            df_full['group'] = df_full['pre_fn_comp']\n",
    "            print(\">>> Group inferred from filename component (before subject number) <<<\")\n",
    "        elif len(df_full['post_fn_comp'].unique()) > 1 and count_postcomp.mean() == 1:\n",
    "            df_full['group'] = df_full['post_fn_comp']\n",
    "            print(\">>> Group inferred from filename component (after subject number) <<<\")\n",
    "        else:\n",
    "            print(\"Did not succeed to identify group from filename component.\")\n",
    "            print(\"It seems that there is only one group in the study!\")\n",
    "else:\n",
    "    print(\">>> Group information coming from participants.tsv <<<\")\n",
    "\n",
    "print(\"\\nGet session information\")\n",
    "if len(df_full['pre_fn_comp'].unique()) > 1 and count_precomp.mean() > 1:\n",
    "    print(\">>> Session inferred from filename component (before subject number) <<<\")\n",
    "    df_full['session'] = df_full['pre_fn_comp']\n",
    "elif len(df_full['post_fn_comp'].unique()) > 1 and count_postcomp.mean() > 1:\n",
    "    print(\">>> Session inferred from filename component (after subject number) <<<\")\n",
    "    df_full['session'] = df_full['post_fn_comp']\n",
    "else:\n",
    "    print(\"It seems that there is only one session in the study\")\n",
    "\n",
    "# save summary table containing full info\n",
    "df_full.to_csv(f'{summary_path}/FULL_summary_table_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving full informations from the dataset to:\\n{summary_path}/FULL_summary_table_edf.tsv')\n",
    "\n",
    "print(\"\\n\\nDataset information:\")\n",
    "print(f\"- Number of files: {len(df_full['subject'].unique())}\")\n",
    "print(f\"- Number of participants: {len(df_full['sub_num'].unique())}\")\n",
    "print(f\"- Number of groups: {len(df_full['group'].unique())}\")\n",
    "print(f\"- Number of sessions: {len(df_full['session'].unique())}\")\n",
    "\n",
    "if len(df_full['group'].unique()) > 1:\n",
    "    print(\"\\nParticipants per groups:\")\n",
    "    print(df_full.drop_duplicates().groupby('group').agg(n_subjects=('subject', 'nunique')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1131160-d67d-48bc-8122-15fcb19a24fc",
   "metadata": {},
   "source": [
    "In the code cell below, we print the unique values of the sensors whithin your database, in case you want to make sure that one specific type of sensors is in your dataset. \\\n",
    "For the rest of the notebook, we will focus, separately, on EEG, EOG and ECG sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3b8b8-fdc9-4b34-abef-5cbaab4a1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nFull recorded sensors configuration of your database (across participants): ')\n",
    "ch_output = '\\n'.join(df_full['channel'].unique())\n",
    "print_in_scrollable_box(ch_output, height = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d188389-063d-43bc-a8c5-b6dfe93d5de8",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4bf662-62bb-4046-a98b-8298c117276f",
   "metadata": {},
   "source": [
    "## 2. Inspect EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020e2fd-b7ec-4249-a53a-f010f38ffcc9",
   "metadata": {},
   "source": [
    "### 2.1 Select only the EEGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a20022-56c3-4392-b6e2-1dc4ae7cb572",
   "metadata": {},
   "source": [
    "The code cell below select only the EEG channels.\\\n",
    "The table containing the only EEGs information will be saved as \"EEG_summary_table.tsv\" in the summary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c434167-29d3-4fd0-894e-8438c8ff5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define common EEG label from the 10-10 convention\n",
    "COMMON_EEG_label = r'\\bFp1\\b|\\bFpz\\b|\\bFp2\\b|\\bAF7\\b|\\bAF3\\b|\\bAFz\\b|\\bAF4\\b|\\bAF8\\b|\\bF7\\b|\\bF5\\b|\\bF3\\b|\\bF1\\b|\\bFz\\b|\\bF2\\b|\\bF4\\b|\\bF6\\b|\\bF8\\b|\\bFT7\\b|\\bFC5\\b|\\bFC3\\b|\\bFC1\\b|\\bFCz\\b|\\bFC2\\b|\\bFC4\\b|\\bFC6\\b|\\bFT8\\b|\\bT7\\b|\\bC5\\b|\\bC3\\b|\\bC1\\b|\\bCz\\b|\\bC2\\b|\\bC4\\b|\\bC6\\b|\\bT8\\b|\\bTP7\\b|\\bCP5\\b|\\bCP3\\b|\\bCP1\\b|\\bCPz\\b|\\bCP2\\b|\\bCP4\\b|\\bCP6\\b|\\bTP8\\b|\\bP7\\b|\\bP5\\b|\\bP3\\b|\\bP1\\b|\\bPz\\b|\\bP2\\b|\\bP4\\b|\\bP6\\b|\\bP8\\b|\\bPO7\\b|\\bPO5\\b|\\bPO3\\b|\\bPOz\\b|\\bPO4\\b|\\bPO6\\b|\\bPO8\\b|\\bO1\\b|\\bOz\\b|\\bO2\\b|\\bM1\\b|\\bM2\\b|EEG'\n",
    "# select only EEG channels and return a warning if the number of participant is smaller/higher\n",
    "mask_ch = df_full['transducer_type'].str.contains(r'EEG|AGAGCL ELECTRODE', case = False, na=False) | df_full['channel'].str.contains(COMMON_EEG_label, case = False, na=False) # create a mask that returns true for lines containing either EEG/AGAGCL ELECTRODE in the transducer_type column or containing a common EEG label in the channel column\n",
    "df_ch = df_full[mask_ch]\n",
    "# remove the emg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "df_ch = df_ch[~df_ch['channel'].str.contains(r'emg|ecg|eog', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "\n",
    "# Check if the number of participants with only EEG is the same as df_full. \n",
    "# If not, it might be because the transducer type was no correctly detected. \n",
    "# One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "if len(df_full['subject'].unique()) > len(df_ch['subject'].unique()):\n",
    "    # identify missing subjects\n",
    "    missing_sub = set(df_full['subject'].unique()) - set(df_ch['subject'].unique())\n",
    "    print('\\n!!! There is less participants in the dataset with only EEGs !!!')\n",
    "    print(f'Missing participants: {missing_sub}')\n",
    "    print(\"\\nEither these participants don't have EEGs.\")\n",
    "    print(\"Or the transducer type was not correctly detected.\")\n",
    "    # get df of missing sub to save and inspect\n",
    "    df_miss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "    df_miss.to_csv(f'{summary_path}/EEG_missing_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from missing participants to:\\n{summary_path}/EEG_missing_edf.tsv')\n",
    "    print('Please inspect the file, and specifically the column transducer_type')\n",
    "elif len(df_full['subject'].unique()) < len(df_ch['subject'].unique()):\n",
    "    print('\\n!!! There is more participants in the dataset with only EEGs !!!')\n",
    "    print('This should not be the case.')\n",
    "    print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "    more_sub = set(df_ch['subject'].unique()) - set(df_full['subject'].unique())\n",
    "    df_more = df_ch[df_ch['subject'].isin(more_sub)]\n",
    "    df_more.to_csv(f'{summary_path}/EEG_suspect_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/EEG_suspect_edf.tsv')\n",
    "\n",
    "# saving info from eeg\n",
    "df_ch.to_csv(f'{summary_path}/EEG_summary_table.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from EEGs to:\\n{summary_path}/EEG_summary_table.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a752f46-632f-4120-b905-f32a26a4d6cc",
   "metadata": {},
   "source": [
    "### 2.2 Inspect EEG configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7373270-1a31-4919-baf8-349c0fa408b5",
   "metadata": {},
   "source": [
    "By EEG configurations, here, we mean the number of EEG channels and their labeling.\\\n",
    "In practice, most EEG studies rely on a single configuration, since all data are typically recorded at the same location, with the same system, and by the same experimenter.\\\n",
    "In multicentric datasets, there will likely be many EEG configurations (specific to each recording center).\\\n",
    "\\\n",
    "Knowing your channels' configurations will allow you to select the subset of channels for your analyses (and later re-harmonize the channel labeling if needed).\\\n",
    "\\\n",
    "In classic polysomnographic EEG, there should be at least 4 EEG (F3, C3, O1 and A2 used as the reference) (or less frequently F4, C4, O2 and A1).\\\n",
    "\\\n",
    "Depending on your planned analyses, if a given configuration lacks those channels, you will either need to re-export the data (provided those channels were originally recorded) or exclude the participant.\\\n",
    "\\\n",
    "The code cell below checks how many EEG configurations your dataset contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994eb7b0-4742-4d3c-94f0-36b34b2b065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the EEG configuration per participant \n",
    "ch_per_sub = df_ch.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the channel configuration of each participant and store them in a dict to print per channel config\n",
    "ch_config_dict = {}\n",
    "for config in ch_per_sub.unique():\n",
    "    sub = ch_per_sub[ch_per_sub == config].index.tolist()\n",
    "    ch_config_dict[config] = sub\n",
    "\n",
    "if len(ch_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple EEG configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different configuration: {len(ch_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one EEG configuration in your dataset! <<<\\n')\n",
    "\n",
    "# # print info per channel configuaration\n",
    "# for i, (config, participants) in enumerate(ch_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Channels ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c6905-ebf9-4b4d-ae5e-6b210dcc4546",
   "metadata": {},
   "source": [
    "Run the code cell below and move the slider to explore each EEG configuration.\\\n",
    "The output will display the channel labels as well as the participant IDs associated with that configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e9c0b-321f-420d-8161-53561474be52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(ch_config_dict)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_ch_slider = mk_config_slider(value = 1, min = 1, max = len(ch_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=ch_config_dict, param=\"channels\"), i=config_ch_slider);\n",
    "else:\n",
    "    print(\"No EEG configuration found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7e4c3-6e5a-4b05-98e3-2183bf7b0e25",
   "metadata": {},
   "source": [
    "### 2.3 Inspect EEG sampling frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f44f5-bc03-46f7-ae35-401ec0e3ab12",
   "metadata": {},
   "source": [
    "The sampling frequency is the number of recorded samples per time unit (expressed in Hz). It is set at the acquisition.\\\n",
    "Ideally, you expect to have only one sampling frequency for all the EEGs and participants.\\\n",
    "In multicentric dataset, you might end up with different sampling frequencies across participants (specific to each recording center).\\\n",
    "\\\n",
    "If you have multiple sampling frequencies across participants in your dataset, we recommend that you harmonize your dataset by downsampling your data to the lowest sampling frequency before your analyses.\\\n",
    "\\\n",
    "The code cell below checks how many different sampling frequencies your dataset contains.\n",
    "___\n",
    "_Side note: With multiple sampling frequencies within participants (that can happen for EEG and EOG), each EEG analysis software behaves differently. For example:_\n",
    "- _MNE python will automatically upsample channels to the highest sampling frequency (with .edf/.bdf/.gdf format)_\n",
    "- _Fieldtrip will load only a subset of channels (with the sampling frequency the most represented)_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a23e13-8c7f-4cb1-af1d-a97a5b828e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sampling frequency configuration\n",
    "sf_per_sub = df_ch.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "sf_config_dict = {}\n",
    "for config in sf_per_sub.unique():\n",
    "    sub = sf_per_sub[sf_per_sub == config].index.tolist()\n",
    "    sf_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration (maybe print it only for multiple config)\n",
    "if len(sf_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple sampling frequency for EEGs in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different sampling frequency configuration: {len(sf_config_dict)}\\n')\n",
    "    print('Quick overlook of the EEGs associated to sampling frequencies:')\n",
    "    for s, sf in enumerate(df_ch['sampling_frequency'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_sf = df_ch[df_ch['sampling_frequency'] == sf].copy()\n",
    "        print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}\\n')\n",
    "else:\n",
    "    print(f'\\n>>> There is only one sampling frequency for EEGs in your dataset: {df_ch['sampling_frequency'].unique()} <<<\\n')\n",
    "\n",
    "# print('\\nSampling frequency configurations:\\n')\n",
    "# for i, (config, participants) in enumerate(sf_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Sampling frequency ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49730cce-9c23-48da-afbd-2d63f0774c94",
   "metadata": {},
   "source": [
    "Run the code cell below and move the slider to explore each sampling frequency configuration.\\\n",
    "The output will display the sampling frequency as well as the participant IDs associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cdcf25-4bc4-44db-abf9-b697c963f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sf_config_dict)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_sf_slider = mk_config_slider(value = 1, min = 1, max = len(sf_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=sf_config_dict, param=\"sampling frequencies\"), i=config_sf_slider);\n",
    "else:\n",
    "    print(\"No EEG sampling frequency found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e85239-2e34-429c-9ddd-192e2dab65a9",
   "metadata": {},
   "source": [
    "### 2.4 Inspect EEG filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08319a27-d470-44c1-b589-875cb7512049",
   "metadata": {},
   "source": [
    "When we visualize EEG data, signals are classically filtered by the software (like compumedics).\\\n",
    "For analyses, we classically apply high-pass (to remove very low frequency), low-pass (to remove high frequency), and notch (to remove electric noise) filters.\\\n",
    "When we export the data, we can specify whether we want the data to be filtered or not.\\\n",
    "A good practice is to export the data without any filter, so that you can apply filters later according to your analyses.\\\n",
    "However, for whole-night recordings, we recommend to export the data with a high-pass filter of 0.01 Hz in order to remove slow drift on such long recordings.\\\n",
    "\\\n",
    "If you have multiple filter configurations, we recommend re-exporting the data without filters if possible.\\\n",
    "\\\n",
    "The code cell below checks which filters were applied and counts how many different ones were used when exporting your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553a505-1807-4ecf-bf4e-71b6b8782387",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) == 3:\n",
    "    print('\\n>>> All EEGs have the same filters! <<<')\n",
    "elif len(df_ch['highpass'].unique())+len(df_ch['lowpass'].unique())+len(df_ch['notch'].unique()) > 3:\n",
    "    print('\\n>>> Filters are not fully consistent in EEGs across the dataset! <<<')\n",
    "else:\n",
    "    print('\\n>>> There may have been a problem in reading the filters. Here is the output: <<<')\n",
    "\n",
    "# Get the list of participants with different filtering parameters\n",
    "# 1st replace NaN because groupby does not like NaN\n",
    "df_filt = df_ch.copy()\n",
    "df_filt[['lowpass', 'highpass', 'notch']] = df_filt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "\n",
    "config_filters = (\n",
    "    df_filt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .reset_index(name = 'subjects')\n",
    ")\n",
    "\n",
    "# print filter configuration\n",
    "print(f'\\n\\tNumber of different EEG filters configurations: {len(config_filters)}\\n')\n",
    "# print('\\nFilters configurations: ')\n",
    "# r=1\n",
    "# for row in config_filters.itertuples(index=False):\n",
    "#     print(f'Configuration #{r} ({len(row.subjects)} participants)')\n",
    "#     print(f'highpass: {row.highpass}, lowpass: {row.lowpass}, notch: {row.notch}\\n')\n",
    "#     r=r+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded87ff-dd63-409a-b15c-a253213e9784",
   "metadata": {},
   "source": [
    "Run the code cell below and move the slider to explore each filters' configuration.\\\n",
    "The output will display the filtering parameters as well as the participant IDs associated with those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f080cb-0bf0-45ce-ac69-f72f8fe4edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(config_filters)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_filter_slider = mk_config_slider(value = 1, min = 1, max = len(config_filters))\n",
    "    \n",
    "    # function to rpint filters configurations\n",
    "    def print_filters(config_slider):\n",
    "        # get the info from the dataframe\n",
    "        idx = config_slider - 1\n",
    "        sID = config_filters.iloc[idx]['subjects']\n",
    "        hpass = config_filters.iloc[idx]['highpass']\n",
    "        lpass = config_filters.iloc[idx]['lowpass']\n",
    "        notch = config_filters.iloc[idx]['notch']\n",
    "        \n",
    "        # print info\n",
    "        print(f'Selected configuration: # {config_slider}')\n",
    "        print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "        print(f'\\t{len(sID)} participants: {sID}')\n",
    "    \n",
    "    widgets.interact(print_filters, config_slider = config_filter_slider);\n",
    "else:\n",
    "    print(\"No EEG filters found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c8623-a3a3-4ebe-a94f-73faf82e6a7a",
   "metadata": {},
   "source": [
    "### 2.5 Inspect EEG units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed44982-de48-4222-a2e3-0ef7b323bae6",
   "metadata": {},
   "source": [
    "At the exportation, channels can be converted to different units.\\\n",
    "Each analysis software will handle units differently, so it can be helpful to know which units your dataset contains. \n",
    "- MNE python will automatically detect the units and convert the data to volts. However, if the unit is not read correctly, the data will **not** be converted (e.g. \"UV\" is not interpreted as ¬µV, therefore data are not converted to Volt while \"uV\" and \"uv\" are correctly detected)\n",
    "- fieldtrip is loading the data with their unit of origin, so you might want to convert all channels to the same unit before your analysis\n",
    "\n",
    "The code cell below checks how many different units your dataset contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffc618-1e2d-48de-be65-d0f81c87be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ch['dimension'].unique()) == 1:\n",
    "    print(f'\\n>>> All EEGs have the same unit: {df_ch[\"dimension\"].unique()} <<<\\n')\n",
    "elif len(df_ch['dimension'].unique()) > 1:\n",
    "    print('\\n>>> Multiple units were found! <<<')\n",
    "    print(f'\\n\\tNumber of different units configurations: {len(df_ch['dimension'].unique())}\\n')\n",
    "    print('Quick overlook of EEGs associated to units:')\n",
    "    for u, unit in enumerate(df_ch['dimension'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_unit = df_ch[df_ch['dimension'] == unit].copy()\n",
    "        print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "    print(f'\\n')\n",
    "    \n",
    "# print the different configuration of units \n",
    "# if info about sf configuration is needed\n",
    "unit_per_sub = df_ch.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "ch_per_unit = df_ch.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "unit_config_dict = {}\n",
    "for config in unit_per_sub.unique():\n",
    "    sub = unit_per_sub[unit_per_sub == config].index.tolist()\n",
    "    unit_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration\n",
    "# print('\\nUnits configurations:')\n",
    "# for i, (config, participants) in enumerate(unit_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Unit ({len(config)}) : {config}\\n')\n",
    "#     # print(f\"Participants : {participants}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a472b7c-c413-485b-8c62-73bcf20d2c00",
   "metadata": {},
   "source": [
    "Run the code cell below and move the slider to explore each EEG units.\\\n",
    "The output will display the EEG units as well as the participant IDs associated with those units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79f538-1c2b-45f8-8b0f-06874c4352f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(unit_config_dict)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_unit_slider = mk_config_slider(value = 1, min = 1, max = len(unit_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=unit_config_dict, param=\"Units\"), i=config_unit_slider);\n",
    "else:\n",
    "    print(\"No EEG unit found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01871a8-6bca-4642-8262-66c5737d43cc",
   "metadata": {},
   "source": [
    "### 2.6 Inspect EEG signal inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761b1c6-ac72-4c39-a8b6-f385dba0f0f9",
   "metadata": {},
   "source": [
    "Some software (e.g. Profusion from Compumedics) allows to invert the polarity when exporting data. This feature can be extremely confusing and can lead to wrong results.\\\n",
    "\\\n",
    "Here, we inspect if the signal is inverted by checking if the minimum physical boundary is higher than the maximum physical boundary.\\\n",
    "For .edf file, the physical boundaries are values that are set when exporting the data by specifying the scale of the data.\\\n",
    "In Profusion (from Compumedics), a scale of 1mV will lead to a minimum physical boundary of -500 ¬µV and a maximum physical boundary of +500 ¬µV.\\\n",
    "\\\n",
    "For other EEG formats and software, the dynamical range might be set before recording (e.g. to be specified in the montage) and can't be changed when exporting.\\\n",
    "\\\n",
    "The code cell below checks, for each EEG channel, if the minimum physical boundary is greater than the maximum physical boundary, and saves a table containing the channels with inverted polarity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1661b24f-eb0c-4787-ad96-538004d08ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where the physical min is greater than the physical max\n",
    "df_inv = df_ch[df_ch['physical_min'] > df_ch['physical_max']]\n",
    "\n",
    "if not df_inv.empty:\n",
    "    print('\\n>>> Inverted polarity detected in EEGs! <<<')\n",
    "    print(f'{df_inv.shape[0]} EEGs have an inverted polarity (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "    print(df_inv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "else:\n",
    "    print('\\n>>> No inverted polarity was detected in EEGs <<<')\n",
    "df_inv.to_csv(f'{summary_path}/EEG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from inverted polarity EEGs to:\\n{summary_path}/EEG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52b08f-3070-4184-b6ad-5c625401d1ce",
   "metadata": {},
   "source": [
    "### 2.7 Inspect EEG dynamic range and resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8cff5-637c-498a-8ad7-d82cc75a3fde",
   "metadata": {},
   "source": [
    "The EDF format stores signals in 16 bits, meaning that each sample can take 65 536 discrete values (2¬π‚Å∂).\\\n",
    "In order to convert these values into real EEG amplitudes, a dynamic range (a minimum and maximum value) must be defined when exporting the data.\\\n",
    "Each sample is then given a value between this minimum and maximum (among the 2¬π‚Å∂ levels).\\\n",
    "\\\n",
    "This choice of dynamic range can lead to two opposing problems:\n",
    "- **Clipping:**\\\n",
    "If the dynamic range is too small, certain signal amplitudes exceed the limits.\\\n",
    "The exceeding values are then cut off (therefore \"locked\" at the min/max), and information is lost.\\\n",
    "Example of data with a dynamic range of ¬± 100 ¬µV:\n",
    "<img src=\"images/clipped.png\" width=\"250\"/>\n",
    "\n",
    "- **Loss of resolution:**\\\n",
    "If the dynamic range is too large, the 65 536 levels are spread over a too-wide amplitude.\\\n",
    "Each quantization step then becomes too large, and small variations in signal amplitude are no longer visible with precision.\\\n",
    "Example of data with a resolution of 30 ¬µV:\\\n",
    "<img src=\"images/low_resolution.png\" width=\"250\"/>\n",
    "\\\n",
    "Example of clean data (dynamic range = ¬± 500 ¬µV; resolution = 0.01 ¬µV:\n",
    "<img src=\"images/clean.png\" width=\"250\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995de14-a19d-44cf-ab2a-53ae0a40e6d5",
   "metadata": {},
   "source": [
    "#### Dynamic range\n",
    "Typical physiological EEG data (good quality) varies from ¬± 500 ¬µV.\\\n",
    "The code cell below checks if the dynamic range physical boundaries are lower than 500 ¬µV (¬± 250 ¬µV).\\\n",
    "You can change the dynamic range threshold with the widget.\\\n",
    "Detected bad channels are saved to a summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6314a71-8c6d-4819-9ea0-0d3db1ee91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_thres = widgets.BoundedFloatText(\n",
    "    value=500,\n",
    "    min=0,\n",
    "    max=5000,\n",
    "    step=0.1,\n",
    "    style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Dynamic range threshold (¬µV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "def check_bad_dr(threshold):\n",
    "    dr_mask = df_ch['res_theoretical']*pow(2,16) <= threshold\n",
    "    bad_dr = df_ch[dr_mask]\n",
    "    \n",
    "    if not bad_dr.empty:\n",
    "        print(f'\\n>>> Dynamic range <= {threshold} ¬µV detected in EEGs! <<<\\n')\n",
    "        print(f'{bad_dr.shape[0]} EEGs detected (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "        print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EEG with a dynamic range <= {threshold} ¬µV was detected! <<<')\n",
    "    bad_dr.to_csv(f'{summary_path}/EEG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad dynamic range EEGs to:\\n{summary_path}/EEG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_dr, threshold = dr_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40bd84-ccc9-4f33-b7a5-9cdf69c49860",
   "metadata": {},
   "source": [
    "#### Resolution\n",
    "The theoretical resolution of .edf file is the minimum amplitude variation that can be recorded between two samples (influenced by the dynamic range, as stated above).\\\n",
    "The code cell below detects EEG channels that have a resolution higher than 0.1 ¬µV.\\\n",
    "You can change the resolution threshold with the widget.\\\n",
    "Channels with a lower resolution than the threshold are saved to a summary table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555defd-0390-4578-9808-21a28ffc3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "r_thres = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Resolution threshold (¬µV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "# define a function to interact with the widget\n",
    "def check_bad_res(threshold):\n",
    "    r_mask = df_ch['res_theoretical'] >= threshold\n",
    "    bad_res = df_ch[r_mask]\n",
    "    \n",
    "    if not bad_res.empty:\n",
    "        print(f'\\n>>> EEGs with a resolution >= {threshold} ¬µV detected! <<<')\n",
    "        print(f'{bad_res.shape[0]} EEGs detected (from {df_ch.shape[0]} EEGs in {len(edf_files)} edf files)')\n",
    "        print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EEG with a resolution >= {threshold} ¬µV was detected! <<<')\n",
    "    bad_res.to_csv(f'{summary_path}/EEG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad resolution EEGs to:\\n{summary_path}/EEG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_res, threshold=r_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ab2fc-79e6-4c30-8155-ed45ec27ce6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Inspect EOG\n",
    "This section follows the same structure, logic, and outputs as section 2. Inspect EEG.\\\n",
    "Hence, the code cells are not commented (please refer to section 2. if you need a refresher)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a154cb-34df-49cd-bc64-6dba5dfa5752",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.1 Select only EOGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eda13e-1ed6-41e1-b9e7-ffe670ce9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only EOGs and return a warning if the number of participant is smaller/higher\n",
    "mask_eog = df_full['channel'].str.contains(r'EOG', case = False, na=False) # create a mask that returns true for lines containing either EOG in the channel column\n",
    "df_eog = df_full[mask_eog]\n",
    "# remove the emg channels that were captured with the AGAGCL ELECTRODE transducer type \n",
    "# df_eog = df_eog[~df_eog['channel'].str.contains(r'emg|ecg|eeg|a1|a2', case=False, na=False)] # the ~ allows to not select the selection (like ! in matlab)\n",
    "\n",
    "# Check if the number of participants with only EOG is the same as df_full. \n",
    "# If not, it might be because the transducer type was no correctly detected. \n",
    "# One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "if len(df_full['subject'].unique()) > len(df_eog['subject'].unique()):\n",
    "    # identify missing subjects\n",
    "    missing_sub = set(df_full['subject'].unique()) - set(df_eog['subject'].unique())\n",
    "    print('\\n!!! There is less participants in the dataset with only EOGs !!!')\n",
    "    print(f'Missing participants: {missing_sub}')\n",
    "    print(\"\\nEither these participants don't have EOGs.\")\n",
    "    print(\"Or the transducer type was not correctly detected.\")\n",
    "    # get df of missing sub to save and inspect\n",
    "    df_eogmiss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "    df_eogmiss.to_csv(f'{summary_path}/EOG_missing_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from missing participants to:\\n{summary_path}/EOG_missing_edf.tsv')\n",
    "    print('Please inspect the file, and specifically the column transducer_type')\n",
    "elif len(df_full['subject'].unique()) < len(df_eog['subject'].unique()):\n",
    "    print('\\n!!! There is more participants in the dataset with only EOGs !!!')\n",
    "    print('This should not be the case.')\n",
    "    print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "    more_sub = set(df_eog['subject'].unique()) - set(df_full['subject'].unique())\n",
    "    df_more = df_eog[df_eog['subject'].isin(more_sub)]\n",
    "    df_more.to_csv(f'{summary_path}/EOG_suspect_edf.csv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/EOG_suspect_edf.tsv')\n",
    "\n",
    "# saving info from EOG\n",
    "df_eog.to_csv(f'{summary_path}/EOG_summary_table.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from EOGs to:\\n{summary_path}/EOG_summary_table.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea70be-3298-4648-8f5f-0f074252632d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2 Inspect EOG configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee87d7-45e7-4a12-a718-9de5c6cf0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the EOG configuration per participant \n",
    "eog_per_sub = df_eog.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the EOG configuration of each participant and store them in a dict to print per EOG config\n",
    "eog_config_dict = {}\n",
    "for config in eog_per_sub.unique():\n",
    "    sub = eog_per_sub[eog_per_sub == config].index.tolist()\n",
    "    eog_config_dict[config] = sub\n",
    "\n",
    "if len(eog_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple EOG configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different configuration: {len(eog_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one EOG configuration in your dataset! <<<')\n",
    "\n",
    "# # print info per channel configuaration\n",
    "# for i, (config, participants) in enumerate(ch_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Channels ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449b2ba-e7c7-4a85-9e24-77b5fa8dc212",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(eog_config_dict)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_eog_slider = mk_config_slider(value = 1, min = 1, max = len(eog_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=eog_config_dict, param=\"Channels\"), i=config_eog_slider);\n",
    "else:\n",
    "    print(\"No EOG configuration found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05198e3-a809-4bc4-a105-e9bfadf22695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.3 Inspect EOG sampling frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d711eb5-b511-474e-9257-e2bcc6566fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sampling frequency configuration\n",
    "sfeog_per_sub = df_eog.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "sfeog_config_dict = {}\n",
    "for config in sfeog_per_sub.unique():\n",
    "    sub = sfeog_per_sub[sfeog_per_sub == config].index.tolist()\n",
    "    sfeog_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration (maybe print it only for multiple config)\n",
    "if len(sfeog_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple sampling frequency for EOGs in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different sampling frequency configuration: {len(sfeog_config_dict)}\\n')\n",
    "    print('Quick overlook of the EOGs associated to sampling frequencies:')\n",
    "    for s, sf in enumerate(df_eog['sampling_frequency'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_sf = df_eog[df_eog['sampling_frequency'] == sf].copy()\n",
    "        print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "else:\n",
    "    print(f'\\n>>> There is only one sampling frequency for EOGs in your dataset: {df_eog['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "# print('\\nSampling frequency configurations:\\n')\n",
    "# for i, (config, participants) in enumerate(sf_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Sampling frequency ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55beab23-6663-4f62-a590-610117b8a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sfeog_config_dict)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_sfeog_slider = mk_config_slider(value = 1, min = 1, max = len(sfeog_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=sfeog_config_dict, param=\"Sampling frequencies\"), i=config_sfeog_slider);\n",
    "else:\n",
    "    print(\"No EOG sampling frequency found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a1db4-4830-4a4f-8688-13e06fda9857",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.4 Inspect EOG filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85f980-2ab7-455e-951a-e6371fe0ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_eog['highpass'].unique())+len(df_eog['lowpass'].unique())+len(df_eog['notch'].unique()) == 3:\n",
    "    print('\\n>>> All EOGs have the same filters! <<<')\n",
    "elif len(df_eog['highpass'].unique())+len(df_eog['lowpass'].unique())+len(df_eog['notch'].unique()) > 3:\n",
    "    print('\\n>>> Filters are not fully consistent across the dataset! <<<')\n",
    "else:\n",
    "    print('\\n>>> There may have been a problem in reading the filters. Here is the output: <<<')\n",
    "\n",
    "# Get the list of participants with different filtering parameters\n",
    "# 1st replace NaN because groupby does not like NaN\n",
    "df_eogfilt = df_eog.copy()\n",
    "df_eogfilt[['lowpass', 'highpass', 'notch']] = df_eogfilt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "\n",
    "config_eogfilters = (\n",
    "    df_eogfilt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .reset_index(name = 'subjects')\n",
    ")\n",
    "\n",
    "# print filter configuration\n",
    "print(f'\\n\\tNumber of different EOG filters configurations: {len(config_eogfilters)}\\n')\n",
    "# print('\\nFilters configurations: ')\n",
    "# r=1\n",
    "# for row in config_filters.itertuples(index=False):\n",
    "#     print(f'Configuration #{r} ({len(row.subjects)} participants)')\n",
    "#     print(f'highpass: {row.highpass}, lowpass: {row.lowpass}, notch: {row.notch}\\n')\n",
    "#     r=r+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01823f26-2f09-4cd9-9a6e-b46c84162081",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(config_eogfilters)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_eogfilter_slider = mk_config_slider(value = 1, min = 1, max = len(config_eogfilters))\n",
    "    \n",
    "    # function to rpint filters configurations\n",
    "    def print_eogfilters(config_slider):\n",
    "        # get the info from the dataframe\n",
    "        idx = config_slider - 1\n",
    "        sID = config_eogfilters.iloc[idx]['subjects']\n",
    "        hpass = config_eogfilters.iloc[idx]['highpass']\n",
    "        lpass = config_eogfilters.iloc[idx]['lowpass']\n",
    "        notch = config_eogfilters.iloc[idx]['notch']\n",
    "        \n",
    "        # print info\n",
    "        print(f'Selected configuration: # {config_slider}')\n",
    "        print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "        print(f'\\t{len(sID)} participants: {sID}')\n",
    "    \n",
    "    widgets.interact(print_eogfilters, config_slider = config_eogfilter_slider);\n",
    "else:\n",
    "    print(\"No EOG filters found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b374f-a67d-4c2c-8d51-3d221131b8bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.5 Inspect EOG units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead498f2-7177-4e47-8df5-01c69abdc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_eog['dimension'].unique()) == 1:\n",
    "    print(f'\\n>>> All EOGs have the same unit: {df_eog[\"dimension\"].unique()} <<<\\n')\n",
    "elif len(df_eog['dimension'].unique()) > 1:\n",
    "    print('\\n>>> Multiple units were found! <<<')\n",
    "    print(f'\\n\\tNumber of different EOG units configurations: {len(df_eog['dimension'].unique())}\\n')\n",
    "    print('Quick overlook of EOGs associated to units:')\n",
    "    for u, unit in enumerate(df_eog['dimension'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_unit = df_eog[df_eog['dimension'] == unit].copy()\n",
    "        print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "    \n",
    "\n",
    "# print the different configuration of units \n",
    "# if info about sf configuration is needed\n",
    "eogunit_per_sub = df_eog.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "eog_per_unit = df_eog.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "eogunit_config_dict = {}\n",
    "for config in eogunit_per_sub.unique():\n",
    "    sub = eogunit_per_sub[eogunit_per_sub == config].index.tolist()\n",
    "    eogunit_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration\n",
    "# print('\\nUnits configurations:')\n",
    "# for i, (config, participants) in enumerate(unit_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Unit ({len(config)}) : {config}\\n')\n",
    "#     # print(f\"Participants : {participants}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c7788-7426-4c55-a262-cb0439e2ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(eogunit_config_dict)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_eogunit_slider = mk_config_slider(value = 1, min = 1, max = len(eogunit_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=eogunit_config_dict, param=\"Units\"), i=config_eogunit_slider);\n",
    "else:\n",
    "    print(\"No EOG unit found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47a3b7-87c6-4e91-99e2-f9efda9e08a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.6 Inspect EOG signal inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c3906-fae3-4702-b6f8-8c6e9b8a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where the physical min is greater than the physical max\n",
    "df_eoginv = df_eog[df_eog['physical_min'] > df_eog['physical_max']]\n",
    "\n",
    "if not df_eoginv.empty:\n",
    "    print('\\n>>> Inverted polarity detected in EOGs! <<<')\n",
    "    print(f'{df_eoginv.shape[0]} EOGs have an inverted polarity (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "    print(df_eoginv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "else:\n",
    "    print('\\n>>> No inverted polarity was detected in EOGs <<<')\n",
    "df_eoginv.to_csv(f'{summary_path}/EOG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from inverted polarity EOGs to:\\n{summary_path}/EOG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2096c3a-1f34-46ed-90d9-3a6505361380",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.7 Inspect EOG dynamic range and resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933f93b-93ef-499e-87f0-f94ea4760bbb",
   "metadata": {},
   "source": [
    "#### Dynamic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5911760-c9bd-4026-930b-f1753f68d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_eogthres = widgets.BoundedFloatText(\n",
    "    value=500,\n",
    "    min=0,\n",
    "    max=5000,\n",
    "    step=0.1,\n",
    "    style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Dynamic range threshold (¬µV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "\n",
    "def check_bad_eogdr(threshold):\n",
    "    dr_mask = df_eog['res_theoretical']*pow(2,16) <= threshold\n",
    "    bad_dr = df_eog[dr_mask]\n",
    "    \n",
    "    if not bad_dr.empty:\n",
    "        print(f'\\n>>> Dynamic range <= {threshold} ¬µV detected in EOGs! <<<\\n')\n",
    "        print(f'{bad_dr.shape[0]} EOGs detected (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "        print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EOG with a dynamic range <= {threshold} ¬µV was detected! <<<')\n",
    "    bad_dr.to_csv(f'{summary_path}/EOG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad dynamic range EOGs to:\\n{summary_path}/EOG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_eogdr, threshold = dr_eogthres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e8713-eb68-4b0c-aa9c-75122905339b",
   "metadata": {},
   "source": [
    "#### Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f375f53-14ef-451a-9429-9e1a22f6dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "eogr_thres = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Resolution threshold (¬µV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "# define a function to interact with the widget\n",
    "def check_bad_eogres(threshold):\n",
    "    r_mask = df_eog['res_theoretical'] >= threshold\n",
    "    bad_res = df_eog[r_mask]\n",
    "    \n",
    "    if not bad_res.empty:\n",
    "        print(f'\\n>>> EOGs with a resolution >= {threshold} ¬µV detected! <<<')\n",
    "        print(f'{bad_res.shape[0]} EOGs detected (from {df_eog.shape[0]} EOGs in {len(edf_files)} edf files)')\n",
    "        print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No EOG with a resolution >= {threshold} ¬µV was detected! <<<')\n",
    "    bad_res.to_csv(f'{summary_path}/EOG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad resolution EOGs to:\\n{summary_path}/EOG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_eogres, threshold=eogr_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e34f1-9a8c-4301-93b5-6d956d6d4b31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Inspect ECG\n",
    "This section follows the same structure, logic, and outputs as section 2. Inspect EEG.\\\n",
    "Hence, the code cells are not commented (please refer to section 2 if you need a refresher)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6965c-43c1-49f8-bddd-b2163a2c5660",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1 Select only ECGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a29cd-f142-4360-8a3e-481130dbad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only ECGs and return a warning if the number of participant is smaller/higher\n",
    "mask_ecg = df_full['channel'].str.contains(r'ecg', case = False, na=False) # create a mask that returns true for lines containing either ecg in the channel column\n",
    "df_ecg = df_full[mask_ecg]\n",
    "\n",
    "# Check if the number of participants with only ECG is the same as df_full. \n",
    "# If not, it might be because the transducer type was no correctly detected. \n",
    "# One possibility is to add the type of transducer to the condition line 2 of this cell.\n",
    "if len(df_full['subject'].unique()) > len(df_ecg['subject'].unique()):\n",
    "    # identify missing subjects\n",
    "    missing_sub = set(df_full['subject'].unique()) - set(df_ecg['subject'].unique())\n",
    "    print('\\n!!! There is less participants in the dataset with only ECGs !!!')\n",
    "    print(f'Missing participants: {missing_sub}')\n",
    "    print(\"\\nEither these participants don't have ECGs.\")\n",
    "    print(\"Or the transducer type was not correctly detected.\")\n",
    "    # get df of missing sub to save and inspect\n",
    "    df_ecgmiss = df_full[df_full['subject'].isin(missing_sub)]\n",
    "    df_ecgmiss.to_csv(f'{summary_path}/ECG_missing_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from missing participants to:\\n{summary_path}/ECG_missing_edf.tsv')\n",
    "    print('Please inspect the file, and specifically the column transducer_type')\n",
    "elif len(df_full['subject'].unique()) < len(df_ecg['subject'].unique()):\n",
    "    print('\\n!!! There is more participants in the dataset with only ECGs !!!')\n",
    "    print('This should not be the case.')\n",
    "    print('Please inspect what is happening in a code editor (spyder..), or ask Yvan.')\n",
    "    more_sub = set(df_ecg['subject'].unique()) - set(df_full['subject'].unique())\n",
    "    df_more = df_ecg[df_ecg['subject'].isin(more_sub)]\n",
    "    df_more.to_csv(f'{summary_path}/ECG_suspect_edf.csv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from suspect participants to:\\n{summary_path}/ECG_suspect_edf.tsv')\n",
    "\n",
    "# saving info from ECG\n",
    "df_ecg.to_csv(f'{summary_path}/ECG_summary_table.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from ECGs to:\\n{summary_path}/ECG_summary_table.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3b1c6-3ba4-4b8a-b367-54dd4413bc06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2 Inspect ECG configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f545a1a-0906-4242-8422-db886f991089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ECGs configuration per participant \n",
    "ecg_per_sub = df_ecg.groupby('subject')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "\n",
    "# identify the ECG configuration of each participant and store them in a dict to print per ECG config\n",
    "ecg_config_dict = {}\n",
    "for config in ecg_per_sub.unique():\n",
    "    sub = ecg_per_sub[ecg_per_sub == config].index.tolist()\n",
    "    ecg_config_dict[config] = sub\n",
    "\n",
    "if len(ecg_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple ECG configurations in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different ECG configuration: {len(ecg_config_dict)}\\n')\n",
    "else:\n",
    "    print('\\n>>> There is only one ECG configuration in your dataset! <<<')\n",
    "\n",
    "# # print info per channel configuaration\n",
    "# for i, (config, participants) in enumerate(ch_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Channels ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf05caa-f3b6-47e4-a470-3ef7cf439efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget to select the configuration of interest\n",
    "if len(ecg_config_dict) >=1:\n",
    "    config_ecg_slider = mk_config_slider(value = 1, min = 1, max = len(ecg_config_dict))\n",
    "\n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=ecg_config_dict, param=\"Channels\"), i=config_ecg_slider);\n",
    "else:\n",
    "    print(\"No ECG  configuration found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e622e81-547c-4c3e-9833-e5ee79c3eee2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3 Inspect ECG sampling frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52a436-092d-40fa-b677-1eb011a4cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sampling frequency configuration\n",
    "ecgsf_per_sub = df_ecg.groupby('subject')['sampling_frequency'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "ecgsf_config_dict = {}\n",
    "for config in ecgsf_per_sub.unique():\n",
    "    sub = ecgsf_per_sub[ecgsf_per_sub == config].index.tolist()\n",
    "    ecgsf_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration (maybe print it only for multiple config)\n",
    "if len(ecgsf_config_dict) > 1:\n",
    "    print('\\n>>> There is multiple sampling frequency for ECGs in your dataset! <<<')    \n",
    "    print(f'\\n\\tNumber of different sampling frequency configuration: {len(ecgsf_config_dict)}\\n')\n",
    "    print('Quick overlook of the ECGs associated to sampling frequencies:')\n",
    "    for s, sf in enumerate(df_ecg['sampling_frequency'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_sf = df_ecg[df_ecg['sampling_frequency'] == sf].copy()\n",
    "        print(f'\\n{sf} Hz: {df_sf[\"channel\"].unique()}')\n",
    "else:\n",
    "    print(f'\\n>>> There is only one sampling frequency for ECGs in your dataset: {df_ecg['sampling_frequency'].unique()} <<<')\n",
    "\n",
    "# print('\\nSampling frequency configurations:\\n')\n",
    "# for i, (config, participants) in enumerate(sf_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Sampling frequency ({len(config)}) : {config}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7365d9b-95cf-40e9-b6b2-2c8bb80836fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget to select the configuration of interest\n",
    "if len(ecgsf_config_dict) >=1:\n",
    "    config_ecgsf_slider = mk_config_slider(value = 1, min = 1, max = len(ecgsf_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=ecgsf_config_dict, param=\"Sampling frequencies\"), i=config_ecgsf_slider);\n",
    "else:\n",
    "    print(\"No ECG sampling frequency found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aabf4-0bff-497c-b3f2-6ea68966bf76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.4 Inspect ECG filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353a752-9e29-4f05-beae-e6b08ccb82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ecg['highpass'].unique())+len(df_ecg['lowpass'].unique())+len(df_ecg['notch'].unique()) == 3:\n",
    "    print('\\n>>> All ECGs have the same filters! <<<')\n",
    "elif len(df_ecg['highpass'].unique())+len(df_ecg['lowpass'].unique())+len(df_ecg['notch'].unique()) > 3:\n",
    "    print('\\n>>> Filters are not fully consistent across the dataset! <<<')\n",
    "else:\n",
    "    print('\\n>>> There may have been a problem in reading the filters. Here is the output: <<<')\n",
    "\n",
    "# Get the list of participants with different filtering parameters\n",
    "# 1st replace NaN because groupby does not like NaN\n",
    "df_ecgfilt = df_ecg.copy()\n",
    "df_ecgfilt[['lowpass', 'highpass', 'notch']] = df_ecgfilt[['lowpass', 'highpass', 'notch']].fillna('missing')\n",
    "\n",
    "config_ecgfilters = (\n",
    "    df_ecgfilt.groupby(['lowpass', 'highpass', 'notch'])['subject']\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    "    .reset_index(name = 'subjects')\n",
    ")\n",
    "\n",
    "# print filter configuration\n",
    "print(f'\\n\\tNumber of different ECG filters configurations: {len(config_ecgfilters)}\\n')\n",
    "# print('\\nFilters configurations: ')\n",
    "# r=1\n",
    "# for row in config_filters.itertuples(index=False):\n",
    "#     print(f'Configuration #{r} ({len(row.subjects)} participants)')\n",
    "#     print(f'highpass: {row.highpass}, lowpass: {row.lowpass}, notch: {row.notch}\\n')\n",
    "#     r=r+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f67fb-fbd8-4931-9ee1-07688b6d8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget to select the configuration of interest\n",
    "if len(config_ecgfilters)>=1:\n",
    "    config_ecgfilter_slider = mk_config_slider(value = 1, min = 1, max = len(config_ecgfilters))\n",
    "    \n",
    "    # function to rpint filters configurations\n",
    "    def print_ecgfilters(config_slider):\n",
    "        # get the info from the dataframe\n",
    "        idx = config_slider - 1\n",
    "        sID = config_ecgfilters.iloc[idx]['subjects']\n",
    "        hpass = config_ecgfilters.iloc[idx]['highpass']\n",
    "        lpass = config_ecgfilters.iloc[idx]['lowpass']\n",
    "        notch = config_ecgfilters.iloc[idx]['notch']\n",
    "        \n",
    "        # print info\n",
    "        print(f'Selected configuration: # {config_slider}')\n",
    "        print(f'\\tFilters configuration: highpass: {hpass}; lowpass: {lpass}; notch: {notch}')\n",
    "        print(f'\\t{len(sID)} participants: {sID}')\n",
    "    \n",
    "    widgets.interact(print_ecgfilters, config_slider = config_ecgfilter_slider);\n",
    "else:\n",
    "    print(\"No ECG filters found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a73596-3052-4332-a608-9e594331d3d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.5 Inspect ECG units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19ed48-d5e8-4f71-9526-753137853b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ecg['dimension'].unique()) == 1:\n",
    "    print(f'\\n>>> All ECGs have the same unit: {df_ecg[\"dimension\"].unique()} <<<\\n')\n",
    "elif len(df_ecg['dimension'].unique()) > 1:\n",
    "    print('\\n>>> Multiple units were found for ECGs! <<<')\n",
    "    print(f'\\n\\tNumber of different units configurations: {len(df_ecg['dimension'].unique())}\\n')\n",
    "    print('Quick overlook of ECGs associated to units:')\n",
    "    for u, unit in enumerate(df_ecg['dimension'].unique()):\n",
    "        # select only rows with the current sf\n",
    "        df_unit = df_ecg[df_ecg['dimension'] == unit].copy()\n",
    "        print(f'\\n{unit}: {df_unit[\"channel\"].unique()}')\n",
    "    \n",
    "\n",
    "# print the different configuration of units \n",
    "# if info about sf configuration is needed\n",
    "ecgunit_per_sub = df_ecg.groupby('subject')['dimension'].apply(lambda x: tuple(sorted(set(x))))\n",
    "ecg_per_unit = df_ecg.groupby('dimension')['channel'].apply(lambda x: tuple(sorted(set(x))))\n",
    "# identify the sampling frequency configuration of each participant and store them in a dict to print per sampling configuration config\n",
    "ecgunit_config_dict = {}\n",
    "for config in ecgunit_per_sub.unique():\n",
    "    sub = ecgunit_per_sub[ecgunit_per_sub == config].index.tolist()\n",
    "    ecgunit_config_dict[config] = sub\n",
    "\n",
    "# print info per sf configuration\n",
    "# print('\\nUnits configurations:')\n",
    "# for i, (config, participants) in enumerate(unit_config_dict.items(), 1):\n",
    "#     print(f'Configuration #{i} ({len(participants)} participants):')\n",
    "#     print(f'Unit ({len(config)}) : {config}\\n')\n",
    "#     # print(f\"Participants : {participants}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61ee8a-9dcc-4bf2-8368-2139f4cd0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ecgunit_config_dict)>=1:\n",
    "    # widget to select the configuration of interest\n",
    "    config_ecgunit_slider = mk_config_slider(value = 1, min = 1, max = len(ecgunit_config_dict))\n",
    "    \n",
    "    # print the configuration selected\n",
    "    # interact with the slider output through the printing function \n",
    "    widgets.interact(lambda i: print_config(i, config_dict=ecgunit_config_dict, param=\"Units\"), i=config_ecgunit_slider);\n",
    "else:\n",
    "    print(\"No ECG unit found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079ce64-f923-4327-9798-fc00749a6bd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.6 Inspect ECG signal inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d7cf6-35d4-4bf8-a0c6-1a23150521b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where the physical min is greater than the physical max\n",
    "df_ecginv = df_ecg[df_ecg['physical_min'] > df_ecg['physical_max']]\n",
    "\n",
    "if not df_ecginv.empty:\n",
    "    print('\\n>>> Inverted polarity detected in ECGs! <<<')\n",
    "    print(f'{df_ecginv.shape[0]} ECGs have an inverted polarity (from {df_ecg.shape[0]} ECGs in {len(edf_files)} edf files)')\n",
    "    print(df_ecginv[['subject', 'channel', 'dimension', 'physical_min', 'physical_max']])\n",
    "else:\n",
    "    print('\\n>>> No inverted polarity was detected in ECGs <<<')\n",
    "df_ecginv.to_csv(f'{summary_path}/ECG_inverted_polarity_edf.tsv', sep = '\\t')\n",
    "print(f'\\nSaving informations from inverted polarity ECGs to:\\n{summary_path}/ECG_inverted_polarity_edf.tsv \\n(will be empty if no inverted polarity)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9047e4-c030-4c44-92de-a1b6f948ed99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.7 Inspect ECG dynamic range and resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475e1e4-ed06-45ca-abec-c6228e30e0f4",
   "metadata": {},
   "source": [
    "#### Dynamic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f97f77-0476-4ff4-83ee-c6cdea87a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecgdr_thres = widgets.BoundedFloatText(\n",
    "    value=500,\n",
    "    min=0,\n",
    "    max=5000,\n",
    "    step=0.1,\n",
    "    style={'description_width': '200px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='270px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Dynamic range threshold (¬µV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "\n",
    "def check_bad_ecgdr(threshold):\n",
    "    dr_mask = df_ecg['res_theoretical']*pow(2,16) <= threshold\n",
    "    bad_dr = df_ecg[dr_mask]\n",
    "    \n",
    "    if not bad_dr.empty:\n",
    "        print(f'\\n>>> Dynamic range <= {threshold} ¬µV detected in ECGs! <<<\\n')\n",
    "        print(f'{bad_dr.shape[0]} ECGs detected (from {df_ecg.shape[0]} ECGs in {len(edf_files)} edf files)')\n",
    "        print(bad_dr[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No ECG with a dynamic range <= {threshold} ¬µV was detected! <<<')\n",
    "    bad_dr.to_csv(f'{summary_path}/ECG_bad_dynamic_range_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad dynamic range ECGs to:\\n{summary_path}/ECG_bad_dynamic_range_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_ecgdr, threshold = ecgdr_thres);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd9c6f-5420-4013-bf02-6a0995c597f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa2a9b-abdb-4e9f-8fb2-dddf92280539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_theo have been converted to uV, but if dimension was not read or not indicated in the headers, it might not work. I might need to add something more robust\n",
    "ecgr_thres = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    style={'description_width': '150px'},  # augmente la largeur de la description\n",
    "    layout=widgets.Layout(width='230px'),   # ajuste la taille totale du widget si besoin\n",
    "    description='Resolution threshold (¬µV):',\n",
    "    disabled=False\n",
    ");\n",
    "\n",
    "# define a function to interact with the widget\n",
    "def check_bad_ecgres(threshold):\n",
    "    r_mask = df_ecg['res_theoretical'] >= threshold\n",
    "    bad_res = df_ecg[r_mask]\n",
    "    \n",
    "    if not bad_res.empty:\n",
    "        print(f'\\n>>> ECGs with a resolution >= {threshold} ¬µV detected! <<<')\n",
    "        print(f'{bad_res.shape[0]} ECGs detected (from {df_ecg.shape[0]} ecgs in {len(edf_files)} edf files)')\n",
    "        print(bad_res[['subject', 'channel', 'dimension', 'physical_min', 'physical_max', 'res_theoretical']])\n",
    "    else:\n",
    "        print(f'\\n>>> No ECG with a resolution >= {threshold} ¬µV was detected! <<<')\n",
    "    bad_res.to_csv(f'{summary_path}/ECG_bad_resolution_edf.tsv', sep = '\\t')\n",
    "    print(f'\\nSaving informations from bad resolution ECGs to:\\n{summary_path}/ECG_bad_resolution_edf.tsv \\n(will be empty if no bad resolution)')\n",
    "\n",
    "widgets.interact(check_bad_ecgres, threshold=ecgr_thres);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
